{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SNP(data):   \n",
    "    df = pd.read_csv(f\"data/{data}\")\n",
    "    X = df.drop([\"Phenotype\", \"Genotype\"],axis=1) # All SNP columns\n",
    "    y = df['Phenotype']  # Convert phenotype to float\n",
    "\n",
    "    variances = X.var(axis=0)\n",
    "    optimal_threshold = variances.quantile(0.25)\n",
    "    var_thresh = VarianceThreshold(threshold=optimal_threshold) \n",
    "    X_var_filtered = pd.DataFrame(var_thresh.fit_transform(X), columns=X.columns[var_thresh.get_support()])\n",
    "    n_features = X_var_filtered.shape[1]\n",
    "\n",
    "    X_var_filtered = np.array(X_var_filtered)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Train-Test split (80% train, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_var_filtered, y, test_size=0.1)\n",
    "\n",
    "    # Further split train into train/val (80/20 split of the train set)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.1)\n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    class SNPPhenotypeDataset(Dataset):\n",
    "        def __init__(self, X, y):\n",
    "            self.X = torch.tensor(X, dtype=torch.float32)  \n",
    "            self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)  \n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.X[idx], self.y[idx]\n",
    "        \n",
    "    train_dataset = SNPPhenotypeDataset(X_train, y_train)\n",
    "    val_dataset   = SNPPhenotypeDataset(X_val, y_val)\n",
    "    test_dataset  = SNPPhenotypeDataset(X_test, y_test)\n",
    "\n",
    "    batch_size = 8\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader,input_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createANNModel(hidden_units, drop,lr,decay,input_length,activation_type=\"relu\",optimizer_type=\"adam\"):\n",
    "    class ANN(nn.Module):\n",
    "        def __init__(self, hidden_units, drop, activation_type,input_length):\n",
    "            super(ANN, self).__init__()\n",
    "\n",
    "            self.nLayers = len(hidden_units)\n",
    "            \n",
    "            self.activations = {\n",
    "                'relu': F.relu,              \n",
    "                'leaky_relu': F.leaky_relu,  \n",
    "                'elu': F.elu,\n",
    "                \"tanh\": F.tanh        \n",
    "            }\n",
    "\n",
    "            self.activation = self.activations.get(activation_type.lower(), F.relu)\n",
    "\n",
    "            self.layers = nn.ModuleDict()\n",
    "\n",
    "            self.batch_norms = nn.ModuleDict()\n",
    "\n",
    "            self.layers[\"input\"] = nn.Linear(input_length, hidden_units[0])\n",
    "            self.batch_norms[\"input\"] = nn.BatchNorm1d(hidden_units[0])\n",
    "\n",
    "            for i in range(self.nLayers - 1):\n",
    "                self.layers[f\"hidden{i}\"] = nn.Linear(hidden_units[i], hidden_units[i+1])\n",
    "                self.batch_norms[f\"hidden{i}\"] = nn.BatchNorm1d(hidden_units[i+1])\n",
    "            \n",
    "            self.layers[\"output\"] = nn.Linear(hidden_units[-1], 1)\n",
    "\n",
    "            self.dropout = nn.Dropout(p=drop)\n",
    "            \n",
    "        def forward(self,x):\n",
    "\n",
    "            x = self.layers['input'](x)\n",
    "            x = self.batch_norms[\"input\"](x)\n",
    "            x = self.activation(x)\n",
    "\n",
    "            # hidden layers\n",
    "            for i in range(self.nLayers - 1):\n",
    "                x = self.layers[f'hidden{i}'](x)\n",
    "                x = self.batch_norms[f'hidden{i}'](x)\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "\n",
    "            # return output layer\n",
    "            x = self.layers['output'](x)\n",
    "            return x\n",
    "    \n",
    "    \n",
    "    model = ANN(hidden_units,drop,activation_type,input_length)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    optimizers = {\n",
    "    'adam': lambda: torch.optim.Adam(model.parameters(), lr=lr, weight_decay=decay),\n",
    "    'sgd': lambda: torch.optim.SGD(model.parameters(), lr=lr, weight_decay=decay, momentum=0.9),\n",
    "    \"adamw\": lambda: torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=decay),\n",
    "    \"rmsprop\": lambda: torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=decay, alpha=0.99,momentum=0.9),\n",
    "    }\n",
    "    optimizer = optimizers.get(optimizer_type.lower(), optimizers['adam'])()\n",
    "\n",
    "    return model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainAndEval(model,criterion,optimizer,train_loader,val_loader,max_epochs=1000,patience=500):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    model.to(device)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device).view(-1, 1)  # Reshape y to match output\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device).view(-1, 1)  # Reshape y to match output\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                running_val_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        \n",
    "        # Update learning rate based on validation loss\n",
    "        scheduler.step(epoch_val_loss)\n",
    "\n",
    "        #print(f\"Epoch [{epoch+1}/{max_epochs}] | Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "        # Early Stopping Check\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            #print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            print(f\"Final Train loss: {train_losses[-1]:.4f} | Final Val Loss: {val_losses[-1]:.4f}\")\n",
    "            break\n",
    "\n",
    "    # Load best model for evaluation\n",
    "    if 'best_model_state' in locals():\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_MLP(target_r2=0.7, data_folder=\"data\"):\n",
    "    # Create a DataFrame to store best results for each dataset\n",
    "    best_results_df = pd.DataFrame(columns=[\n",
    "        'Dataset', 'MSE', 'MAE', 'R2', 'Units', 'Dropout', 'Learning_Rate', \n",
    "        'Weight_Decay', 'Epochs', 'Activation', 'Optimizer', 'Patience'\n",
    "    ])\n",
    "    \n",
    "    # Iterate through each dataset in the folder\n",
    "    for data_file in os.listdir(data_folder):\n",
    "        if not data_file.endswith('.csv'):\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n\\n{'='*50}\")\n",
    "        print(f\"Processing dataset: {data_file}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Create a DataFrame to store all trial results for this dataset\n",
    "        all_trials_df = pd.DataFrame(columns=[\n",
    "            'Trial', 'MSE', 'MAE', 'R2', 'Units', 'Dropout', 'Learning_Rate', \n",
    "            'Weight_Decay', 'Epochs', 'Activation', 'Optimizer', 'Patience'\n",
    "        ])\n",
    "        \n",
    "        try:\n",
    "            train_loader, val_loader, test_loader, input_dim = get_SNP(data_file)\n",
    "            \n",
    "            # Define parameter grid\n",
    "            param_grid = {\n",
    "                \"NUM_EPOCH\": [250, 350, 450],\n",
    "                \"NUM_UNITS\": [[24, 16, 16, 8],\n",
    "                             [32, 16, 8, 8], \n",
    "                             [16, 16, 8, 8]], \n",
    "                \"DROP\": [0.2, 0.3],                       \n",
    "                \"LR\": [0.001, 0.0001],                       \n",
    "                \"DECAY\": [1e-4, 1e-5],                 \n",
    "                \"PATIENCE\": 15,\n",
    "                \"ACTIVATION\": [\"relu\", \"tanh\"],\n",
    "                \"OPTIMIZER\": [\"adam\", \"sgd\"]    \n",
    "            }\n",
    "            \n",
    "            # Calculate total number of combinations\n",
    "            total_combinations = (\n",
    "                len(param_grid[\"NUM_UNITS\"]) * \n",
    "                len(param_grid[\"DROP\"]) *\n",
    "                len(param_grid[\"LR\"]) * \n",
    "                len(param_grid[\"DECAY\"]) *\n",
    "                len(param_grid[\"NUM_EPOCH\"]) *\n",
    "                len(param_grid[\"ACTIVATION\"]) *\n",
    "                len(param_grid[\"OPTIMIZER\"])\n",
    "            )\n",
    "            \n",
    "            print(f\"Total parameter combinations to try: {total_combinations}\")\n",
    "            \n",
    "            best_r2 = -float('inf')\n",
    "            best_params = None\n",
    "            best_model = None\n",
    "            best_metrics = None\n",
    "            current_trial = 0\n",
    "            \n",
    "            # Iterate through all parameter combinations\n",
    "            for units in param_grid[\"NUM_UNITS\"]:\n",
    "                for epochs in param_grid[\"NUM_EPOCH\"]:\n",
    "                    for act in param_grid[\"ACTIVATION\"]:\n",
    "                        for opt in param_grid[\"OPTIMIZER\"]:\n",
    "                            for drop in param_grid[\"DROP\"]:\n",
    "                                for lr in param_grid[\"LR\"]:\n",
    "                                    for decay in param_grid[\"DECAY\"]:\n",
    "                                        current_trial += 1\n",
    "                \n",
    "                                        \n",
    "                                        current_params = {\n",
    "                                            \"num_epochs\": epochs,\n",
    "                                            'num_units': units,\n",
    "                                            'drop': drop,\n",
    "                                            'lr': lr,\n",
    "                                            'decay': decay,\n",
    "                                            \"acts\": act,\n",
    "                                            \"opts\": opt,\n",
    "                                            \"patience\": param_grid[\"PATIENCE\"]\n",
    "                                        }\n",
    "                                        \n",
    "                                        print(f\"\\nTrial {current_trial}/{total_combinations}\")\n",
    "                                        print(\"Current parameters:\", current_params)\n",
    "                                        \n",
    "                                        # Create and train model\n",
    "                                        model, criterion, optimizer = createANNModel(\n",
    "                                            hidden_units=units,\n",
    "                                            drop=drop,\n",
    "                                            lr=lr, \n",
    "                                            decay=decay,\n",
    "                                            optimizer_type=opt,\n",
    "                                            activation_type=act,\n",
    "                                            input_length=input_dim\n",
    "                                        )\n",
    "                                        \n",
    "                                        # Train model and get metrics\n",
    "                                        trained_model = trainAndEval(\n",
    "                                            model, criterion, optimizer, \n",
    "                                            max_epochs=epochs, \n",
    "                                            patience=param_grid[\"PATIENCE\"],\n",
    "                                            train_loader=train_loader,\n",
    "                                            val_loader=val_loader\n",
    "                                        )\n",
    "                                        \n",
    "                                        # Get predictions on test set\n",
    "                                        model.eval()\n",
    "                                        with torch.no_grad():\n",
    "                                            all_preds = []\n",
    "                                            all_targets = []\n",
    "                                            for batch_X, batch_y in test_loader:\n",
    "                                                batch_X = batch_X.to(device)\n",
    "                                                outputs = model(batch_X)\n",
    "                                                all_preds.append(outputs.cpu().numpy())\n",
    "                                                all_targets.append(batch_y.numpy())\n",
    "                                                \n",
    "                                        y_pred = np.concatenate(all_preds).reshape(-1)\n",
    "                                        y_true = np.concatenate(all_targets).reshape(-1)\n",
    "                                        \n",
    "                                        # Calculate metrics\n",
    "                                        mse = mean_squared_error(y_true, y_pred)\n",
    "                                        mae = mean_absolute_error(y_true, y_pred)\n",
    "                                        r2 = r2_score(y_true, y_pred)\n",
    "                                        \n",
    "                                        print(f\"R2 Score: {r2:.4f}\")\n",
    "                                        print(f\"MSE Score: {mse:.4f}\")\n",
    "                                        print(f\"MAE Score: {mae:.4f}\")\n",
    "                                        \n",
    "                                        # Add results to the dataset's trial DataFrame\n",
    "                                        trial_results = {\n",
    "                                            'Trial': current_trial,\n",
    "                                            'MSE': mse,\n",
    "                                            'MAE': mae,\n",
    "                                            'R2': r2,\n",
    "                                            'Units': str(units),\n",
    "                                            'Dropout': drop,\n",
    "                                            'Learning_Rate': lr,\n",
    "                                            'Weight_Decay': decay,\n",
    "                                            'Epochs': epochs,\n",
    "                                            'Activation': act,\n",
    "                                            'Optimizer': opt,\n",
    "                                            'Patience': param_grid[\"PATIENCE\"]\n",
    "                                        }\n",
    "                                        all_trials_df = pd.concat([all_trials_df, pd.DataFrame([trial_results])], ignore_index=True)\n",
    "                                        \n",
    "                                        # Save current trial results to CSV (append mode)\n",
    "                                        dataset_name = data_file.split('.')[0]\n",
    "                                        trials_csv_path = f\"MLP_results/grid_search_{dataset_name}.csv\"\n",
    "                                        \n",
    "                                        # Create directory if it doesn't exist\n",
    "                                        os.makedirs(\"MLP_results\", exist_ok=True)\n",
    "                                        \n",
    "                                        # Save with header only if file doesn't exist\n",
    "                                        all_trials_df.iloc[-1:].to_csv(\n",
    "                                            trials_csv_path, \n",
    "                                            mode='a', \n",
    "                                            header=not os.path.exists(trials_csv_path),\n",
    "                                            index=False\n",
    "                                        )\n",
    "                                        \n",
    "                                        # Update best results if better R2 found\n",
    "                                        if r2 > best_r2:\n",
    "                                            best_r2 = r2\n",
    "                                            best_params = current_params\n",
    "                                            best_model = trained_model\n",
    "                                            best_metrics = {\n",
    "                                                'r2': r2,\n",
    "                                                'mse': mse,\n",
    "                                                'mae': mae\n",
    "                                            }\n",
    "                                            print(\"New best R2 score!\")\n",
    "                                            \n",
    "                                            # Save the best model so far\n",
    "                                            model_save_path = f\"MLP_models/best_model_{dataset_name}.pth\"\n",
    "                                            os.makedirs('MLP_models', exist_ok=True)\n",
    "                                            torch.save(best_model.state_dict(), model_save_path)\n",
    "                                        \n",
    "                                        # Check if target achieved\n",
    "                                        if r2 >= target_r2:\n",
    "                                            print(f\"\\nTarget R2 score of {target_r2} achieved!\")\n",
    "                                            break\n",
    "                                            \n",
    "            # After all trials for this dataset, add best result to the main results DataFrame\n",
    "            best_result = {\n",
    "                'Dataset': data_file,\n",
    "                'MSE': best_metrics['mse'],\n",
    "                'MAE': best_metrics['mae'],\n",
    "                'R2': best_metrics['r2'],\n",
    "                'Units': str(best_params['num_units']),\n",
    "                'Dropout': best_params['drop'],\n",
    "                'Learning_Rate': best_params['lr'],\n",
    "                'Weight_Decay': best_params['decay'],\n",
    "                'Epochs': best_params['num_epochs'],\n",
    "                'Activation': best_params['acts'],\n",
    "                'Optimizer': best_params['opts'],\n",
    "                'Patience': best_params['patience']\n",
    "            }\n",
    "            best_results_df = pd.concat([best_results_df, pd.DataFrame([best_result])], ignore_index=True)\n",
    "            \n",
    "            # Display best results for this dataset\n",
    "            print(\"\\nGrid search completed for this dataset!\")\n",
    "            print(\"\\nBest parameters found:\")\n",
    "            for param, value in best_params.items():\n",
    "                print(f\"{param}: {value}\")\n",
    "            print(f\"\\nBest metrics:\")\n",
    "            print(f\"R2: {best_metrics['r2']:.4f}\")\n",
    "            print(f\"MSE: {best_metrics['mse']:.4f}\") \n",
    "            print(f\"MAE: {best_metrics['mae']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing dataset {data_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Save the best results from all datasets to a main CSV file\n",
    "    os.makedirs('MLP_results', exist_ok=True)\n",
    "    best_results_df.to_csv(\"MLP_results/best_models_summary.csv\", index=False)\n",
    "    \n",
    "    print(\"\\nAll datasets processed. Best results saved to 'results/best_models_summary.csv'\")\n",
    "    \n",
    "    # Return the best overall model if needed\n",
    "    best_overall_idx = best_results_df['R2'].idxmax()\n",
    "    best_overall_dataset = best_results_df.loc[best_overall_idx, 'Dataset']\n",
    "    print(f\"\\nBest overall model found for dataset: {best_overall_dataset}\")\n",
    "    print(f\"R2 Score: {best_results_df.loc[best_overall_idx, 'R2']:.4f}\")\n",
    "    \n",
    "    # The function can still return the best model from the last dataset processed\n",
    "    # or you could load and return the best overall model\n",
    "    return best_params, best_model, best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "Processing dataset: filtered_00001.csv\n",
      "==================================================\n",
      "Total parameter combinations to try: 288\n",
      "\n",
      "Trial 1/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2683 | Final Val Loss: 1.9471\n",
      "R2 Score: 0.3651\n",
      "MSE Score: 0.8431\n",
      "MAE Score: 0.6859\n",
      "New best R2 score!\n",
      "\n",
      "Trial 2/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20332\\425057010.py:142: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_trials_df = pd.concat([all_trials_df, pd.DataFrame([trial_results])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train loss: 1.4701 | Final Val Loss: 2.1057\n",
      "R2 Score: 0.4623\n",
      "MSE Score: 0.7141\n",
      "MAE Score: 0.6081\n",
      "New best R2 score!\n",
      "\n",
      "Trial 3/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8906 | Final Val Loss: 12.9751\n",
      "R2 Score: -4.6392\n",
      "MSE Score: 7.4887\n",
      "MAE Score: 2.5427\n",
      "\n",
      "Trial 4/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.7166 | Final Val Loss: 16.1412\n",
      "R2 Score: -6.0768\n",
      "MSE Score: 9.3978\n",
      "MAE Score: 2.8404\n",
      "\n",
      "Trial 5/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.3906 | Final Val Loss: 2.1519\n",
      "R2 Score: 0.3874\n",
      "MSE Score: 0.8135\n",
      "MAE Score: 0.6050\n",
      "\n",
      "Trial 6/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6990 | Final Val Loss: 2.1138\n",
      "R2 Score: 0.3033\n",
      "MSE Score: 0.9253\n",
      "MAE Score: 0.6982\n",
      "\n",
      "Trial 7/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.4373 | Final Val Loss: 12.5023\n",
      "R2 Score: -4.1538\n",
      "MSE Score: 6.8440\n",
      "MAE Score: 2.3651\n",
      "\n",
      "Trial 8/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.0350 | Final Val Loss: 10.8375\n",
      "R2 Score: -3.3658\n",
      "MSE Score: 5.7977\n",
      "MAE Score: 2.1963\n",
      "\n",
      "Trial 9/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3912 | Final Val Loss: 1.6107\n",
      "R2 Score: 0.4020\n",
      "MSE Score: 0.7942\n",
      "MAE Score: 0.5858\n",
      "\n",
      "Trial 10/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2785 | Final Val Loss: 1.0076\n",
      "R2 Score: 0.5022\n",
      "MSE Score: 0.6611\n",
      "MAE Score: 0.6434\n",
      "New best R2 score!\n",
      "\n",
      "Trial 11/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5944 | Final Val Loss: 2.1697\n",
      "R2 Score: 0.3521\n",
      "MSE Score: 0.8604\n",
      "MAE Score: 0.6763\n",
      "\n",
      "Trial 12/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4120 | Final Val Loss: 1.8138\n",
      "R2 Score: 0.4142\n",
      "MSE Score: 0.7780\n",
      "MAE Score: 0.6223\n",
      "\n",
      "Trial 13/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6103 | Final Val Loss: 1.4071\n",
      "R2 Score: 0.3051\n",
      "MSE Score: 0.9228\n",
      "MAE Score: 0.7040\n",
      "\n",
      "Trial 14/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5597 | Final Val Loss: 1.3662\n",
      "R2 Score: 0.3769\n",
      "MSE Score: 0.8275\n",
      "MAE Score: 0.6508\n",
      "\n",
      "Trial 15/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7064 | Final Val Loss: 1.8359\n",
      "R2 Score: 0.5043\n",
      "MSE Score: 0.6582\n",
      "MAE Score: 0.6103\n",
      "New best R2 score!\n",
      "\n",
      "Trial 16/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8558 | Final Val Loss: 2.9657\n",
      "R2 Score: 0.1539\n",
      "MSE Score: 1.1236\n",
      "MAE Score: 0.7642\n",
      "\n",
      "Trial 17/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8816 | Final Val Loss: 1.0108\n",
      "R2 Score: 0.4338\n",
      "MSE Score: 0.7519\n",
      "MAE Score: 0.7642\n",
      "\n",
      "Trial 18/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8250 | Final Val Loss: 0.8849\n",
      "R2 Score: 0.4974\n",
      "MSE Score: 0.6674\n",
      "MAE Score: 0.7048\n",
      "\n",
      "Trial 19/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.1285 | Final Val Loss: 9.0949\n",
      "R2 Score: -2.6355\n",
      "MSE Score: 4.8279\n",
      "MAE Score: 2.0210\n",
      "\n",
      "Trial 20/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9449 | Final Val Loss: 11.4634\n",
      "R2 Score: -3.8567\n",
      "MSE Score: 6.4495\n",
      "MAE Score: 2.3866\n",
      "\n",
      "Trial 21/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0435 | Final Val Loss: 0.9004\n",
      "R2 Score: 0.5343\n",
      "MSE Score: 0.6184\n",
      "MAE Score: 0.6353\n",
      "New best R2 score!\n",
      "\n",
      "Trial 22/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0994 | Final Val Loss: 1.0605\n",
      "R2 Score: 0.5555\n",
      "MSE Score: 0.5902\n",
      "MAE Score: 0.6345\n",
      "New best R2 score!\n",
      "\n",
      "Trial 23/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.0927 | Final Val Loss: 12.3545\n",
      "R2 Score: -4.4953\n",
      "MSE Score: 7.2976\n",
      "MAE Score: 2.5865\n",
      "\n",
      "Trial 24/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.3023 | Final Val Loss: 13.1377\n",
      "R2 Score: -4.8898\n",
      "MSE Score: 7.8214\n",
      "MAE Score: 2.6525\n",
      "\n",
      "Trial 25/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0356 | Final Val Loss: 0.9192\n",
      "R2 Score: 0.6203\n",
      "MSE Score: 0.5043\n",
      "MAE Score: 0.6064\n",
      "New best R2 score!\n",
      "\n",
      "Trial 26/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7077 | Final Val Loss: 1.1133\n",
      "R2 Score: 0.5081\n",
      "MSE Score: 0.6532\n",
      "MAE Score: 0.6660\n",
      "\n",
      "Trial 27/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8262 | Final Val Loss: 0.8789\n",
      "R2 Score: 0.5621\n",
      "MSE Score: 0.5815\n",
      "MAE Score: 0.6646\n",
      "\n",
      "Trial 28/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8546 | Final Val Loss: 1.6474\n",
      "R2 Score: 0.6181\n",
      "MSE Score: 0.5071\n",
      "MAE Score: 0.6208\n",
      "\n",
      "Trial 29/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9495 | Final Val Loss: 1.1476\n",
      "R2 Score: 0.6308\n",
      "MSE Score: 0.4903\n",
      "MAE Score: 0.5604\n",
      "New best R2 score!\n",
      "\n",
      "Trial 30/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8928 | Final Val Loss: 1.1724\n",
      "R2 Score: 0.5382\n",
      "MSE Score: 0.6132\n",
      "MAE Score: 0.6328\n",
      "\n",
      "Trial 31/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2057 | Final Val Loss: 1.4508\n",
      "R2 Score: 0.5855\n",
      "MSE Score: 0.5504\n",
      "MAE Score: 0.6009\n",
      "\n",
      "Trial 32/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3429 | Final Val Loss: 1.6397\n",
      "R2 Score: 0.5407\n",
      "MSE Score: 0.6100\n",
      "MAE Score: 0.6682\n",
      "\n",
      "Trial 33/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1164 | Final Val Loss: 1.8101\n",
      "R2 Score: 0.5068\n",
      "MSE Score: 0.6550\n",
      "MAE Score: 0.5791\n",
      "\n",
      "Trial 34/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6748 | Final Val Loss: 2.9487\n",
      "R2 Score: 0.1232\n",
      "MSE Score: 1.1643\n",
      "MAE Score: 0.7597\n",
      "\n",
      "Trial 35/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.1046 | Final Val Loss: 15.0930\n",
      "R2 Score: -6.0166\n",
      "MSE Score: 9.3178\n",
      "MAE Score: 2.8884\n",
      "\n",
      "Trial 36/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5647 | Final Val Loss: 12.1144\n",
      "R2 Score: -4.1219\n",
      "MSE Score: 6.8018\n",
      "MAE Score: 2.3825\n",
      "\n",
      "Trial 37/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.4287 | Final Val Loss: 2.0493\n",
      "R2 Score: 0.3191\n",
      "MSE Score: 0.9042\n",
      "MAE Score: 0.7520\n",
      "\n",
      "Trial 38/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7104 | Final Val Loss: 1.4883\n",
      "R2 Score: 0.5241\n",
      "MSE Score: 0.6319\n",
      "MAE Score: 0.5847\n",
      "\n",
      "Trial 39/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9313 | Final Val Loss: 13.0071\n",
      "R2 Score: -4.3889\n",
      "MSE Score: 7.1563\n",
      "MAE Score: 2.4397\n",
      "\n",
      "Trial 40/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.1740 | Final Val Loss: 15.7042\n",
      "R2 Score: -5.9341\n",
      "MSE Score: 9.2083\n",
      "MAE Score: 2.8027\n",
      "\n",
      "Trial 41/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5371 | Final Val Loss: 1.4482\n",
      "R2 Score: 0.4766\n",
      "MSE Score: 0.6951\n",
      "MAE Score: 0.5446\n",
      "\n",
      "Trial 42/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3120 | Final Val Loss: 1.2788\n",
      "R2 Score: 0.5378\n",
      "MSE Score: 0.6138\n",
      "MAE Score: 0.5523\n",
      "\n",
      "Trial 43/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4372 | Final Val Loss: 1.9358\n",
      "R2 Score: 0.4689\n",
      "MSE Score: 0.7052\n",
      "MAE Score: 0.6522\n",
      "\n",
      "Trial 44/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0783 | Final Val Loss: 1.7557\n",
      "R2 Score: 0.4458\n",
      "MSE Score: 0.7359\n",
      "MAE Score: 0.6225\n",
      "\n",
      "Trial 45/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1144 | Final Val Loss: 1.1559\n",
      "R2 Score: 0.4005\n",
      "MSE Score: 0.7961\n",
      "MAE Score: 0.6682\n",
      "\n",
      "Trial 46/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0210 | Final Val Loss: 1.1804\n",
      "R2 Score: 0.5559\n",
      "MSE Score: 0.5898\n",
      "MAE Score: 0.5906\n",
      "\n",
      "Trial 47/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5991 | Final Val Loss: 2.9689\n",
      "R2 Score: 0.2121\n",
      "MSE Score: 1.0463\n",
      "MAE Score: 0.8261\n",
      "\n",
      "Trial 48/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8605 | Final Val Loss: 2.0963\n",
      "R2 Score: 0.2956\n",
      "MSE Score: 0.9354\n",
      "MAE Score: 0.6858\n",
      "\n",
      "Trial 49/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1186 | Final Val Loss: 0.7770\n",
      "R2 Score: 0.4964\n",
      "MSE Score: 0.6687\n",
      "MAE Score: 0.6736\n",
      "\n",
      "Trial 50/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0792 | Final Val Loss: 0.8180\n",
      "R2 Score: 0.4100\n",
      "MSE Score: 0.7835\n",
      "MAE Score: 0.7344\n",
      "\n",
      "Trial 51/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.9718 | Final Val Loss: 11.7447\n",
      "R2 Score: -4.1455\n",
      "MSE Score: 6.8331\n",
      "MAE Score: 2.4739\n",
      "\n",
      "Trial 52/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.0343 | Final Val Loss: 11.2659\n",
      "R2 Score: -4.1108\n",
      "MSE Score: 6.7869\n",
      "MAE Score: 2.4899\n",
      "\n",
      "Trial 53/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2899 | Final Val Loss: 1.0055\n",
      "R2 Score: 0.6359\n",
      "MSE Score: 0.4835\n",
      "MAE Score: 0.5435\n",
      "New best R2 score!\n",
      "\n",
      "Trial 54/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2445 | Final Val Loss: 1.4943\n",
      "R2 Score: 0.6093\n",
      "MSE Score: 0.5189\n",
      "MAE Score: 0.5770\n",
      "\n",
      "Trial 55/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.8332 | Final Val Loss: 9.8987\n",
      "R2 Score: -3.1404\n",
      "MSE Score: 5.4983\n",
      "MAE Score: 2.1911\n",
      "\n",
      "Trial 56/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.2055 | Final Val Loss: 10.9547\n",
      "R2 Score: -3.5015\n",
      "MSE Score: 5.9778\n",
      "MAE Score: 2.2712\n",
      "\n",
      "Trial 57/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7635 | Final Val Loss: 1.0405\n",
      "R2 Score: 0.6183\n",
      "MSE Score: 0.5069\n",
      "MAE Score: 0.6022\n",
      "\n",
      "Trial 58/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8601 | Final Val Loss: 0.9566\n",
      "R2 Score: 0.5587\n",
      "MSE Score: 0.5860\n",
      "MAE Score: 0.6541\n",
      "\n",
      "Trial 59/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1676 | Final Val Loss: 1.3402\n",
      "R2 Score: 0.5265\n",
      "MSE Score: 0.6288\n",
      "MAE Score: 0.6692\n",
      "\n",
      "Trial 60/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1243 | Final Val Loss: 2.3023\n",
      "R2 Score: 0.3984\n",
      "MSE Score: 0.7990\n",
      "MAE Score: 0.7501\n",
      "\n",
      "Trial 61/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8748 | Final Val Loss: 0.8552\n",
      "R2 Score: 0.5375\n",
      "MSE Score: 0.6141\n",
      "MAE Score: 0.6556\n",
      "\n",
      "Trial 62/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1637 | Final Val Loss: 0.7996\n",
      "R2 Score: 0.4956\n",
      "MSE Score: 0.6698\n",
      "MAE Score: 0.6903\n",
      "\n",
      "Trial 63/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2464 | Final Val Loss: 1.2018\n",
      "R2 Score: 0.5514\n",
      "MSE Score: 0.5957\n",
      "MAE Score: 0.6597\n",
      "\n",
      "Trial 64/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9220 | Final Val Loss: 0.8765\n",
      "R2 Score: 0.5341\n",
      "MSE Score: 0.6187\n",
      "MAE Score: 0.6598\n",
      "\n",
      "Trial 65/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5269 | Final Val Loss: 1.8722\n",
      "R2 Score: 0.5564\n",
      "MSE Score: 0.5891\n",
      "MAE Score: 0.5276\n",
      "\n",
      "Trial 66/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6873 | Final Val Loss: 1.3740\n",
      "R2 Score: 0.5627\n",
      "MSE Score: 0.5807\n",
      "MAE Score: 0.5374\n",
      "\n",
      "Trial 67/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.1306 | Final Val Loss: 13.1690\n",
      "R2 Score: -4.6538\n",
      "MSE Score: 7.5080\n",
      "MAE Score: 2.5524\n",
      "\n",
      "Trial 68/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8207 | Final Val Loss: 11.9135\n",
      "R2 Score: -4.0028\n",
      "MSE Score: 6.6436\n",
      "MAE Score: 2.3628\n",
      "\n",
      "Trial 69/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.9884 | Final Val Loss: 2.3820\n",
      "R2 Score: 0.2757\n",
      "MSE Score: 0.9619\n",
      "MAE Score: 0.7065\n",
      "\n",
      "Trial 70/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.9657 | Final Val Loss: 1.5289\n",
      "R2 Score: 0.4120\n",
      "MSE Score: 0.7808\n",
      "MAE Score: 0.5813\n",
      "\n",
      "Trial 71/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3873 | Final Val Loss: 13.6291\n",
      "R2 Score: -4.7219\n",
      "MSE Score: 7.5985\n",
      "MAE Score: 2.5705\n",
      "\n",
      "Trial 72/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.0208 | Final Val Loss: 12.3510\n",
      "R2 Score: -4.2059\n",
      "MSE Score: 6.9133\n",
      "MAE Score: 2.3349\n",
      "\n",
      "Trial 73/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7438 | Final Val Loss: 1.6893\n",
      "R2 Score: 0.4648\n",
      "MSE Score: 0.7108\n",
      "MAE Score: 0.5703\n",
      "\n",
      "Trial 74/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5116 | Final Val Loss: 1.5561\n",
      "R2 Score: 0.5038\n",
      "MSE Score: 0.6589\n",
      "MAE Score: 0.5449\n",
      "\n",
      "Trial 75/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1902 | Final Val Loss: 2.2362\n",
      "R2 Score: 0.2560\n",
      "MSE Score: 0.9879\n",
      "MAE Score: 0.6957\n",
      "\n",
      "Trial 76/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6537 | Final Val Loss: 3.4224\n",
      "R2 Score: 0.0316\n",
      "MSE Score: 1.2859\n",
      "MAE Score: 0.7739\n",
      "\n",
      "Trial 77/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6055 | Final Val Loss: 1.4574\n",
      "R2 Score: 0.4324\n",
      "MSE Score: 0.7537\n",
      "MAE Score: 0.6033\n",
      "\n",
      "Trial 78/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2865 | Final Val Loss: 1.3563\n",
      "R2 Score: 0.4909\n",
      "MSE Score: 0.6761\n",
      "MAE Score: 0.5811\n",
      "\n",
      "Trial 79/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6500 | Final Val Loss: 1.6356\n",
      "R2 Score: 0.5652\n",
      "MSE Score: 0.5774\n",
      "MAE Score: 0.4968\n",
      "\n",
      "Trial 80/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.9627 | Final Val Loss: 1.8241\n",
      "R2 Score: 0.4210\n",
      "MSE Score: 0.7688\n",
      "MAE Score: 0.6005\n",
      "\n",
      "Trial 81/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1010 | Final Val Loss: 0.9730\n",
      "R2 Score: 0.4804\n",
      "MSE Score: 0.6900\n",
      "MAE Score: 0.6002\n",
      "\n",
      "Trial 82/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5915 | Final Val Loss: 1.8210\n",
      "R2 Score: 0.3993\n",
      "MSE Score: 0.7977\n",
      "MAE Score: 0.7206\n",
      "\n",
      "Trial 83/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.6341 | Final Val Loss: 11.5542\n",
      "R2 Score: -3.7590\n",
      "MSE Score: 6.3199\n",
      "MAE Score: 2.3815\n",
      "\n",
      "Trial 84/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.3676 | Final Val Loss: 13.9308\n",
      "R2 Score: -5.6097\n",
      "MSE Score: 8.7775\n",
      "MAE Score: 2.8571\n",
      "\n",
      "Trial 85/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5497 | Final Val Loss: 1.2066\n",
      "R2 Score: 0.5077\n",
      "MSE Score: 0.6537\n",
      "MAE Score: 0.7019\n",
      "\n",
      "Trial 86/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8614 | Final Val Loss: 0.7613\n",
      "R2 Score: 0.4545\n",
      "MSE Score: 0.7244\n",
      "MAE Score: 0.7335\n",
      "\n",
      "Trial 87/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.3016 | Final Val Loss: 13.9011\n",
      "R2 Score: -5.2809\n",
      "MSE Score: 8.3408\n",
      "MAE Score: 2.7584\n",
      "\n",
      "Trial 88/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.6855 | Final Val Loss: 9.5366\n",
      "R2 Score: -3.0690\n",
      "MSE Score: 5.4035\n",
      "MAE Score: 2.1906\n",
      "\n",
      "Trial 89/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8747 | Final Val Loss: 0.7639\n",
      "R2 Score: 0.5139\n",
      "MSE Score: 0.6455\n",
      "MAE Score: 0.6949\n",
      "\n",
      "Trial 90/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2099 | Final Val Loss: 1.1038\n",
      "R2 Score: 0.5812\n",
      "MSE Score: 0.5561\n",
      "MAE Score: 0.6308\n",
      "\n",
      "Trial 91/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8218 | Final Val Loss: 2.2227\n",
      "R2 Score: 0.3705\n",
      "MSE Score: 0.8359\n",
      "MAE Score: 0.6769\n",
      "\n",
      "Trial 92/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9992 | Final Val Loss: 1.2288\n",
      "R2 Score: 0.5618\n",
      "MSE Score: 0.5819\n",
      "MAE Score: 0.6470\n",
      "\n",
      "Trial 93/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3094 | Final Val Loss: 1.0935\n",
      "R2 Score: 0.5302\n",
      "MSE Score: 0.6238\n",
      "MAE Score: 0.6585\n",
      "\n",
      "Trial 94/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0320 | Final Val Loss: 0.9431\n",
      "R2 Score: 0.4501\n",
      "MSE Score: 0.7302\n",
      "MAE Score: 0.7351\n",
      "\n",
      "Trial 95/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0540 | Final Val Loss: 1.2816\n",
      "R2 Score: 0.6225\n",
      "MSE Score: 0.5013\n",
      "MAE Score: 0.6075\n",
      "\n",
      "Trial 96/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4917 | Final Val Loss: 1.8139\n",
      "R2 Score: 0.4697\n",
      "MSE Score: 0.7042\n",
      "MAE Score: 0.6809\n",
      "\n",
      "Trial 97/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6429 | Final Val Loss: 2.9954\n",
      "R2 Score: 0.1289\n",
      "MSE Score: 1.1568\n",
      "MAE Score: 0.8075\n",
      "\n",
      "Trial 98/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.0109 | Final Val Loss: 2.3325\n",
      "R2 Score: 0.3561\n",
      "MSE Score: 0.8551\n",
      "MAE Score: 0.6651\n",
      "\n",
      "Trial 99/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.3112 | Final Val Loss: 13.4986\n",
      "R2 Score: -4.8474\n",
      "MSE Score: 7.7651\n",
      "MAE Score: 2.5808\n",
      "\n",
      "Trial 100/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.3212 | Final Val Loss: 11.7467\n",
      "R2 Score: -3.8138\n",
      "MSE Score: 6.3925\n",
      "MAE Score: 2.3006\n",
      "\n",
      "Trial 101/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5163 | Final Val Loss: 2.5498\n",
      "R2 Score: 0.1457\n",
      "MSE Score: 1.1344\n",
      "MAE Score: 0.9019\n",
      "\n",
      "Trial 102/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7440 | Final Val Loss: 1.8428\n",
      "R2 Score: 0.3649\n",
      "MSE Score: 0.8434\n",
      "MAE Score: 0.6637\n",
      "\n",
      "Trial 103/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.4055 | Final Val Loss: 11.7820\n",
      "R2 Score: -3.8466\n",
      "MSE Score: 6.4362\n",
      "MAE Score: 2.2739\n",
      "\n",
      "Trial 104/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.3732 | Final Val Loss: 12.2542\n",
      "R2 Score: -4.3269\n",
      "MSE Score: 7.0739\n",
      "MAE Score: 2.3699\n",
      "\n",
      "Trial 105/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0745 | Final Val Loss: 1.8099\n",
      "R2 Score: 0.4331\n",
      "MSE Score: 0.7528\n",
      "MAE Score: 0.6210\n",
      "\n",
      "Trial 106/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3744 | Final Val Loss: 1.4875\n",
      "R2 Score: 0.5287\n",
      "MSE Score: 0.6258\n",
      "MAE Score: 0.5153\n",
      "\n",
      "Trial 107/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7048 | Final Val Loss: 2.5695\n",
      "R2 Score: 0.2627\n",
      "MSE Score: 0.9791\n",
      "MAE Score: 0.7844\n",
      "\n",
      "Trial 108/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6857 | Final Val Loss: 3.4723\n",
      "R2 Score: -0.1856\n",
      "MSE Score: 1.5744\n",
      "MAE Score: 0.9944\n",
      "\n",
      "Trial 109/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4006 | Final Val Loss: 1.5845\n",
      "R2 Score: 0.3876\n",
      "MSE Score: 0.8133\n",
      "MAE Score: 0.6782\n",
      "\n",
      "Trial 110/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5082 | Final Val Loss: 1.3411\n",
      "R2 Score: 0.3403\n",
      "MSE Score: 0.8761\n",
      "MAE Score: 0.6801\n",
      "\n",
      "Trial 111/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.5190 | Final Val Loss: 2.1316\n",
      "R2 Score: 0.3488\n",
      "MSE Score: 0.8648\n",
      "MAE Score: 0.6116\n",
      "\n",
      "Trial 112/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2640 | Final Val Loss: 2.0417\n",
      "R2 Score: 0.4172\n",
      "MSE Score: 0.7740\n",
      "MAE Score: 0.6452\n",
      "\n",
      "Trial 113/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2440 | Final Val Loss: 1.1388\n",
      "R2 Score: 0.5073\n",
      "MSE Score: 0.6543\n",
      "MAE Score: 0.6357\n",
      "\n",
      "Trial 114/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0830 | Final Val Loss: 0.9834\n",
      "R2 Score: 0.6151\n",
      "MSE Score: 0.5111\n",
      "MAE Score: 0.5738\n",
      "\n",
      "Trial 115/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.5210 | Final Val Loss: 9.6987\n",
      "R2 Score: -2.9554\n",
      "MSE Score: 5.2527\n",
      "MAE Score: 2.1408\n",
      "\n",
      "Trial 116/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.6756 | Final Val Loss: 13.4992\n",
      "R2 Score: -5.1818\n",
      "MSE Score: 8.2092\n",
      "MAE Score: 2.7364\n",
      "\n",
      "Trial 117/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2536 | Final Val Loss: 1.0406\n",
      "R2 Score: 0.5908\n",
      "MSE Score: 0.5435\n",
      "MAE Score: 0.5897\n",
      "\n",
      "Trial 118/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1183 | Final Val Loss: 0.9167\n",
      "R2 Score: 0.5003\n",
      "MSE Score: 0.6635\n",
      "MAE Score: 0.6847\n",
      "\n",
      "Trial 119/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7999 | Final Val Loss: 12.2775\n",
      "R2 Score: -4.2395\n",
      "MSE Score: 6.9579\n",
      "MAE Score: 2.4958\n",
      "\n",
      "Trial 120/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.4613 | Final Val Loss: 12.8976\n",
      "R2 Score: -4.7668\n",
      "MSE Score: 7.6581\n",
      "MAE Score: 2.6217\n",
      "\n",
      "Trial 121/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9545 | Final Val Loss: 0.9801\n",
      "R2 Score: 0.5737\n",
      "MSE Score: 0.5661\n",
      "MAE Score: 0.6294\n",
      "\n",
      "Trial 122/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9264 | Final Val Loss: 0.8047\n",
      "R2 Score: 0.5245\n",
      "MSE Score: 0.6314\n",
      "MAE Score: 0.6805\n",
      "\n",
      "Trial 123/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0743 | Final Val Loss: 1.5693\n",
      "R2 Score: 0.5245\n",
      "MSE Score: 0.6314\n",
      "MAE Score: 0.6577\n",
      "\n",
      "Trial 124/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3893 | Final Val Loss: 2.0271\n",
      "R2 Score: 0.5681\n",
      "MSE Score: 0.5736\n",
      "MAE Score: 0.5917\n",
      "\n",
      "Trial 125/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8376 | Final Val Loss: 0.9605\n",
      "R2 Score: 0.4853\n",
      "MSE Score: 0.6835\n",
      "MAE Score: 0.7222\n",
      "\n",
      "Trial 126/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8048 | Final Val Loss: 0.8556\n",
      "R2 Score: 0.5376\n",
      "MSE Score: 0.6140\n",
      "MAE Score: 0.6597\n",
      "\n",
      "Trial 127/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2966 | Final Val Loss: 1.5715\n",
      "R2 Score: 0.5854\n",
      "MSE Score: 0.5505\n",
      "MAE Score: 0.6091\n",
      "\n",
      "Trial 128/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1669 | Final Val Loss: 1.6802\n",
      "R2 Score: 0.5060\n",
      "MSE Score: 0.6561\n",
      "MAE Score: 0.6432\n",
      "\n",
      "Trial 129/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7968 | Final Val Loss: 2.1378\n",
      "R2 Score: 0.2727\n",
      "MSE Score: 0.9658\n",
      "MAE Score: 0.7460\n",
      "\n",
      "Trial 130/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3761 | Final Val Loss: 1.4459\n",
      "R2 Score: 0.5629\n",
      "MSE Score: 0.5804\n",
      "MAE Score: 0.6194\n",
      "\n",
      "Trial 131/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2927 | Final Val Loss: 9.5425\n",
      "R2 Score: -2.8325\n",
      "MSE Score: 5.0895\n",
      "MAE Score: 2.0343\n",
      "\n",
      "Trial 132/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5492 | Final Val Loss: 11.5696\n",
      "R2 Score: -3.9103\n",
      "MSE Score: 6.5208\n",
      "MAE Score: 2.3535\n",
      "\n",
      "Trial 133/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.9659 | Final Val Loss: 1.7201\n",
      "R2 Score: 0.5340\n",
      "MSE Score: 0.6188\n",
      "MAE Score: 0.5190\n",
      "\n",
      "Trial 134/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1093 | Final Val Loss: 1.7274\n",
      "R2 Score: 0.3902\n",
      "MSE Score: 0.8098\n",
      "MAE Score: 0.6459\n",
      "\n",
      "Trial 135/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.7668 | Final Val Loss: 10.5800\n",
      "R2 Score: -3.3427\n",
      "MSE Score: 5.7669\n",
      "MAE Score: 2.2002\n",
      "\n",
      "Trial 136/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.4674 | Final Val Loss: 12.7062\n",
      "R2 Score: -4.4294\n",
      "MSE Score: 7.2101\n",
      "MAE Score: 2.4454\n",
      "\n",
      "Trial 137/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0464 | Final Val Loss: 2.0851\n",
      "R2 Score: 0.3941\n",
      "MSE Score: 0.8047\n",
      "MAE Score: 0.6217\n",
      "\n",
      "Trial 138/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4510 | Final Val Loss: 2.0717\n",
      "R2 Score: 0.2893\n",
      "MSE Score: 0.9437\n",
      "MAE Score: 0.6533\n",
      "\n",
      "Trial 139/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1330 | Final Val Loss: 1.9334\n",
      "R2 Score: 0.3925\n",
      "MSE Score: 0.8068\n",
      "MAE Score: 0.6297\n",
      "\n",
      "Trial 140/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2984 | Final Val Loss: 1.9879\n",
      "R2 Score: 0.3376\n",
      "MSE Score: 0.8796\n",
      "MAE Score: 0.6707\n",
      "\n",
      "Trial 141/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4353 | Final Val Loss: 2.1050\n",
      "R2 Score: 0.3604\n",
      "MSE Score: 0.8494\n",
      "MAE Score: 0.6640\n",
      "\n",
      "Trial 142/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2686 | Final Val Loss: 1.5147\n",
      "R2 Score: 0.4721\n",
      "MSE Score: 0.7010\n",
      "MAE Score: 0.6182\n",
      "\n",
      "Trial 143/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8423 | Final Val Loss: 2.8175\n",
      "R2 Score: 0.1605\n",
      "MSE Score: 1.1149\n",
      "MAE Score: 0.7702\n",
      "\n",
      "Trial 144/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.1764 | Final Val Loss: 3.8680\n",
      "R2 Score: -0.2262\n",
      "MSE Score: 1.6284\n",
      "MAE Score: 0.9833\n",
      "\n",
      "Trial 145/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7525 | Final Val Loss: 0.8152\n",
      "R2 Score: 0.5087\n",
      "MSE Score: 0.6524\n",
      "MAE Score: 0.6805\n",
      "\n",
      "Trial 146/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9927 | Final Val Loss: 0.9713\n",
      "R2 Score: 0.4979\n",
      "MSE Score: 0.6668\n",
      "MAE Score: 0.6580\n",
      "\n",
      "Trial 147/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.4952 | Final Val Loss: 10.2837\n",
      "R2 Score: -3.3158\n",
      "MSE Score: 5.7313\n",
      "MAE Score: 2.2474\n",
      "\n",
      "Trial 148/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.9654 | Final Val Loss: 13.0602\n",
      "R2 Score: -4.7997\n",
      "MSE Score: 7.7017\n",
      "MAE Score: 2.6630\n",
      "\n",
      "Trial 149/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1228 | Final Val Loss: 0.9764\n",
      "R2 Score: 0.4669\n",
      "MSE Score: 0.7079\n",
      "MAE Score: 0.6943\n",
      "\n",
      "Trial 150/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0809 | Final Val Loss: 1.1291\n",
      "R2 Score: 0.5408\n",
      "MSE Score: 0.6098\n",
      "MAE Score: 0.6419\n",
      "\n",
      "Trial 151/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.0333 | Final Val Loss: 11.5476\n",
      "R2 Score: -3.9019\n",
      "MSE Score: 6.5096\n",
      "MAE Score: 2.3918\n",
      "\n",
      "Trial 152/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2733 | Final Val Loss: 10.3837\n",
      "R2 Score: -3.4419\n",
      "MSE Score: 5.8987\n",
      "MAE Score: 2.2665\n",
      "\n",
      "Trial 153/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6839 | Final Val Loss: 0.7943\n",
      "R2 Score: 0.5508\n",
      "MSE Score: 0.5965\n",
      "MAE Score: 0.6098\n",
      "\n",
      "Trial 154/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7964 | Final Val Loss: 1.2248\n",
      "R2 Score: 0.5658\n",
      "MSE Score: 0.5765\n",
      "MAE Score: 0.6012\n",
      "\n",
      "Trial 155/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8466 | Final Val Loss: 1.3189\n",
      "R2 Score: 0.6046\n",
      "MSE Score: 0.5251\n",
      "MAE Score: 0.5972\n",
      "\n",
      "Trial 156/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9664 | Final Val Loss: 1.3161\n",
      "R2 Score: 0.6552\n",
      "MSE Score: 0.4579\n",
      "MAE Score: 0.5479\n",
      "New best R2 score!\n",
      "\n",
      "Trial 157/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9058 | Final Val Loss: 1.0183\n",
      "R2 Score: 0.5930\n",
      "MSE Score: 0.5405\n",
      "MAE Score: 0.5791\n",
      "\n",
      "Trial 158/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8578 | Final Val Loss: 0.8551\n",
      "R2 Score: 0.4889\n",
      "MSE Score: 0.6787\n",
      "MAE Score: 0.6926\n",
      "\n",
      "Trial 159/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3053 | Final Val Loss: 1.2469\n",
      "R2 Score: 0.6355\n",
      "MSE Score: 0.4841\n",
      "MAE Score: 0.5905\n",
      "\n",
      "Trial 160/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4113 | Final Val Loss: 1.7159\n",
      "R2 Score: 0.4680\n",
      "MSE Score: 0.7065\n",
      "MAE Score: 0.7050\n",
      "\n",
      "Trial 161/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1415 | Final Val Loss: 1.7797\n",
      "R2 Score: 0.3128\n",
      "MSE Score: 0.9126\n",
      "MAE Score: 0.7469\n",
      "\n",
      "Trial 162/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2085 | Final Val Loss: 1.7240\n",
      "R2 Score: 0.3940\n",
      "MSE Score: 0.8047\n",
      "MAE Score: 0.6842\n",
      "\n",
      "Trial 163/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.7188 | Final Val Loss: 12.1094\n",
      "R2 Score: -4.0723\n",
      "MSE Score: 6.7358\n",
      "MAE Score: 2.3501\n",
      "\n",
      "Trial 164/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2688 | Final Val Loss: 11.1101\n",
      "R2 Score: -3.5569\n",
      "MSE Score: 6.0514\n",
      "MAE Score: 2.2305\n",
      "\n",
      "Trial 165/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8724 | Final Val Loss: 2.9334\n",
      "R2 Score: 0.0761\n",
      "MSE Score: 1.2269\n",
      "MAE Score: 0.7837\n",
      "\n",
      "Trial 166/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.3830 | Final Val Loss: 1.7414\n",
      "R2 Score: 0.2973\n",
      "MSE Score: 0.9331\n",
      "MAE Score: 0.7333\n",
      "\n",
      "Trial 167/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.5956 | Final Val Loss: 13.2933\n",
      "R2 Score: -4.6715\n",
      "MSE Score: 7.5316\n",
      "MAE Score: 2.5270\n",
      "\n",
      "Trial 168/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3969 | Final Val Loss: 13.7900\n",
      "R2 Score: -5.0155\n",
      "MSE Score: 7.9884\n",
      "MAE Score: 2.6458\n",
      "\n",
      "Trial 169/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3948 | Final Val Loss: 1.3922\n",
      "R2 Score: 0.4313\n",
      "MSE Score: 0.7552\n",
      "MAE Score: 0.5791\n",
      "\n",
      "Trial 170/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5125 | Final Val Loss: 1.5332\n",
      "R2 Score: 0.4270\n",
      "MSE Score: 0.7610\n",
      "MAE Score: 0.6149\n",
      "\n",
      "Trial 171/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6846 | Final Val Loss: 1.4945\n",
      "R2 Score: 0.3141\n",
      "MSE Score: 0.9109\n",
      "MAE Score: 0.7209\n",
      "\n",
      "Trial 172/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3382 | Final Val Loss: 2.1577\n",
      "R2 Score: 0.4975\n",
      "MSE Score: 0.6673\n",
      "MAE Score: 0.5807\n",
      "\n",
      "Trial 173/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5101 | Final Val Loss: 1.8643\n",
      "R2 Score: 0.4401\n",
      "MSE Score: 0.7436\n",
      "MAE Score: 0.6193\n",
      "\n",
      "Trial 174/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6907 | Final Val Loss: 1.4212\n",
      "R2 Score: 0.4756\n",
      "MSE Score: 0.6964\n",
      "MAE Score: 0.6062\n",
      "\n",
      "Trial 175/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7664 | Final Val Loss: 2.7599\n",
      "R2 Score: 0.1762\n",
      "MSE Score: 1.0940\n",
      "MAE Score: 0.7602\n",
      "\n",
      "Trial 176/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3451 | Final Val Loss: 2.3055\n",
      "R2 Score: 0.4610\n",
      "MSE Score: 0.7157\n",
      "MAE Score: 0.6183\n",
      "\n",
      "Trial 177/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0958 | Final Val Loss: 0.9734\n",
      "R2 Score: 0.5834\n",
      "MSE Score: 0.5532\n",
      "MAE Score: 0.6352\n",
      "\n",
      "Trial 178/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9186 | Final Val Loss: 0.9455\n",
      "R2 Score: 0.5565\n",
      "MSE Score: 0.5889\n",
      "MAE Score: 0.6266\n",
      "\n",
      "Trial 179/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.4455 | Final Val Loss: 13.0850\n",
      "R2 Score: -5.0048\n",
      "MSE Score: 7.9741\n",
      "MAE Score: 2.7019\n",
      "\n",
      "Trial 180/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.3830 | Final Val Loss: 10.0400\n",
      "R2 Score: -3.0591\n",
      "MSE Score: 5.3903\n",
      "MAE Score: 2.1535\n",
      "\n",
      "Trial 181/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4550 | Final Val Loss: 0.8451\n",
      "R2 Score: 0.4459\n",
      "MSE Score: 0.7358\n",
      "MAE Score: 0.7243\n",
      "\n",
      "Trial 182/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1261 | Final Val Loss: 1.0249\n",
      "R2 Score: 0.5715\n",
      "MSE Score: 0.5690\n",
      "MAE Score: 0.6234\n",
      "\n",
      "Trial 183/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.1103 | Final Val Loss: 9.9892\n",
      "R2 Score: -2.9992\n",
      "MSE Score: 5.3109\n",
      "MAE Score: 2.1314\n",
      "\n",
      "Trial 184/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.0346 | Final Val Loss: 9.5692\n",
      "R2 Score: -3.3198\n",
      "MSE Score: 5.7365\n",
      "MAE Score: 2.2742\n",
      "\n",
      "Trial 185/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6990 | Final Val Loss: 1.0964\n",
      "R2 Score: 0.6406\n",
      "MSE Score: 0.4772\n",
      "MAE Score: 0.5454\n",
      "\n",
      "Trial 186/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8337 | Final Val Loss: 0.9415\n",
      "R2 Score: 0.5195\n",
      "MSE Score: 0.6381\n",
      "MAE Score: 0.6931\n",
      "\n",
      "Trial 187/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2579 | Final Val Loss: 1.2757\n",
      "R2 Score: 0.6199\n",
      "MSE Score: 0.5047\n",
      "MAE Score: 0.5954\n",
      "\n",
      "Trial 188/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1237 | Final Val Loss: 1.6842\n",
      "R2 Score: 0.5322\n",
      "MSE Score: 0.6212\n",
      "MAE Score: 0.6268\n",
      "\n",
      "Trial 189/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7698 | Final Val Loss: 1.2977\n",
      "R2 Score: 0.5528\n",
      "MSE Score: 0.5938\n",
      "MAE Score: 0.6413\n",
      "\n",
      "Trial 190/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2401 | Final Val Loss: 0.9047\n",
      "R2 Score: 0.5281\n",
      "MSE Score: 0.6267\n",
      "MAE Score: 0.6716\n",
      "\n",
      "Trial 191/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4170 | Final Val Loss: 1.8415\n",
      "R2 Score: 0.4654\n",
      "MSE Score: 0.7099\n",
      "MAE Score: 0.7084\n",
      "\n",
      "Trial 192/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2394 | Final Val Loss: 1.0569\n",
      "R2 Score: 0.6091\n",
      "MSE Score: 0.5191\n",
      "MAE Score: 0.6000\n",
      "\n",
      "Trial 193/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7227 | Final Val Loss: 1.6639\n",
      "R2 Score: 0.4676\n",
      "MSE Score: 0.7070\n",
      "MAE Score: 0.6430\n",
      "\n",
      "Trial 194/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8274 | Final Val Loss: 2.3888\n",
      "R2 Score: 0.3805\n",
      "MSE Score: 0.8227\n",
      "MAE Score: 0.6239\n",
      "\n",
      "Trial 195/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.4903 | Final Val Loss: 11.2470\n",
      "R2 Score: -3.7957\n",
      "MSE Score: 6.3685\n",
      "MAE Score: 2.2755\n",
      "\n",
      "Trial 196/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.0866 | Final Val Loss: 12.2479\n",
      "R2 Score: -4.0052\n",
      "MSE Score: 6.6467\n",
      "MAE Score: 2.3303\n",
      "\n",
      "Trial 197/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.3745 | Final Val Loss: 2.6351\n",
      "R2 Score: 0.2179\n",
      "MSE Score: 1.0386\n",
      "MAE Score: 0.7520\n",
      "\n",
      "Trial 198/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.0713 | Final Val Loss: 1.5547\n",
      "R2 Score: 0.2480\n",
      "MSE Score: 0.9987\n",
      "MAE Score: 0.8268\n",
      "\n",
      "Trial 199/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 12.9546 | Final Val Loss: 18.0985\n",
      "R2 Score: -7.2277\n",
      "MSE Score: 10.9261\n",
      "MAE Score: 3.1059\n",
      "\n",
      "Trial 200/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.2860 | Final Val Loss: 12.5408\n",
      "R2 Score: -4.3747\n",
      "MSE Score: 7.1374\n",
      "MAE Score: 2.4485\n",
      "\n",
      "Trial 201/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2886 | Final Val Loss: 1.8560\n",
      "R2 Score: 0.4603\n",
      "MSE Score: 0.7167\n",
      "MAE Score: 0.6229\n",
      "\n",
      "Trial 202/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2340 | Final Val Loss: 1.4185\n",
      "R2 Score: 0.5260\n",
      "MSE Score: 0.6294\n",
      "MAE Score: 0.5572\n",
      "\n",
      "Trial 203/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2582 | Final Val Loss: 2.1814\n",
      "R2 Score: 0.3306\n",
      "MSE Score: 0.8890\n",
      "MAE Score: 0.7244\n",
      "\n",
      "Trial 204/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5477 | Final Val Loss: 1.7842\n",
      "R2 Score: 0.5678\n",
      "MSE Score: 0.5740\n",
      "MAE Score: 0.5293\n",
      "\n",
      "Trial 205/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4877 | Final Val Loss: 1.7182\n",
      "R2 Score: 0.3702\n",
      "MSE Score: 0.8364\n",
      "MAE Score: 0.6053\n",
      "\n",
      "Trial 206/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6747 | Final Val Loss: 1.6255\n",
      "R2 Score: 0.3343\n",
      "MSE Score: 0.8840\n",
      "MAE Score: 0.6523\n",
      "\n",
      "Trial 207/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7608 | Final Val Loss: 1.3120\n",
      "R2 Score: 0.5313\n",
      "MSE Score: 0.6225\n",
      "MAE Score: 0.6225\n",
      "\n",
      "Trial 208/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.5849 | Final Val Loss: 4.4857\n",
      "R2 Score: -0.5926\n",
      "MSE Score: 2.1150\n",
      "MAE Score: 1.0926\n",
      "\n",
      "Trial 209/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9826 | Final Val Loss: 0.8179\n",
      "R2 Score: 0.5592\n",
      "MSE Score: 0.5854\n",
      "MAE Score: 0.6212\n",
      "\n",
      "Trial 210/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9799 | Final Val Loss: 0.9144\n",
      "R2 Score: 0.5126\n",
      "MSE Score: 0.6472\n",
      "MAE Score: 0.6899\n",
      "\n",
      "Trial 211/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.6448 | Final Val Loss: 10.6771\n",
      "R2 Score: -3.6323\n",
      "MSE Score: 6.1516\n",
      "MAE Score: 2.3336\n",
      "\n",
      "Trial 212/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.5107 | Final Val Loss: 9.9736\n",
      "R2 Score: -3.0795\n",
      "MSE Score: 5.4175\n",
      "MAE Score: 2.1557\n",
      "\n",
      "Trial 213/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2716 | Final Val Loss: 1.0259\n",
      "R2 Score: 0.6287\n",
      "MSE Score: 0.4931\n",
      "MAE Score: 0.5178\n",
      "\n",
      "Trial 214/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0062 | Final Val Loss: 1.0379\n",
      "R2 Score: 0.5700\n",
      "MSE Score: 0.5710\n",
      "MAE Score: 0.6245\n",
      "\n",
      "Trial 215/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3678 | Final Val Loss: 12.2228\n",
      "R2 Score: -4.2668\n",
      "MSE Score: 6.9941\n",
      "MAE Score: 2.5036\n",
      "\n",
      "Trial 216/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2802 | Final Val Loss: 10.0474\n",
      "R2 Score: -3.0898\n",
      "MSE Score: 5.4312\n",
      "MAE Score: 2.1848\n",
      "\n",
      "Trial 217/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0424 | Final Val Loss: 1.3785\n",
      "R2 Score: 0.5675\n",
      "MSE Score: 0.5744\n",
      "MAE Score: 0.5856\n",
      "\n",
      "Trial 218/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2333 | Final Val Loss: 0.9474\n",
      "R2 Score: 0.5084\n",
      "MSE Score: 0.6528\n",
      "MAE Score: 0.6757\n",
      "\n",
      "Trial 219/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9369 | Final Val Loss: 1.5954\n",
      "R2 Score: 0.5733\n",
      "MSE Score: 0.5666\n",
      "MAE Score: 0.6477\n",
      "\n",
      "Trial 220/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9093 | Final Val Loss: 1.1331\n",
      "R2 Score: 0.6671\n",
      "MSE Score: 0.4421\n",
      "MAE Score: 0.5105\n",
      "New best R2 score!\n",
      "\n",
      "Trial 221/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9605 | Final Val Loss: 0.8605\n",
      "R2 Score: 0.5930\n",
      "MSE Score: 0.5405\n",
      "MAE Score: 0.6033\n",
      "\n",
      "Trial 222/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8883 | Final Val Loss: 1.2719\n",
      "R2 Score: 0.5513\n",
      "MSE Score: 0.5959\n",
      "MAE Score: 0.6059\n",
      "\n",
      "Trial 223/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4635 | Final Val Loss: 1.5748\n",
      "R2 Score: 0.5167\n",
      "MSE Score: 0.6419\n",
      "MAE Score: 0.6555\n",
      "\n",
      "Trial 224/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9535 | Final Val Loss: 1.2012\n",
      "R2 Score: 0.6249\n",
      "MSE Score: 0.4981\n",
      "MAE Score: 0.5695\n",
      "\n",
      "Trial 225/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5356 | Final Val Loss: 2.2246\n",
      "R2 Score: 0.5033\n",
      "MSE Score: 0.6595\n",
      "MAE Score: 0.6242\n",
      "\n",
      "Trial 226/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2772 | Final Val Loss: 2.0989\n",
      "R2 Score: 0.3953\n",
      "MSE Score: 0.8030\n",
      "MAE Score: 0.6238\n",
      "\n",
      "Trial 227/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.2091 | Final Val Loss: 13.2743\n",
      "R2 Score: -4.5575\n",
      "MSE Score: 7.3802\n",
      "MAE Score: 2.4712\n",
      "\n",
      "Trial 228/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 5.8281 | Final Val Loss: 10.0872\n",
      "R2 Score: -3.1390\n",
      "MSE Score: 5.4964\n",
      "MAE Score: 2.0909\n",
      "\n",
      "Trial 229/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8224 | Final Val Loss: 2.8687\n",
      "R2 Score: 0.1027\n",
      "MSE Score: 1.1915\n",
      "MAE Score: 0.8062\n",
      "\n",
      "Trial 230/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6667 | Final Val Loss: 1.4131\n",
      "R2 Score: 0.5377\n",
      "MSE Score: 0.6139\n",
      "MAE Score: 0.5133\n",
      "\n",
      "Trial 231/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.6077 | Final Val Loss: 14.0432\n",
      "R2 Score: -4.9197\n",
      "MSE Score: 7.8612\n",
      "MAE Score: 2.5453\n",
      "\n",
      "Trial 232/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.3082 | Final Val Loss: 12.1141\n",
      "R2 Score: -4.0110\n",
      "MSE Score: 6.6544\n",
      "MAE Score: 2.3258\n",
      "\n",
      "Trial 233/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4080 | Final Val Loss: 1.6981\n",
      "R2 Score: 0.4567\n",
      "MSE Score: 0.7215\n",
      "MAE Score: 0.5717\n",
      "\n",
      "Trial 234/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5611 | Final Val Loss: 1.5379\n",
      "R2 Score: 0.4754\n",
      "MSE Score: 0.6967\n",
      "MAE Score: 0.5738\n",
      "\n",
      "Trial 235/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4764 | Final Val Loss: 3.3091\n",
      "R2 Score: 0.0162\n",
      "MSE Score: 1.3065\n",
      "MAE Score: 0.8605\n",
      "\n",
      "Trial 236/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5018 | Final Val Loss: 1.9733\n",
      "R2 Score: 0.5193\n",
      "MSE Score: 0.6383\n",
      "MAE Score: 0.5113\n",
      "\n",
      "Trial 237/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4664 | Final Val Loss: 1.5852\n",
      "R2 Score: 0.4685\n",
      "MSE Score: 0.7058\n",
      "MAE Score: 0.6499\n",
      "\n",
      "Trial 238/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5944 | Final Val Loss: 1.5822\n",
      "R2 Score: 0.4868\n",
      "MSE Score: 0.6815\n",
      "MAE Score: 0.6013\n",
      "\n",
      "Trial 239/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8320 | Final Val Loss: 2.0395\n",
      "R2 Score: 0.3663\n",
      "MSE Score: 0.8416\n",
      "MAE Score: 0.6615\n",
      "\n",
      "Trial 240/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6438 | Final Val Loss: 1.9374\n",
      "R2 Score: 0.4584\n",
      "MSE Score: 0.7192\n",
      "MAE Score: 0.5266\n",
      "\n",
      "Trial 241/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0501 | Final Val Loss: 1.0828\n",
      "R2 Score: 0.5132\n",
      "MSE Score: 0.6464\n",
      "MAE Score: 0.6655\n",
      "\n",
      "Trial 242/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8972 | Final Val Loss: 0.8772\n",
      "R2 Score: 0.5507\n",
      "MSE Score: 0.5967\n",
      "MAE Score: 0.6236\n",
      "\n",
      "Trial 243/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.8027 | Final Val Loss: 10.5121\n",
      "R2 Score: -3.3763\n",
      "MSE Score: 5.8116\n",
      "MAE Score: 2.2456\n",
      "\n",
      "Trial 244/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9149 | Final Val Loss: 9.9541\n",
      "R2 Score: -3.2235\n",
      "MSE Score: 5.6086\n",
      "MAE Score: 2.2215\n",
      "\n",
      "Trial 245/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3867 | Final Val Loss: 1.0035\n",
      "R2 Score: 0.5995\n",
      "MSE Score: 0.5318\n",
      "MAE Score: 0.5760\n",
      "\n",
      "Trial 246/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3488 | Final Val Loss: 1.0040\n",
      "R2 Score: 0.5888\n",
      "MSE Score: 0.5461\n",
      "MAE Score: 0.5576\n",
      "\n",
      "Trial 247/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3156 | Final Val Loss: 13.1332\n",
      "R2 Score: -4.6159\n",
      "MSE Score: 7.4577\n",
      "MAE Score: 2.5505\n",
      "\n",
      "Trial 248/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7598 | Final Val Loss: 10.5044\n",
      "R2 Score: -3.4229\n",
      "MSE Score: 5.8735\n",
      "MAE Score: 2.2682\n",
      "\n",
      "Trial 249/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8818 | Final Val Loss: 0.8411\n",
      "R2 Score: 0.5006\n",
      "MSE Score: 0.6632\n",
      "MAE Score: 0.7031\n",
      "\n",
      "Trial 250/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0193 | Final Val Loss: 0.9018\n",
      "R2 Score: 0.5402\n",
      "MSE Score: 0.6106\n",
      "MAE Score: 0.6761\n",
      "\n",
      "Trial 251/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1047 | Final Val Loss: 1.0430\n",
      "R2 Score: 0.6804\n",
      "MSE Score: 0.4244\n",
      "MAE Score: 0.5277\n",
      "New best R2 score!\n",
      "\n",
      "Trial 252/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7379 | Final Val Loss: 1.2915\n",
      "R2 Score: 0.6193\n",
      "MSE Score: 0.5056\n",
      "MAE Score: 0.5235\n",
      "\n",
      "Trial 253/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0161 | Final Val Loss: 1.0502\n",
      "R2 Score: 0.5915\n",
      "MSE Score: 0.5425\n",
      "MAE Score: 0.6244\n",
      "\n",
      "Trial 254/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8243 | Final Val Loss: 0.9456\n",
      "R2 Score: 0.5968\n",
      "MSE Score: 0.5355\n",
      "MAE Score: 0.6074\n",
      "\n",
      "Trial 255/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9823 | Final Val Loss: 1.5167\n",
      "R2 Score: 0.5560\n",
      "MSE Score: 0.5896\n",
      "MAE Score: 0.6216\n",
      "\n",
      "Trial 256/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0992 | Final Val Loss: 1.0472\n",
      "R2 Score: 0.5341\n",
      "MSE Score: 0.6188\n",
      "MAE Score: 0.6708\n",
      "\n",
      "Trial 257/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7310 | Final Val Loss: 1.5201\n",
      "R2 Score: 0.5033\n",
      "MSE Score: 0.6596\n",
      "MAE Score: 0.5788\n",
      "\n",
      "Trial 258/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7290 | Final Val Loss: 1.5214\n",
      "R2 Score: 0.6237\n",
      "MSE Score: 0.4997\n",
      "MAE Score: 0.5142\n",
      "\n",
      "Trial 259/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.6666 | Final Val Loss: 17.0561\n",
      "R2 Score: -6.7654\n",
      "MSE Score: 10.3122\n",
      "MAE Score: 2.9897\n",
      "\n",
      "Trial 260/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.4794 | Final Val Loss: 10.7566\n",
      "R2 Score: -3.3840\n",
      "MSE Score: 5.8218\n",
      "MAE Score: 2.1734\n",
      "\n",
      "Trial 261/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8692 | Final Val Loss: 2.0886\n",
      "R2 Score: 0.3455\n",
      "MSE Score: 0.8692\n",
      "MAE Score: 0.7035\n",
      "\n",
      "Trial 262/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.6317 | Final Val Loss: 2.0869\n",
      "R2 Score: 0.2801\n",
      "MSE Score: 0.9560\n",
      "MAE Score: 0.6974\n",
      "\n",
      "Trial 263/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5741 | Final Val Loss: 12.8023\n",
      "R2 Score: -4.5517\n",
      "MSE Score: 7.3724\n",
      "MAE Score: 2.5039\n",
      "\n",
      "Trial 264/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.4264 | Final Val Loss: 16.1944\n",
      "R2 Score: -6.1810\n",
      "MSE Score: 9.5362\n",
      "MAE Score: 2.8604\n",
      "\n",
      "Trial 265/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0366 | Final Val Loss: 1.8507\n",
      "R2 Score: 0.4174\n",
      "MSE Score: 0.7736\n",
      "MAE Score: 0.6917\n",
      "\n",
      "Trial 266/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2580 | Final Val Loss: 1.7358\n",
      "R2 Score: 0.4840\n",
      "MSE Score: 0.6852\n",
      "MAE Score: 0.5457\n",
      "\n",
      "Trial 267/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3299 | Final Val Loss: 3.2325\n",
      "R2 Score: 0.0188\n",
      "MSE Score: 1.3030\n",
      "MAE Score: 0.9286\n",
      "\n",
      "Trial 268/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3748 | Final Val Loss: 3.0363\n",
      "R2 Score: 0.2347\n",
      "MSE Score: 1.0163\n",
      "MAE Score: 0.7556\n",
      "\n",
      "Trial 269/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4723 | Final Val Loss: 2.9611\n",
      "R2 Score: 0.0748\n",
      "MSE Score: 1.2287\n",
      "MAE Score: 0.8456\n",
      "\n",
      "Trial 270/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0322 | Final Val Loss: 1.5206\n",
      "R2 Score: 0.4812\n",
      "MSE Score: 0.6889\n",
      "MAE Score: 0.6215\n",
      "\n",
      "Trial 271/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.9740 | Final Val Loss: 2.5997\n",
      "R2 Score: 0.2828\n",
      "MSE Score: 0.9525\n",
      "MAE Score: 0.7267\n",
      "\n",
      "Trial 272/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2318 | Final Val Loss: 2.4519\n",
      "R2 Score: 0.2329\n",
      "MSE Score: 1.0186\n",
      "MAE Score: 0.7036\n",
      "\n",
      "Trial 273/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9637 | Final Val Loss: 1.0864\n",
      "R2 Score: 0.5243\n",
      "MSE Score: 0.6317\n",
      "MAE Score: 0.6365\n",
      "\n",
      "Trial 274/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8528 | Final Val Loss: 0.8299\n",
      "R2 Score: 0.5543\n",
      "MSE Score: 0.5918\n",
      "MAE Score: 0.6394\n",
      "\n",
      "Trial 275/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.5494 | Final Val Loss: 12.3294\n",
      "R2 Score: -4.8741\n",
      "MSE Score: 7.8007\n",
      "MAE Score: 2.6889\n",
      "\n",
      "Trial 276/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9186 | Final Val Loss: 10.5491\n",
      "R2 Score: -3.5626\n",
      "MSE Score: 6.0590\n",
      "MAE Score: 2.3136\n",
      "\n",
      "Trial 277/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2506 | Final Val Loss: 0.8628\n",
      "R2 Score: 0.4877\n",
      "MSE Score: 0.6803\n",
      "MAE Score: 0.6630\n",
      "\n",
      "Trial 278/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0649 | Final Val Loss: 1.0674\n",
      "R2 Score: 0.5027\n",
      "MSE Score: 0.6603\n",
      "MAE Score: 0.6716\n",
      "\n",
      "Trial 279/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.7173 | Final Val Loss: 12.6788\n",
      "R2 Score: -4.5937\n",
      "MSE Score: 7.4282\n",
      "MAE Score: 2.5479\n",
      "\n",
      "Trial 280/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.6962 | Final Val Loss: 11.8317\n",
      "R2 Score: -4.2331\n",
      "MSE Score: 6.9494\n",
      "MAE Score: 2.5011\n",
      "\n",
      "Trial 281/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8564 | Final Val Loss: 1.0705\n",
      "R2 Score: 0.6022\n",
      "MSE Score: 0.5283\n",
      "MAE Score: 0.5876\n",
      "\n",
      "Trial 282/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7240 | Final Val Loss: 1.0416\n",
      "R2 Score: 0.5496\n",
      "MSE Score: 0.5981\n",
      "MAE Score: 0.6395\n",
      "\n",
      "Trial 283/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6479 | Final Val Loss: 1.1862\n",
      "R2 Score: 0.6239\n",
      "MSE Score: 0.4994\n",
      "MAE Score: 0.5680\n",
      "\n",
      "Trial 284/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0280 | Final Val Loss: 1.0918\n",
      "R2 Score: 0.6103\n",
      "MSE Score: 0.5175\n",
      "MAE Score: 0.5754\n",
      "\n",
      "Trial 285/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8093 | Final Val Loss: 1.1027\n",
      "R2 Score: 0.5940\n",
      "MSE Score: 0.5391\n",
      "MAE Score: 0.5888\n",
      "\n",
      "Trial 286/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8769 | Final Val Loss: 1.1007\n",
      "R2 Score: 0.6235\n",
      "MSE Score: 0.5000\n",
      "MAE Score: 0.5679\n",
      "\n",
      "Trial 287/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1028 | Final Val Loss: 1.4375\n",
      "R2 Score: 0.6047\n",
      "MSE Score: 0.5250\n",
      "MAE Score: 0.5770\n",
      "\n",
      "Trial 288/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2414 | Final Val Loss: 1.4296\n",
      "R2 Score: 0.5297\n",
      "MSE Score: 0.6245\n",
      "MAE Score: 0.6656\n",
      "\n",
      "Grid search completed for this dataset!\n",
      "\n",
      "Best parameters found:\n",
      "num_epochs: 350\n",
      "num_units: [16, 16, 8, 8]\n",
      "drop: 0.2\n",
      "lr: 0.0001\n",
      "decay: 0.0001\n",
      "acts: tanh\n",
      "opts: sgd\n",
      "patience: 15\n",
      "\n",
      "Best metrics:\n",
      "R2: 0.6804\n",
      "MSE: 0.4244\n",
      "MAE: 0.5277\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing dataset: filtered_0001.csv\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20332\\425057010.py:196: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  best_results_df = pd.concat([best_results_df, pd.DataFrame([best_result])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameter combinations to try: 288\n",
      "\n",
      "Trial 1/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1449 | Final Val Loss: 1.3350\n",
      "R2 Score: 0.3986\n",
      "MSE Score: 0.9605\n",
      "MAE Score: 0.7754\n",
      "New best R2 score!\n",
      "\n",
      "Trial 2/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20332\\425057010.py:142: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_trials_df = pd.concat([all_trials_df, pd.DataFrame([trial_results])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train loss: 1.4309 | Final Val Loss: 1.8314\n",
      "R2 Score: -0.0388\n",
      "MSE Score: 1.6589\n",
      "MAE Score: 1.0715\n",
      "\n",
      "Trial 3/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.2503 | Final Val Loss: 6.7629\n",
      "R2 Score: -4.6481\n",
      "MSE Score: 9.0201\n",
      "MAE Score: 2.7262\n",
      "\n",
      "Trial 4/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2177 | Final Val Loss: 5.2145\n",
      "R2 Score: -3.5493\n",
      "MSE Score: 7.2654\n",
      "MAE Score: 2.4034\n",
      "\n",
      "Trial 5/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8554 | Final Val Loss: 1.1535\n",
      "R2 Score: 0.2369\n",
      "MSE Score: 1.2187\n",
      "MAE Score: 0.9201\n",
      "\n",
      "Trial 6/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.9193 | Final Val Loss: 0.8021\n",
      "R2 Score: 0.3542\n",
      "MSE Score: 1.0313\n",
      "MAE Score: 0.8570\n",
      "\n",
      "Trial 7/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.9429 | Final Val Loss: 7.7555\n",
      "R2 Score: -5.1617\n",
      "MSE Score: 9.8404\n",
      "MAE Score: 2.8964\n",
      "\n",
      "Trial 8/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 13.2455 | Final Val Loss: 7.7041\n",
      "R2 Score: -5.3379\n",
      "MSE Score: 10.1217\n",
      "MAE Score: 2.9747\n",
      "\n",
      "Trial 9/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5553 | Final Val Loss: 1.1996\n",
      "R2 Score: 0.2122\n",
      "MSE Score: 1.2582\n",
      "MAE Score: 0.9413\n",
      "\n",
      "Trial 10/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7433 | Final Val Loss: 0.9366\n",
      "R2 Score: 0.2518\n",
      "MSE Score: 1.1949\n",
      "MAE Score: 0.9117\n",
      "\n",
      "Trial 11/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5144 | Final Val Loss: 1.4928\n",
      "R2 Score: -0.1721\n",
      "MSE Score: 1.8719\n",
      "MAE Score: 1.1310\n",
      "\n",
      "Trial 12/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3908 | Final Val Loss: 1.1079\n",
      "R2 Score: 0.3841\n",
      "MSE Score: 0.9837\n",
      "MAE Score: 0.7881\n",
      "\n",
      "Trial 13/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4116 | Final Val Loss: 1.1908\n",
      "R2 Score: 0.1495\n",
      "MSE Score: 1.3582\n",
      "MAE Score: 0.9501\n",
      "\n",
      "Trial 14/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6453 | Final Val Loss: 1.5997\n",
      "R2 Score: 0.2265\n",
      "MSE Score: 1.2353\n",
      "MAE Score: 0.9528\n",
      "\n",
      "Trial 15/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1778 | Final Val Loss: 1.0124\n",
      "R2 Score: 0.3559\n",
      "MSE Score: 1.0286\n",
      "MAE Score: 0.8724\n",
      "\n",
      "Trial 16/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.0904 | Final Val Loss: 1.1062\n",
      "R2 Score: 0.3004\n",
      "MSE Score: 1.1173\n",
      "MAE Score: 0.8491\n",
      "\n",
      "Trial 17/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7817 | Final Val Loss: 1.1399\n",
      "R2 Score: 0.4975\n",
      "MSE Score: 0.8026\n",
      "MAE Score: 0.6618\n",
      "New best R2 score!\n",
      "\n",
      "Trial 18/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7785 | Final Val Loss: 0.8106\n",
      "R2 Score: 0.4734\n",
      "MSE Score: 0.8410\n",
      "MAE Score: 0.7504\n",
      "\n",
      "Trial 19/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.8120 | Final Val Loss: 6.9708\n",
      "R2 Score: -4.4469\n",
      "MSE Score: 8.6989\n",
      "MAE Score: 2.7798\n",
      "\n",
      "Trial 20/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7043 | Final Val Loss: 6.1350\n",
      "R2 Score: -3.9214\n",
      "MSE Score: 7.8596\n",
      "MAE Score: 2.6144\n",
      "\n",
      "Trial 21/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4127 | Final Val Loss: 0.9630\n",
      "R2 Score: 0.4516\n",
      "MSE Score: 0.8757\n",
      "MAE Score: 0.7074\n",
      "\n",
      "Trial 22/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1871 | Final Val Loss: 0.7799\n",
      "R2 Score: 0.4957\n",
      "MSE Score: 0.8053\n",
      "MAE Score: 0.7178\n",
      "\n",
      "Trial 23/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.5218 | Final Val Loss: 7.0172\n",
      "R2 Score: -4.0474\n",
      "MSE Score: 8.0608\n",
      "MAE Score: 2.6678\n",
      "\n",
      "Trial 24/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.6694 | Final Val Loss: 5.6117\n",
      "R2 Score: -3.7039\n",
      "MSE Score: 7.5123\n",
      "MAE Score: 2.5228\n",
      "\n",
      "Trial 25/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5062 | Final Val Loss: 0.5737\n",
      "R2 Score: 0.5070\n",
      "MSE Score: 0.7873\n",
      "MAE Score: 0.6974\n",
      "New best R2 score!\n",
      "\n",
      "Trial 26/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0265 | Final Val Loss: 0.9988\n",
      "R2 Score: 0.3886\n",
      "MSE Score: 0.9765\n",
      "MAE Score: 0.7614\n",
      "\n",
      "Trial 27/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8703 | Final Val Loss: 0.6441\n",
      "R2 Score: 0.5007\n",
      "MSE Score: 0.7974\n",
      "MAE Score: 0.7154\n",
      "\n",
      "Trial 28/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6700 | Final Val Loss: 0.5005\n",
      "R2 Score: 0.5753\n",
      "MSE Score: 0.6783\n",
      "MAE Score: 0.6683\n",
      "New best R2 score!\n",
      "\n",
      "Trial 29/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8191 | Final Val Loss: 0.6241\n",
      "R2 Score: 0.5118\n",
      "MSE Score: 0.7796\n",
      "MAE Score: 0.7437\n",
      "\n",
      "Trial 30/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0440 | Final Val Loss: 1.0063\n",
      "R2 Score: 0.4157\n",
      "MSE Score: 0.9331\n",
      "MAE Score: 0.7586\n",
      "\n",
      "Trial 31/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9694 | Final Val Loss: 0.5090\n",
      "R2 Score: 0.5731\n",
      "MSE Score: 0.6817\n",
      "MAE Score: 0.6516\n",
      "\n",
      "Trial 32/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2597 | Final Val Loss: 0.8739\n",
      "R2 Score: 0.4989\n",
      "MSE Score: 0.8003\n",
      "MAE Score: 0.7192\n",
      "\n",
      "Trial 33/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3674 | Final Val Loss: 1.1644\n",
      "R2 Score: 0.1555\n",
      "MSE Score: 1.3487\n",
      "MAE Score: 0.9296\n",
      "\n",
      "Trial 34/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4692 | Final Val Loss: 0.9438\n",
      "R2 Score: 0.3260\n",
      "MSE Score: 1.0764\n",
      "MAE Score: 0.8832\n",
      "\n",
      "Trial 35/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 12.0402 | Final Val Loss: 8.1601\n",
      "R2 Score: -5.4996\n",
      "MSE Score: 10.3801\n",
      "MAE Score: 3.0024\n",
      "\n",
      "Trial 36/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.5396 | Final Val Loss: 7.0487\n",
      "R2 Score: -4.7991\n",
      "MSE Score: 9.2613\n",
      "MAE Score: 2.7943\n",
      "\n",
      "Trial 37/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.9496 | Final Val Loss: 0.8687\n",
      "R2 Score: 0.3400\n",
      "MSE Score: 1.0540\n",
      "MAE Score: 0.8488\n",
      "\n",
      "Trial 38/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6560 | Final Val Loss: 1.2255\n",
      "R2 Score: 0.1493\n",
      "MSE Score: 1.3586\n",
      "MAE Score: 1.0172\n",
      "\n",
      "Trial 39/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.7724 | Final Val Loss: 5.4161\n",
      "R2 Score: -3.7462\n",
      "MSE Score: 7.5799\n",
      "MAE Score: 2.5028\n",
      "\n",
      "Trial 40/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.7249 | Final Val Loss: 8.8246\n",
      "R2 Score: -6.3613\n",
      "MSE Score: 11.7562\n",
      "MAE Score: 3.1962\n",
      "\n",
      "Trial 41/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1492 | Final Val Loss: 1.1583\n",
      "R2 Score: 0.2979\n",
      "MSE Score: 1.1213\n",
      "MAE Score: 0.8224\n",
      "\n",
      "Trial 42/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0282 | Final Val Loss: 0.9509\n",
      "R2 Score: 0.3923\n",
      "MSE Score: 0.9705\n",
      "MAE Score: 0.8062\n",
      "\n",
      "Trial 43/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8450 | Final Val Loss: 1.2473\n",
      "R2 Score: 0.0637\n",
      "MSE Score: 1.4953\n",
      "MAE Score: 0.9863\n",
      "\n",
      "Trial 44/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1854 | Final Val Loss: 1.3315\n",
      "R2 Score: 0.1041\n",
      "MSE Score: 1.4308\n",
      "MAE Score: 0.9588\n",
      "\n",
      "Trial 45/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2808 | Final Val Loss: 0.9234\n",
      "R2 Score: 0.3227\n",
      "MSE Score: 1.0816\n",
      "MAE Score: 0.8786\n",
      "\n",
      "Trial 46/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7684 | Final Val Loss: 1.0465\n",
      "R2 Score: 0.2406\n",
      "MSE Score: 1.2128\n",
      "MAE Score: 0.9505\n",
      "\n",
      "Trial 47/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1720 | Final Val Loss: 0.8392\n",
      "R2 Score: 0.3353\n",
      "MSE Score: 1.0615\n",
      "MAE Score: 0.8628\n",
      "\n",
      "Trial 48/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7178 | Final Val Loss: 0.8787\n",
      "R2 Score: 0.2707\n",
      "MSE Score: 1.1647\n",
      "MAE Score: 0.8251\n",
      "\n",
      "Trial 49/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1389 | Final Val Loss: 0.7705\n",
      "R2 Score: 0.5169\n",
      "MSE Score: 0.7715\n",
      "MAE Score: 0.7259\n",
      "\n",
      "Trial 50/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0788 | Final Val Loss: 0.8362\n",
      "R2 Score: 0.5765\n",
      "MSE Score: 0.6764\n",
      "MAE Score: 0.7149\n",
      "New best R2 score!\n",
      "\n",
      "Trial 51/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.4890 | Final Val Loss: 8.0127\n",
      "R2 Score: -5.4649\n",
      "MSE Score: 10.3247\n",
      "MAE Score: 3.0159\n",
      "\n",
      "Trial 52/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.2629 | Final Val Loss: 8.2433\n",
      "R2 Score: -5.0388\n",
      "MSE Score: 9.6441\n",
      "MAE Score: 2.9311\n",
      "\n",
      "Trial 53/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9417 | Final Val Loss: 0.8343\n",
      "R2 Score: 0.4160\n",
      "MSE Score: 0.9326\n",
      "MAE Score: 0.8091\n",
      "\n",
      "Trial 54/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 3.2229 | Final Val Loss: 1.6672\n",
      "R2 Score: -0.1874\n",
      "MSE Score: 1.8963\n",
      "MAE Score: 1.1859\n",
      "\n",
      "Trial 55/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.5761 | Final Val Loss: 7.2324\n",
      "R2 Score: -4.9761\n",
      "MSE Score: 9.5440\n",
      "MAE Score: 2.8752\n",
      "\n",
      "Trial 56/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.2279 | Final Val Loss: 6.5983\n",
      "R2 Score: -4.5219\n",
      "MSE Score: 8.8185\n",
      "MAE Score: 2.7719\n",
      "\n",
      "Trial 57/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7242 | Final Val Loss: 0.7207\n",
      "R2 Score: 0.5508\n",
      "MSE Score: 0.7174\n",
      "MAE Score: 0.6763\n",
      "\n",
      "Trial 58/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6470 | Final Val Loss: 0.7871\n",
      "R2 Score: 0.4760\n",
      "MSE Score: 0.8369\n",
      "MAE Score: 0.7656\n",
      "\n",
      "Trial 59/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0136 | Final Val Loss: 0.6522\n",
      "R2 Score: 0.5944\n",
      "MSE Score: 0.6477\n",
      "MAE Score: 0.6243\n",
      "New best R2 score!\n",
      "\n",
      "Trial 60/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0228 | Final Val Loss: 1.0557\n",
      "R2 Score: 0.3338\n",
      "MSE Score: 1.0640\n",
      "MAE Score: 0.8483\n",
      "\n",
      "Trial 61/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7477 | Final Val Loss: 0.6018\n",
      "R2 Score: 0.5555\n",
      "MSE Score: 0.7099\n",
      "MAE Score: 0.7208\n",
      "\n",
      "Trial 62/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6701 | Final Val Loss: 0.8133\n",
      "R2 Score: 0.4069\n",
      "MSE Score: 0.9472\n",
      "MAE Score: 0.7414\n",
      "\n",
      "Trial 63/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5944 | Final Val Loss: 1.0290\n",
      "R2 Score: 0.3370\n",
      "MSE Score: 1.0588\n",
      "MAE Score: 0.7988\n",
      "\n",
      "Trial 64/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9466 | Final Val Loss: 0.5184\n",
      "R2 Score: 0.5094\n",
      "MSE Score: 0.7835\n",
      "MAE Score: 0.7125\n",
      "\n",
      "Trial 65/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5140 | Final Val Loss: 1.4979\n",
      "R2 Score: -0.0212\n",
      "MSE Score: 1.6309\n",
      "MAE Score: 1.0357\n",
      "\n",
      "Trial 66/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3961 | Final Val Loss: 0.6407\n",
      "R2 Score: 0.4047\n",
      "MSE Score: 0.9507\n",
      "MAE Score: 0.8329\n",
      "\n",
      "Trial 67/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9341 | Final Val Loss: 5.3651\n",
      "R2 Score: -3.3558\n",
      "MSE Score: 6.9564\n",
      "MAE Score: 2.3814\n",
      "\n",
      "Trial 68/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5826 | Final Val Loss: 6.9900\n",
      "R2 Score: -4.7879\n",
      "MSE Score: 9.2435\n",
      "MAE Score: 2.8094\n",
      "\n",
      "Trial 69/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6157 | Final Val Loss: 1.2672\n",
      "R2 Score: 0.2325\n",
      "MSE Score: 1.2257\n",
      "MAE Score: 0.9599\n",
      "\n",
      "Trial 70/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.0595 | Final Val Loss: 1.3952\n",
      "R2 Score: 0.1422\n",
      "MSE Score: 1.3699\n",
      "MAE Score: 0.9384\n",
      "\n",
      "Trial 71/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3679 | Final Val Loss: 7.4653\n",
      "R2 Score: -5.2363\n",
      "MSE Score: 9.9596\n",
      "MAE Score: 2.9392\n",
      "\n",
      "Trial 72/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 12.2995 | Final Val Loss: 8.8455\n",
      "R2 Score: -6.2965\n",
      "MSE Score: 11.6526\n",
      "MAE Score: 3.1680\n",
      "\n",
      "Trial 73/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0543 | Final Val Loss: 1.0167\n",
      "R2 Score: 0.1092\n",
      "MSE Score: 1.4227\n",
      "MAE Score: 1.0100\n",
      "\n",
      "Trial 74/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2380 | Final Val Loss: 0.9704\n",
      "R2 Score: 0.2522\n",
      "MSE Score: 1.1942\n",
      "MAE Score: 0.9059\n",
      "\n",
      "Trial 75/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3667 | Final Val Loss: 0.8902\n",
      "R2 Score: 0.0315\n",
      "MSE Score: 1.5467\n",
      "MAE Score: 1.0228\n",
      "\n",
      "Trial 76/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3885 | Final Val Loss: 0.9828\n",
      "R2 Score: 0.2234\n",
      "MSE Score: 1.2402\n",
      "MAE Score: 0.8741\n",
      "\n",
      "Trial 77/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2657 | Final Val Loss: 1.5667\n",
      "R2 Score: 0.2348\n",
      "MSE Score: 1.2220\n",
      "MAE Score: 0.8988\n",
      "\n",
      "Trial 78/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4875 | Final Val Loss: 1.4169\n",
      "R2 Score: 0.0113\n",
      "MSE Score: 1.5789\n",
      "MAE Score: 0.9895\n",
      "\n",
      "Trial 79/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7604 | Final Val Loss: 1.1575\n",
      "R2 Score: 0.0334\n",
      "MSE Score: 1.5437\n",
      "MAE Score: 0.9673\n",
      "\n",
      "Trial 80/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7055 | Final Val Loss: 1.4600\n",
      "R2 Score: -0.5245\n",
      "MSE Score: 2.4347\n",
      "MAE Score: 1.2811\n",
      "\n",
      "Trial 81/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1487 | Final Val Loss: 0.9413\n",
      "R2 Score: 0.4946\n",
      "MSE Score: 0.8071\n",
      "MAE Score: 0.7587\n",
      "\n",
      "Trial 82/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0134 | Final Val Loss: 0.7071\n",
      "R2 Score: 0.5801\n",
      "MSE Score: 0.6706\n",
      "MAE Score: 0.7027\n",
      "\n",
      "Trial 83/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.4613 | Final Val Loss: 7.5587\n",
      "R2 Score: -4.4296\n",
      "MSE Score: 8.6712\n",
      "MAE Score: 2.7740\n",
      "\n",
      "Trial 84/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.3075 | Final Val Loss: 7.3300\n",
      "R2 Score: -4.5067\n",
      "MSE Score: 8.7943\n",
      "MAE Score: 2.7913\n",
      "\n",
      "Trial 85/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0332 | Final Val Loss: 0.9849\n",
      "R2 Score: 0.5135\n",
      "MSE Score: 0.7769\n",
      "MAE Score: 0.6766\n",
      "\n",
      "Trial 86/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2616 | Final Val Loss: 0.9237\n",
      "R2 Score: 0.4450\n",
      "MSE Score: 0.8863\n",
      "MAE Score: 0.7343\n",
      "\n",
      "Trial 87/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.1165 | Final Val Loss: 5.5500\n",
      "R2 Score: -3.3747\n",
      "MSE Score: 6.9865\n",
      "MAE Score: 2.4203\n",
      "\n",
      "Trial 88/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.5175 | Final Val Loss: 6.4282\n",
      "R2 Score: -4.1564\n",
      "MSE Score: 8.2350\n",
      "MAE Score: 2.6483\n",
      "\n",
      "Trial 89/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7243 | Final Val Loss: 0.5777\n",
      "R2 Score: 0.5359\n",
      "MSE Score: 0.7412\n",
      "MAE Score: 0.7364\n",
      "\n",
      "Trial 90/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0573 | Final Val Loss: 1.0133\n",
      "R2 Score: 0.4117\n",
      "MSE Score: 0.9395\n",
      "MAE Score: 0.8059\n",
      "\n",
      "Trial 91/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6671 | Final Val Loss: 0.6699\n",
      "R2 Score: 0.6283\n",
      "MSE Score: 0.5935\n",
      "MAE Score: 0.6036\n",
      "New best R2 score!\n",
      "\n",
      "Trial 92/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9085 | Final Val Loss: 0.5997\n",
      "R2 Score: 0.4939\n",
      "MSE Score: 0.8082\n",
      "MAE Score: 0.7455\n",
      "\n",
      "Trial 93/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9935 | Final Val Loss: 0.4491\n",
      "R2 Score: 0.5683\n",
      "MSE Score: 0.6894\n",
      "MAE Score: 0.6882\n",
      "\n",
      "Trial 94/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0265 | Final Val Loss: 1.2443\n",
      "R2 Score: 0.2809\n",
      "MSE Score: 1.1484\n",
      "MAE Score: 0.8598\n",
      "\n",
      "Trial 95/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2660 | Final Val Loss: 0.6984\n",
      "R2 Score: 0.3997\n",
      "MSE Score: 0.9586\n",
      "MAE Score: 0.7637\n",
      "\n",
      "Trial 96/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2575 | Final Val Loss: 0.6566\n",
      "R2 Score: 0.5376\n",
      "MSE Score: 0.7384\n",
      "MAE Score: 0.6730\n",
      "\n",
      "Trial 97/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4513 | Final Val Loss: 1.2081\n",
      "R2 Score: 0.3965\n",
      "MSE Score: 0.9638\n",
      "MAE Score: 0.7842\n",
      "\n",
      "Trial 98/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7665 | Final Val Loss: 1.6370\n",
      "R2 Score: 0.0549\n",
      "MSE Score: 1.5093\n",
      "MAE Score: 1.0622\n",
      "\n",
      "Trial 99/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.0373 | Final Val Loss: 5.5211\n",
      "R2 Score: -3.7216\n",
      "MSE Score: 7.5405\n",
      "MAE Score: 2.4608\n",
      "\n",
      "Trial 100/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7588 | Final Val Loss: 5.3644\n",
      "R2 Score: -3.6548\n",
      "MSE Score: 7.4339\n",
      "MAE Score: 2.4310\n",
      "\n",
      "Trial 101/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.0796 | Final Val Loss: 0.9596\n",
      "R2 Score: 0.2104\n",
      "MSE Score: 1.2610\n",
      "MAE Score: 0.9455\n",
      "\n",
      "Trial 102/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1926 | Final Val Loss: 1.0238\n",
      "R2 Score: 0.1986\n",
      "MSE Score: 1.2798\n",
      "MAE Score: 0.9158\n",
      "\n",
      "Trial 103/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.8733 | Final Val Loss: 6.9657\n",
      "R2 Score: -4.8822\n",
      "MSE Score: 9.3941\n",
      "MAE Score: 2.8334\n",
      "\n",
      "Trial 104/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.5610 | Final Val Loss: 8.5645\n",
      "R2 Score: -5.8859\n",
      "MSE Score: 10.9970\n",
      "MAE Score: 3.0946\n",
      "\n",
      "Trial 105/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7638 | Final Val Loss: 1.9786\n",
      "R2 Score: -0.0044\n",
      "MSE Score: 1.6041\n",
      "MAE Score: 1.0376\n",
      "\n",
      "Trial 106/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4841 | Final Val Loss: 1.2344\n",
      "R2 Score: 0.2832\n",
      "MSE Score: 1.1448\n",
      "MAE Score: 0.8594\n",
      "\n",
      "Trial 107/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8679 | Final Val Loss: 1.1106\n",
      "R2 Score: -0.0221\n",
      "MSE Score: 1.6323\n",
      "MAE Score: 1.0362\n",
      "\n",
      "Trial 108/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.0215 | Final Val Loss: 0.9628\n",
      "R2 Score: 0.2628\n",
      "MSE Score: 1.1774\n",
      "MAE Score: 0.8697\n",
      "\n",
      "Trial 109/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5688 | Final Val Loss: 1.2061\n",
      "R2 Score: 0.2182\n",
      "MSE Score: 1.2486\n",
      "MAE Score: 0.9029\n",
      "\n",
      "Trial 110/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6486 | Final Val Loss: 0.8188\n",
      "R2 Score: 0.2785\n",
      "MSE Score: 1.1523\n",
      "MAE Score: 0.9169\n",
      "\n",
      "Trial 111/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6883 | Final Val Loss: 1.7113\n",
      "R2 Score: -0.2370\n",
      "MSE Score: 1.9756\n",
      "MAE Score: 1.1381\n",
      "\n",
      "Trial 112/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.4501 | Final Val Loss: 1.7343\n",
      "R2 Score: -0.2387\n",
      "MSE Score: 1.9783\n",
      "MAE Score: 1.2375\n",
      "\n",
      "Trial 113/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9771 | Final Val Loss: 1.0705\n",
      "R2 Score: 0.6067\n",
      "MSE Score: 0.6281\n",
      "MAE Score: 0.6643\n",
      "\n",
      "Trial 114/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0352 | Final Val Loss: 1.0971\n",
      "R2 Score: 0.3031\n",
      "MSE Score: 1.1130\n",
      "MAE Score: 0.8561\n",
      "\n",
      "Trial 115/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3768 | Final Val Loss: 6.3534\n",
      "R2 Score: -4.0594\n",
      "MSE Score: 8.0800\n",
      "MAE Score: 2.6605\n",
      "\n",
      "Trial 116/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.4929 | Final Val Loss: 6.9350\n",
      "R2 Score: -4.8886\n",
      "MSE Score: 9.4042\n",
      "MAE Score: 2.8614\n",
      "\n",
      "Trial 117/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8137 | Final Val Loss: 1.0574\n",
      "R2 Score: 0.3415\n",
      "MSE Score: 1.0516\n",
      "MAE Score: 0.8654\n",
      "\n",
      "Trial 118/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1987 | Final Val Loss: 0.9560\n",
      "R2 Score: 0.3322\n",
      "MSE Score: 1.0665\n",
      "MAE Score: 0.8812\n",
      "\n",
      "Trial 119/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3406 | Final Val Loss: 6.8028\n",
      "R2 Score: -3.9338\n",
      "MSE Score: 7.8794\n",
      "MAE Score: 2.6350\n",
      "\n",
      "Trial 120/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 12.0491 | Final Val Loss: 8.5934\n",
      "R2 Score: -5.8660\n",
      "MSE Score: 10.9652\n",
      "MAE Score: 3.1236\n",
      "\n",
      "Trial 121/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9462 | Final Val Loss: 0.7608\n",
      "R2 Score: 0.5431\n",
      "MSE Score: 0.7298\n",
      "MAE Score: 0.6695\n",
      "\n",
      "Trial 122/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6150 | Final Val Loss: 0.4666\n",
      "R2 Score: 0.5714\n",
      "MSE Score: 0.6845\n",
      "MAE Score: 0.6787\n",
      "\n",
      "Trial 123/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9681 | Final Val Loss: 0.8168\n",
      "R2 Score: 0.4846\n",
      "MSE Score: 0.8231\n",
      "MAE Score: 0.7200\n",
      "\n",
      "Trial 124/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6239 | Final Val Loss: 0.5255\n",
      "R2 Score: 0.5427\n",
      "MSE Score: 0.7303\n",
      "MAE Score: 0.6726\n",
      "\n",
      "Trial 125/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8589 | Final Val Loss: 0.6400\n",
      "R2 Score: 0.5052\n",
      "MSE Score: 0.7902\n",
      "MAE Score: 0.6931\n",
      "\n",
      "Trial 126/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6992 | Final Val Loss: 0.8020\n",
      "R2 Score: 0.6038\n",
      "MSE Score: 0.6328\n",
      "MAE Score: 0.7015\n",
      "\n",
      "Trial 127/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1653 | Final Val Loss: 0.6220\n",
      "R2 Score: 0.4284\n",
      "MSE Score: 0.9129\n",
      "MAE Score: 0.7239\n",
      "\n",
      "Trial 128/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1738 | Final Val Loss: 0.7148\n",
      "R2 Score: 0.5082\n",
      "MSE Score: 0.7854\n",
      "MAE Score: 0.6888\n",
      "\n",
      "Trial 129/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1037 | Final Val Loss: 0.9779\n",
      "R2 Score: 0.2565\n",
      "MSE Score: 1.1874\n",
      "MAE Score: 0.8394\n",
      "\n",
      "Trial 130/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6813 | Final Val Loss: 1.0312\n",
      "R2 Score: 0.1412\n",
      "MSE Score: 1.3715\n",
      "MAE Score: 0.9452\n",
      "\n",
      "Trial 131/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.6698 | Final Val Loss: 5.6960\n",
      "R2 Score: -4.0429\n",
      "MSE Score: 8.0536\n",
      "MAE Score: 2.5644\n",
      "\n",
      "Trial 132/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.3700 | Final Val Loss: 7.7612\n",
      "R2 Score: -5.3473\n",
      "MSE Score: 10.1367\n",
      "MAE Score: 2.9524\n",
      "\n",
      "Trial 133/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5347 | Final Val Loss: 0.8428\n",
      "R2 Score: 0.2823\n",
      "MSE Score: 1.1461\n",
      "MAE Score: 0.8740\n",
      "\n",
      "Trial 134/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.9703 | Final Val Loss: 1.0193\n",
      "R2 Score: 0.3454\n",
      "MSE Score: 1.0455\n",
      "MAE Score: 0.8471\n",
      "\n",
      "Trial 135/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.7418 | Final Val Loss: 6.3109\n",
      "R2 Score: -4.3146\n",
      "MSE Score: 8.4875\n",
      "MAE Score: 2.6622\n",
      "\n",
      "Trial 136/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.9146 | Final Val Loss: 6.2746\n",
      "R2 Score: -4.1926\n",
      "MSE Score: 8.2928\n",
      "MAE Score: 2.6057\n",
      "\n",
      "Trial 137/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2224 | Final Val Loss: 1.2488\n",
      "R2 Score: 0.3390\n",
      "MSE Score: 1.0556\n",
      "MAE Score: 0.8266\n",
      "\n",
      "Trial 138/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3758 | Final Val Loss: 1.0254\n",
      "R2 Score: 0.3315\n",
      "MSE Score: 1.0676\n",
      "MAE Score: 0.8417\n",
      "\n",
      "Trial 139/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1047 | Final Val Loss: 1.2089\n",
      "R2 Score: -0.0467\n",
      "MSE Score: 1.6716\n",
      "MAE Score: 1.0231\n",
      "\n",
      "Trial 140/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2152 | Final Val Loss: 1.4442\n",
      "R2 Score: -0.1289\n",
      "MSE Score: 1.8028\n",
      "MAE Score: 1.0973\n",
      "\n",
      "Trial 141/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6856 | Final Val Loss: 1.0405\n",
      "R2 Score: 0.1683\n",
      "MSE Score: 1.3282\n",
      "MAE Score: 0.9645\n",
      "\n",
      "Trial 142/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5642 | Final Val Loss: 0.9879\n",
      "R2 Score: 0.2856\n",
      "MSE Score: 1.1410\n",
      "MAE Score: 0.8563\n",
      "\n",
      "Trial 143/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.0288 | Final Val Loss: 1.3203\n",
      "R2 Score: -0.2863\n",
      "MSE Score: 2.0542\n",
      "MAE Score: 1.2020\n",
      "\n",
      "Trial 144/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3868 | Final Val Loss: 1.1676\n",
      "R2 Score: 0.0973\n",
      "MSE Score: 1.4416\n",
      "MAE Score: 0.9887\n",
      "\n",
      "Trial 145/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8947 | Final Val Loss: 0.8904\n",
      "R2 Score: 0.4258\n",
      "MSE Score: 0.9170\n",
      "MAE Score: 0.7964\n",
      "\n",
      "Trial 146/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7909 | Final Val Loss: 0.7471\n",
      "R2 Score: 0.5758\n",
      "MSE Score: 0.6774\n",
      "MAE Score: 0.6600\n",
      "\n",
      "Trial 147/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.4727 | Final Val Loss: 6.5635\n",
      "R2 Score: -4.1105\n",
      "MSE Score: 8.1616\n",
      "MAE Score: 2.6549\n",
      "\n",
      "Trial 148/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2036 | Final Val Loss: 4.9492\n",
      "R2 Score: -2.7746\n",
      "MSE Score: 6.0281\n",
      "MAE Score: 2.2316\n",
      "\n",
      "Trial 149/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9815 | Final Val Loss: 0.6926\n",
      "R2 Score: 0.5288\n",
      "MSE Score: 0.7525\n",
      "MAE Score: 0.7266\n",
      "\n",
      "Trial 150/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2882 | Final Val Loss: 1.0344\n",
      "R2 Score: 0.4130\n",
      "MSE Score: 0.9375\n",
      "MAE Score: 0.7859\n",
      "\n",
      "Trial 151/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3168 | Final Val Loss: 6.7210\n",
      "R2 Score: -4.2853\n",
      "MSE Score: 8.4407\n",
      "MAE Score: 2.7188\n",
      "\n",
      "Trial 152/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5866 | Final Val Loss: 5.3912\n",
      "R2 Score: -3.5568\n",
      "MSE Score: 7.2773\n",
      "MAE Score: 2.4696\n",
      "\n",
      "Trial 153/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7306 | Final Val Loss: 0.6994\n",
      "R2 Score: 0.5178\n",
      "MSE Score: 0.7701\n",
      "MAE Score: 0.7231\n",
      "\n",
      "Trial 154/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7339 | Final Val Loss: 0.6874\n",
      "R2 Score: 0.4298\n",
      "MSE Score: 0.9106\n",
      "MAE Score: 0.7762\n",
      "\n",
      "Trial 155/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3117 | Final Val Loss: 0.6978\n",
      "R2 Score: 0.5841\n",
      "MSE Score: 0.6643\n",
      "MAE Score: 0.6645\n",
      "\n",
      "Trial 156/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0080 | Final Val Loss: 0.8511\n",
      "R2 Score: 0.5552\n",
      "MSE Score: 0.7103\n",
      "MAE Score: 0.6705\n",
      "\n",
      "Trial 157/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8522 | Final Val Loss: 0.6909\n",
      "R2 Score: 0.4531\n",
      "MSE Score: 0.8734\n",
      "MAE Score: 0.8012\n",
      "\n",
      "Trial 158/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4993 | Final Val Loss: 1.4676\n",
      "R2 Score: 0.1907\n",
      "MSE Score: 1.2925\n",
      "MAE Score: 0.9150\n",
      "\n",
      "Trial 159/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2737 | Final Val Loss: 0.7040\n",
      "R2 Score: 0.4984\n",
      "MSE Score: 0.8011\n",
      "MAE Score: 0.7100\n",
      "\n",
      "Trial 160/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3442 | Final Val Loss: 0.5311\n",
      "R2 Score: 0.5700\n",
      "MSE Score: 0.6868\n",
      "MAE Score: 0.6500\n",
      "\n",
      "Trial 161/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5071 | Final Val Loss: 1.2354\n",
      "R2 Score: 0.3466\n",
      "MSE Score: 1.0434\n",
      "MAE Score: 0.8278\n",
      "\n",
      "Trial 162/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4958 | Final Val Loss: 1.3449\n",
      "R2 Score: 0.2102\n",
      "MSE Score: 1.2613\n",
      "MAE Score: 0.9273\n",
      "\n",
      "Trial 163/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.2900 | Final Val Loss: 7.3697\n",
      "R2 Score: -5.1635\n",
      "MSE Score: 9.8433\n",
      "MAE Score: 2.9088\n",
      "\n",
      "Trial 164/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.4413 | Final Val Loss: 7.0640\n",
      "R2 Score: -4.5044\n",
      "MSE Score: 8.7906\n",
      "MAE Score: 2.7391\n",
      "\n",
      "Trial 165/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1440 | Final Val Loss: 1.3469\n",
      "R2 Score: 0.1869\n",
      "MSE Score: 1.2985\n",
      "MAE Score: 0.9714\n",
      "\n",
      "Trial 166/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7716 | Final Val Loss: 0.8253\n",
      "R2 Score: 0.3383\n",
      "MSE Score: 1.0567\n",
      "MAE Score: 0.8572\n",
      "\n",
      "Trial 167/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2531 | Final Val Loss: 5.2050\n",
      "R2 Score: -3.5806\n",
      "MSE Score: 7.3153\n",
      "MAE Score: 2.4111\n",
      "\n",
      "Trial 168/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.4397 | Final Val Loss: 6.6075\n",
      "R2 Score: -4.3665\n",
      "MSE Score: 8.5704\n",
      "MAE Score: 2.7109\n",
      "\n",
      "Trial 169/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1745 | Final Val Loss: 1.1833\n",
      "R2 Score: -0.0445\n",
      "MSE Score: 1.6680\n",
      "MAE Score: 1.0686\n",
      "\n",
      "Trial 170/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3353 | Final Val Loss: 1.0230\n",
      "R2 Score: 0.3670\n",
      "MSE Score: 1.0108\n",
      "MAE Score: 0.8314\n",
      "\n",
      "Trial 171/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2904 | Final Val Loss: 0.9116\n",
      "R2 Score: 0.3072\n",
      "MSE Score: 1.1063\n",
      "MAE Score: 0.8472\n",
      "\n",
      "Trial 172/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6385 | Final Val Loss: 1.3418\n",
      "R2 Score: 0.0291\n",
      "MSE Score: 1.5506\n",
      "MAE Score: 1.0446\n",
      "\n",
      "Trial 173/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5647 | Final Val Loss: 0.9812\n",
      "R2 Score: 0.2645\n",
      "MSE Score: 1.1746\n",
      "MAE Score: 0.9204\n",
      "\n",
      "Trial 174/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4998 | Final Val Loss: 1.6371\n",
      "R2 Score: -0.2159\n",
      "MSE Score: 1.9419\n",
      "MAE Score: 1.2059\n",
      "\n",
      "Trial 175/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5946 | Final Val Loss: 1.4801\n",
      "R2 Score: -0.2293\n",
      "MSE Score: 1.9632\n",
      "MAE Score: 1.1591\n",
      "\n",
      "Trial 176/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2515 | Final Val Loss: 0.7630\n",
      "R2 Score: 0.3503\n",
      "MSE Score: 1.0376\n",
      "MAE Score: 0.8312\n",
      "\n",
      "Trial 177/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9216 | Final Val Loss: 0.9259\n",
      "R2 Score: 0.5067\n",
      "MSE Score: 0.7878\n",
      "MAE Score: 0.7345\n",
      "\n",
      "Trial 178/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0602 | Final Val Loss: 1.3609\n",
      "R2 Score: 0.3543\n",
      "MSE Score: 1.0313\n",
      "MAE Score: 0.7945\n",
      "\n",
      "Trial 179/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.0449 | Final Val Loss: 5.2460\n",
      "R2 Score: -2.8598\n",
      "MSE Score: 6.1641\n",
      "MAE Score: 2.2992\n",
      "\n",
      "Trial 180/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.4117 | Final Val Loss: 5.7319\n",
      "R2 Score: -3.5911\n",
      "MSE Score: 7.3320\n",
      "MAE Score: 2.5156\n",
      "\n",
      "Trial 181/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0393 | Final Val Loss: 0.7217\n",
      "R2 Score: 0.5370\n",
      "MSE Score: 0.7394\n",
      "MAE Score: 0.7035\n",
      "\n",
      "Trial 182/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2978 | Final Val Loss: 0.5932\n",
      "R2 Score: 0.4600\n",
      "MSE Score: 0.8623\n",
      "MAE Score: 0.7780\n",
      "\n",
      "Trial 183/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9138 | Final Val Loss: 5.6233\n",
      "R2 Score: -3.5833\n",
      "MSE Score: 7.3196\n",
      "MAE Score: 2.4777\n",
      "\n",
      "Trial 184/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.1265 | Final Val Loss: 8.3822\n",
      "R2 Score: -5.1233\n",
      "MSE Score: 9.7790\n",
      "MAE Score: 2.9499\n",
      "\n",
      "Trial 185/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6820 | Final Val Loss: 0.7651\n",
      "R2 Score: 0.5361\n",
      "MSE Score: 0.7408\n",
      "MAE Score: 0.6739\n",
      "\n",
      "Trial 186/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8732 | Final Val Loss: 0.6044\n",
      "R2 Score: 0.5836\n",
      "MSE Score: 0.6650\n",
      "MAE Score: 0.6470\n",
      "\n",
      "Trial 187/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8248 | Final Val Loss: 0.7535\n",
      "R2 Score: 0.4331\n",
      "MSE Score: 0.9054\n",
      "MAE Score: 0.7815\n",
      "\n",
      "Trial 188/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9608 | Final Val Loss: 0.9077\n",
      "R2 Score: 0.5102\n",
      "MSE Score: 0.7822\n",
      "MAE Score: 0.7027\n",
      "\n",
      "Trial 189/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1457 | Final Val Loss: 1.2421\n",
      "R2 Score: 0.2838\n",
      "MSE Score: 1.1438\n",
      "MAE Score: 0.8546\n",
      "\n",
      "Trial 190/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0270 | Final Val Loss: 1.1352\n",
      "R2 Score: 0.2706\n",
      "MSE Score: 1.1649\n",
      "MAE Score: 0.8794\n",
      "\n",
      "Trial 191/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1530 | Final Val Loss: 0.6339\n",
      "R2 Score: 0.6060\n",
      "MSE Score: 0.6293\n",
      "MAE Score: 0.6145\n",
      "\n",
      "Trial 192/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8232 | Final Val Loss: 1.3963\n",
      "R2 Score: 0.2831\n",
      "MSE Score: 1.1449\n",
      "MAE Score: 0.9097\n",
      "\n",
      "Trial 193/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3374 | Final Val Loss: 1.1851\n",
      "R2 Score: 0.3108\n",
      "MSE Score: 1.1007\n",
      "MAE Score: 0.8246\n",
      "\n",
      "Trial 194/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6492 | Final Val Loss: 0.8699\n",
      "R2 Score: 0.4021\n",
      "MSE Score: 0.9549\n",
      "MAE Score: 0.8335\n",
      "\n",
      "Trial 195/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5390 | Final Val Loss: 6.0529\n",
      "R2 Score: -3.9785\n",
      "MSE Score: 7.9508\n",
      "MAE Score: 2.5691\n",
      "\n",
      "Trial 196/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 12.8691 | Final Val Loss: 8.5569\n",
      "R2 Score: -5.6933\n",
      "MSE Score: 10.6894\n",
      "MAE Score: 3.0343\n",
      "\n",
      "Trial 197/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.0307 | Final Val Loss: 1.7950\n",
      "R2 Score: -0.2259\n",
      "MSE Score: 1.9579\n",
      "MAE Score: 1.1045\n",
      "\n",
      "Trial 198/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.3057 | Final Val Loss: 1.3467\n",
      "R2 Score: 0.2409\n",
      "MSE Score: 1.2122\n",
      "MAE Score: 0.9004\n",
      "\n",
      "Trial 199/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.2091 | Final Val Loss: 6.4934\n",
      "R2 Score: -4.6771\n",
      "MSE Score: 9.0664\n",
      "MAE Score: 2.7729\n",
      "\n",
      "Trial 200/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.6561 | Final Val Loss: 4.8898\n",
      "R2 Score: -3.1958\n",
      "MSE Score: 6.7009\n",
      "MAE Score: 2.3139\n",
      "\n",
      "Trial 201/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9879 | Final Val Loss: 1.2808\n",
      "R2 Score: 0.2442\n",
      "MSE Score: 1.2070\n",
      "MAE Score: 0.8625\n",
      "\n",
      "Trial 202/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8756 | Final Val Loss: 0.9067\n",
      "R2 Score: 0.4488\n",
      "MSE Score: 0.8802\n",
      "MAE Score: 0.7534\n",
      "\n",
      "Trial 203/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5222 | Final Val Loss: 1.2132\n",
      "R2 Score: 0.1769\n",
      "MSE Score: 1.3145\n",
      "MAE Score: 0.9258\n",
      "\n",
      "Trial 204/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6240 | Final Val Loss: 1.7285\n",
      "R2 Score: -0.1053\n",
      "MSE Score: 1.7652\n",
      "MAE Score: 1.1145\n",
      "\n",
      "Trial 205/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5589 | Final Val Loss: 1.1616\n",
      "R2 Score: 0.1165\n",
      "MSE Score: 1.4110\n",
      "MAE Score: 1.0149\n",
      "\n",
      "Trial 206/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5242 | Final Val Loss: 1.1503\n",
      "R2 Score: -0.0098\n",
      "MSE Score: 1.6127\n",
      "MAE Score: 1.0585\n",
      "\n",
      "Trial 207/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2242 | Final Val Loss: 1.0164\n",
      "R2 Score: 0.1008\n",
      "MSE Score: 1.4360\n",
      "MAE Score: 0.9837\n",
      "\n",
      "Trial 208/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4504 | Final Val Loss: 1.0465\n",
      "R2 Score: 0.1663\n",
      "MSE Score: 1.3314\n",
      "MAE Score: 0.9495\n",
      "\n",
      "Trial 209/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9650 | Final Val Loss: 0.9788\n",
      "R2 Score: 0.3502\n",
      "MSE Score: 1.0377\n",
      "MAE Score: 0.9056\n",
      "\n",
      "Trial 210/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2817 | Final Val Loss: 0.8004\n",
      "R2 Score: 0.4367\n",
      "MSE Score: 0.8997\n",
      "MAE Score: 0.8079\n",
      "\n",
      "Trial 211/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.4424 | Final Val Loss: 4.6670\n",
      "R2 Score: -2.8415\n",
      "MSE Score: 6.1349\n",
      "MAE Score: 2.2696\n",
      "\n",
      "Trial 212/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9420 | Final Val Loss: 5.2511\n",
      "R2 Score: -3.3419\n",
      "MSE Score: 6.9340\n",
      "MAE Score: 2.4372\n",
      "\n",
      "Trial 213/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3079 | Final Val Loss: 0.7224\n",
      "R2 Score: 0.4760\n",
      "MSE Score: 0.8369\n",
      "MAE Score: 0.7156\n",
      "\n",
      "Trial 214/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6351 | Final Val Loss: 0.9994\n",
      "R2 Score: 0.4537\n",
      "MSE Score: 0.8724\n",
      "MAE Score: 0.8018\n",
      "\n",
      "Trial 215/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.1622 | Final Val Loss: 5.4711\n",
      "R2 Score: -3.5790\n",
      "MSE Score: 7.3127\n",
      "MAE Score: 2.4806\n",
      "\n",
      "Trial 216/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.1385 | Final Val Loss: 6.7640\n",
      "R2 Score: -4.8192\n",
      "MSE Score: 9.2934\n",
      "MAE Score: 2.8196\n",
      "\n",
      "Trial 217/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8321 | Final Val Loss: 0.8217\n",
      "R2 Score: 0.3444\n",
      "MSE Score: 1.0470\n",
      "MAE Score: 0.7847\n",
      "\n",
      "Trial 218/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1807 | Final Val Loss: 0.8184\n",
      "R2 Score: 0.4006\n",
      "MSE Score: 0.9573\n",
      "MAE Score: 0.8127\n",
      "\n",
      "Trial 219/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1689 | Final Val Loss: 0.6867\n",
      "R2 Score: 0.5159\n",
      "MSE Score: 0.7731\n",
      "MAE Score: 0.7351\n",
      "\n",
      "Trial 220/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2345 | Final Val Loss: 0.8855\n",
      "R2 Score: 0.4381\n",
      "MSE Score: 0.8974\n",
      "MAE Score: 0.7878\n",
      "\n",
      "Trial 221/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0961 | Final Val Loss: 1.2272\n",
      "R2 Score: 0.3153\n",
      "MSE Score: 1.0935\n",
      "MAE Score: 0.8536\n",
      "\n",
      "Trial 222/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7560 | Final Val Loss: 0.7583\n",
      "R2 Score: 0.4649\n",
      "MSE Score: 0.8546\n",
      "MAE Score: 0.8029\n",
      "\n",
      "Trial 223/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6773 | Final Val Loss: 1.5858\n",
      "R2 Score: 0.0277\n",
      "MSE Score: 1.5528\n",
      "MAE Score: 1.0728\n",
      "\n",
      "Trial 224/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6248 | Final Val Loss: 0.7424\n",
      "R2 Score: 0.5110\n",
      "MSE Score: 0.7809\n",
      "MAE Score: 0.7261\n",
      "\n",
      "Trial 225/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.0458 | Final Val Loss: 1.5764\n",
      "R2 Score: -0.0221\n",
      "MSE Score: 1.6323\n",
      "MAE Score: 1.0812\n",
      "\n",
      "Trial 226/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.0043 | Final Val Loss: 1.1549\n",
      "R2 Score: 0.3880\n",
      "MSE Score: 0.9774\n",
      "MAE Score: 0.8286\n",
      "\n",
      "Trial 227/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5953 | Final Val Loss: 5.9660\n",
      "R2 Score: -4.2292\n",
      "MSE Score: 8.3511\n",
      "MAE Score: 2.6209\n",
      "\n",
      "Trial 228/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.6886 | Final Val Loss: 9.2075\n",
      "R2 Score: -6.3626\n",
      "MSE Score: 11.7583\n",
      "MAE Score: 3.2117\n",
      "\n",
      "Trial 229/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1429 | Final Val Loss: 1.3605\n",
      "R2 Score: 0.0476\n",
      "MSE Score: 1.5210\n",
      "MAE Score: 1.0371\n",
      "\n",
      "Trial 230/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1047 | Final Val Loss: 1.0220\n",
      "R2 Score: 0.3343\n",
      "MSE Score: 1.0631\n",
      "MAE Score: 0.8506\n",
      "\n",
      "Trial 231/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.6211 | Final Val Loss: 8.6833\n",
      "R2 Score: -5.8139\n",
      "MSE Score: 10.8819\n",
      "MAE Score: 3.0710\n",
      "\n",
      "Trial 232/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.9261 | Final Val Loss: 6.4836\n",
      "R2 Score: -4.2697\n",
      "MSE Score: 8.4158\n",
      "MAE Score: 2.6447\n",
      "\n",
      "Trial 233/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3746 | Final Val Loss: 1.2993\n",
      "R2 Score: -0.0191\n",
      "MSE Score: 1.6275\n",
      "MAE Score: 1.0560\n",
      "\n",
      "Trial 234/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1046 | Final Val Loss: 1.0610\n",
      "R2 Score: 0.2078\n",
      "MSE Score: 1.2651\n",
      "MAE Score: 0.9444\n",
      "\n",
      "Trial 235/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0378 | Final Val Loss: 0.8300\n",
      "R2 Score: 0.3310\n",
      "MSE Score: 1.0684\n",
      "MAE Score: 0.8280\n",
      "\n",
      "Trial 236/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3804 | Final Val Loss: 1.2068\n",
      "R2 Score: 0.0514\n",
      "MSE Score: 1.5150\n",
      "MAE Score: 1.0370\n",
      "\n",
      "Trial 237/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0854 | Final Val Loss: 0.8851\n",
      "R2 Score: 0.3577\n",
      "MSE Score: 1.0258\n",
      "MAE Score: 0.8229\n",
      "\n",
      "Trial 238/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8534 | Final Val Loss: 1.0515\n",
      "R2 Score: 0.2405\n",
      "MSE Score: 1.2129\n",
      "MAE Score: 0.9098\n",
      "\n",
      "Trial 239/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.0799 | Final Val Loss: 1.0391\n",
      "R2 Score: 0.2162\n",
      "MSE Score: 1.2517\n",
      "MAE Score: 0.8726\n",
      "\n",
      "Trial 240/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5313 | Final Val Loss: 0.8570\n",
      "R2 Score: 0.2183\n",
      "MSE Score: 1.2484\n",
      "MAE Score: 0.9072\n",
      "\n",
      "Trial 241/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0380 | Final Val Loss: 0.9768\n",
      "R2 Score: 0.4741\n",
      "MSE Score: 0.8399\n",
      "MAE Score: 0.7583\n",
      "\n",
      "Trial 242/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8323 | Final Val Loss: 0.8151\n",
      "R2 Score: 0.4844\n",
      "MSE Score: 0.8235\n",
      "MAE Score: 0.7340\n",
      "\n",
      "Trial 243/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.1738 | Final Val Loss: 7.1199\n",
      "R2 Score: -4.7169\n",
      "MSE Score: 9.1300\n",
      "MAE Score: 2.8361\n",
      "\n",
      "Trial 244/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5562 | Final Val Loss: 4.9882\n",
      "R2 Score: -3.2549\n",
      "MSE Score: 6.7952\n",
      "MAE Score: 2.3919\n",
      "\n",
      "Trial 245/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9580 | Final Val Loss: 0.8539\n",
      "R2 Score: 0.3211\n",
      "MSE Score: 1.0842\n",
      "MAE Score: 0.8562\n",
      "\n",
      "Trial 246/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3208 | Final Val Loss: 0.8585\n",
      "R2 Score: 0.4684\n",
      "MSE Score: 0.8490\n",
      "MAE Score: 0.7959\n",
      "\n",
      "Trial 247/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.0122 | Final Val Loss: 7.7094\n",
      "R2 Score: -5.3721\n",
      "MSE Score: 10.1764\n",
      "MAE Score: 2.9753\n",
      "\n",
      "Trial 248/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.6052 | Final Val Loss: 5.7418\n",
      "R2 Score: -3.6124\n",
      "MSE Score: 7.3661\n",
      "MAE Score: 2.5160\n",
      "\n",
      "Trial 249/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6495 | Final Val Loss: 0.4920\n",
      "R2 Score: 0.4937\n",
      "MSE Score: 0.8086\n",
      "MAE Score: 0.7216\n",
      "\n",
      "Trial 250/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9857 | Final Val Loss: 0.6963\n",
      "R2 Score: 0.5383\n",
      "MSE Score: 0.7373\n",
      "MAE Score: 0.7781\n",
      "\n",
      "Trial 251/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0854 | Final Val Loss: 0.5824\n",
      "R2 Score: 0.4310\n",
      "MSE Score: 0.9087\n",
      "MAE Score: 0.7704\n",
      "\n",
      "Trial 252/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2259 | Final Val Loss: 0.7700\n",
      "R2 Score: 0.4830\n",
      "MSE Score: 0.8257\n",
      "MAE Score: 0.7326\n",
      "\n",
      "Trial 253/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2211 | Final Val Loss: 1.0432\n",
      "R2 Score: 0.3788\n",
      "MSE Score: 0.9921\n",
      "MAE Score: 0.8303\n",
      "\n",
      "Trial 254/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1518 | Final Val Loss: 1.2010\n",
      "R2 Score: 0.2934\n",
      "MSE Score: 1.1284\n",
      "MAE Score: 0.8426\n",
      "\n",
      "Trial 255/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0441 | Final Val Loss: 0.7313\n",
      "R2 Score: 0.5474\n",
      "MSE Score: 0.7229\n",
      "MAE Score: 0.6998\n",
      "\n",
      "Trial 256/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0952 | Final Val Loss: 0.5954\n",
      "R2 Score: 0.4896\n",
      "MSE Score: 0.8151\n",
      "MAE Score: 0.7093\n",
      "\n",
      "Trial 257/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3954 | Final Val Loss: 1.5714\n",
      "R2 Score: -0.0103\n",
      "MSE Score: 1.6135\n",
      "MAE Score: 1.1049\n",
      "\n",
      "Trial 258/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5632 | Final Val Loss: 1.2301\n",
      "R2 Score: 0.2326\n",
      "MSE Score: 1.2256\n",
      "MAE Score: 0.9545\n",
      "\n",
      "Trial 259/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8312 | Final Val Loss: 7.3054\n",
      "R2 Score: -4.7268\n",
      "MSE Score: 9.1458\n",
      "MAE Score: 2.7926\n",
      "\n",
      "Trial 260/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7648 | Final Val Loss: 6.5673\n",
      "R2 Score: -4.4408\n",
      "MSE Score: 8.6891\n",
      "MAE Score: 2.6999\n",
      "\n",
      "Trial 261/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.4174 | Final Val Loss: 0.9856\n",
      "R2 Score: 0.2187\n",
      "MSE Score: 1.2477\n",
      "MAE Score: 0.9476\n",
      "\n",
      "Trial 262/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6027 | Final Val Loss: 0.9590\n",
      "R2 Score: 0.0669\n",
      "MSE Score: 1.4903\n",
      "MAE Score: 0.9755\n",
      "\n",
      "Trial 263/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.2261 | Final Val Loss: 7.0865\n",
      "R2 Score: -4.8670\n",
      "MSE Score: 9.3697\n",
      "MAE Score: 2.8351\n",
      "\n",
      "Trial 264/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.0454 | Final Val Loss: 6.0986\n",
      "R2 Score: -4.1467\n",
      "MSE Score: 8.2195\n",
      "MAE Score: 2.6121\n",
      "\n",
      "Trial 265/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1756 | Final Val Loss: 1.1224\n",
      "R2 Score: 0.2715\n",
      "MSE Score: 1.1634\n",
      "MAE Score: 0.8610\n",
      "\n",
      "Trial 266/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2527 | Final Val Loss: 0.9130\n",
      "R2 Score: 0.3160\n",
      "MSE Score: 1.0924\n",
      "MAE Score: 0.8877\n",
      "\n",
      "Trial 267/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3046 | Final Val Loss: 1.7661\n",
      "R2 Score: -0.2346\n",
      "MSE Score: 1.9717\n",
      "MAE Score: 1.1586\n",
      "\n",
      "Trial 268/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0818 | Final Val Loss: 1.0508\n",
      "R2 Score: 0.0368\n",
      "MSE Score: 1.5383\n",
      "MAE Score: 1.0637\n",
      "\n",
      "Trial 269/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3328 | Final Val Loss: 1.1595\n",
      "R2 Score: 0.3369\n",
      "MSE Score: 1.0589\n",
      "MAE Score: 0.9041\n",
      "\n",
      "Trial 270/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5742 | Final Val Loss: 1.1148\n",
      "R2 Score: 0.1040\n",
      "MSE Score: 1.4310\n",
      "MAE Score: 1.0095\n",
      "\n",
      "Trial 271/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.9250 | Final Val Loss: 0.8607\n",
      "R2 Score: -0.2126\n",
      "MSE Score: 1.9366\n",
      "MAE Score: 1.1186\n",
      "\n",
      "Trial 272/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.9886 | Final Val Loss: 1.9891\n",
      "R2 Score: -0.8348\n",
      "MSE Score: 2.9302\n",
      "MAE Score: 1.4598\n",
      "\n",
      "Trial 273/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8888 | Final Val Loss: 0.7225\n",
      "R2 Score: 0.5374\n",
      "MSE Score: 0.7388\n",
      "MAE Score: 0.6788\n",
      "\n",
      "Trial 274/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 3.8144 | Final Val Loss: 1.8323\n",
      "R2 Score: -0.4312\n",
      "MSE Score: 2.2856\n",
      "MAE Score: 1.3042\n",
      "\n",
      "Trial 275/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.6770 | Final Val Loss: 7.6117\n",
      "R2 Score: -5.4599\n",
      "MSE Score: 10.3167\n",
      "MAE Score: 3.0142\n",
      "\n",
      "Trial 276/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.0152 | Final Val Loss: 7.6750\n",
      "R2 Score: -5.0278\n",
      "MSE Score: 9.6265\n",
      "MAE Score: 2.9110\n",
      "\n",
      "Trial 277/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3505 | Final Val Loss: 0.9780\n",
      "R2 Score: 0.3834\n",
      "MSE Score: 0.9848\n",
      "MAE Score: 0.8260\n",
      "\n",
      "Trial 278/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0095 | Final Val Loss: 0.5962\n",
      "R2 Score: 0.5007\n",
      "MSE Score: 0.7973\n",
      "MAE Score: 0.7712\n",
      "\n",
      "Trial 279/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.4184 | Final Val Loss: 6.6807\n",
      "R2 Score: -4.3818\n",
      "MSE Score: 8.5948\n",
      "MAE Score: 2.7227\n",
      "\n",
      "Trial 280/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.8047 | Final Val Loss: 6.5292\n",
      "R2 Score: -4.2590\n",
      "MSE Score: 8.3988\n",
      "MAE Score: 2.6654\n",
      "\n",
      "Trial 281/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7981 | Final Val Loss: 0.4933\n",
      "R2 Score: 0.5976\n",
      "MSE Score: 0.6426\n",
      "MAE Score: 0.5999\n",
      "\n",
      "Trial 282/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5922 | Final Val Loss: 0.7307\n",
      "R2 Score: 0.5299\n",
      "MSE Score: 0.7508\n",
      "MAE Score: 0.6614\n",
      "\n",
      "Trial 283/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8314 | Final Val Loss: 0.7306\n",
      "R2 Score: 0.5196\n",
      "MSE Score: 0.7672\n",
      "MAE Score: 0.7331\n",
      "\n",
      "Trial 284/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8743 | Final Val Loss: 0.5108\n",
      "R2 Score: 0.5656\n",
      "MSE Score: 0.6938\n",
      "MAE Score: 0.6963\n",
      "\n",
      "Trial 285/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9305 | Final Val Loss: 0.7645\n",
      "R2 Score: 0.3896\n",
      "MSE Score: 0.9748\n",
      "MAE Score: 0.8704\n",
      "\n",
      "Trial 286/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1673 | Final Val Loss: 1.4351\n",
      "R2 Score: 0.2360\n",
      "MSE Score: 1.2201\n",
      "MAE Score: 0.9258\n",
      "\n",
      "Trial 287/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9449 | Final Val Loss: 0.6468\n",
      "R2 Score: 0.5491\n",
      "MSE Score: 0.7201\n",
      "MAE Score: 0.7109\n",
      "\n",
      "Trial 288/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9650 | Final Val Loss: 0.4351\n",
      "R2 Score: 0.6768\n",
      "MSE Score: 0.5162\n",
      "MAE Score: 0.5868\n",
      "New best R2 score!\n",
      "\n",
      "Grid search completed for this dataset!\n",
      "\n",
      "Best parameters found:\n",
      "num_epochs: 450\n",
      "num_units: [16, 16, 8, 8]\n",
      "drop: 0.3\n",
      "lr: 0.0001\n",
      "decay: 1e-05\n",
      "acts: tanh\n",
      "opts: sgd\n",
      "patience: 15\n",
      "\n",
      "Best metrics:\n",
      "R2: 0.6768\n",
      "MSE: 0.5162\n",
      "MAE: 0.5868\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing dataset: filtered_001.csv\n",
      "==================================================\n",
      "Total parameter combinations to try: 288\n",
      "\n",
      "Trial 1/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2082 | Final Val Loss: 1.2931\n",
      "R2 Score: 0.0314\n",
      "MSE Score: 1.2807\n",
      "MAE Score: 0.9273\n",
      "New best R2 score!\n",
      "\n",
      "Trial 2/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20332\\425057010.py:142: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_trials_df = pd.concat([all_trials_df, pd.DataFrame([trial_results])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train loss: 0.9839 | Final Val Loss: 1.9452\n",
      "R2 Score: -0.3289\n",
      "MSE Score: 1.7571\n",
      "MAE Score: 1.1499\n",
      "\n",
      "Trial 3/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.4051 | Final Val Loss: 8.9467\n",
      "R2 Score: -6.8633\n",
      "MSE Score: 10.3971\n",
      "MAE Score: 3.0501\n",
      "\n",
      "Trial 4/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.3525 | Final Val Loss: 12.6763\n",
      "R2 Score: -10.2819\n",
      "MSE Score: 14.9173\n",
      "MAE Score: 3.7049\n",
      "\n",
      "Trial 5/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4756 | Final Val Loss: 2.1991\n",
      "R2 Score: -0.6659\n",
      "MSE Score: 2.2027\n",
      "MAE Score: 1.2269\n",
      "\n",
      "Trial 6/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4136 | Final Val Loss: 1.8730\n",
      "R2 Score: -0.7792\n",
      "MSE Score: 2.3526\n",
      "MAE Score: 1.2195\n",
      "\n",
      "Trial 7/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.1621 | Final Val Loss: 9.7597\n",
      "R2 Score: -7.5769\n",
      "MSE Score: 11.3405\n",
      "MAE Score: 3.1776\n",
      "\n",
      "Trial 8/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.1505 | Final Val Loss: 8.4555\n",
      "R2 Score: -6.6748\n",
      "MSE Score: 10.1478\n",
      "MAE Score: 2.9666\n",
      "\n",
      "Trial 9/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9694 | Final Val Loss: 1.4668\n",
      "R2 Score: -0.0426\n",
      "MSE Score: 1.3786\n",
      "MAE Score: 0.9647\n",
      "\n",
      "Trial 10/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1767 | Final Val Loss: 1.6768\n",
      "R2 Score: -0.0396\n",
      "MSE Score: 1.3745\n",
      "MAE Score: 0.9767\n",
      "\n",
      "Trial 11/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9656 | Final Val Loss: 1.5588\n",
      "R2 Score: -0.1327\n",
      "MSE Score: 1.4977\n",
      "MAE Score: 0.9493\n",
      "\n",
      "Trial 12/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2554 | Final Val Loss: 0.9278\n",
      "R2 Score: -0.3229\n",
      "MSE Score: 1.7492\n",
      "MAE Score: 1.1595\n",
      "\n",
      "Trial 13/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1270 | Final Val Loss: 1.8628\n",
      "R2 Score: -0.3468\n",
      "MSE Score: 1.7808\n",
      "MAE Score: 1.1063\n",
      "\n",
      "Trial 14/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3942 | Final Val Loss: 2.1719\n",
      "R2 Score: -0.0754\n",
      "MSE Score: 1.4220\n",
      "MAE Score: 1.0700\n",
      "\n",
      "Trial 15/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5037 | Final Val Loss: 1.3363\n",
      "R2 Score: -0.2772\n",
      "MSE Score: 1.6887\n",
      "MAE Score: 1.0641\n",
      "\n",
      "Trial 16/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7640 | Final Val Loss: 2.7230\n",
      "R2 Score: -1.2563\n",
      "MSE Score: 2.9834\n",
      "MAE Score: 1.4460\n",
      "\n",
      "Trial 17/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8182 | Final Val Loss: 1.6840\n",
      "R2 Score: 0.4465\n",
      "MSE Score: 0.7319\n",
      "MAE Score: 0.6147\n",
      "New best R2 score!\n",
      "\n",
      "Trial 18/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7190 | Final Val Loss: 1.4965\n",
      "R2 Score: 0.4121\n",
      "MSE Score: 0.7773\n",
      "MAE Score: 0.6395\n",
      "\n",
      "Trial 19/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.1461 | Final Val Loss: 8.8382\n",
      "R2 Score: -6.5883\n",
      "MSE Score: 10.0335\n",
      "MAE Score: 3.0315\n",
      "\n",
      "Trial 20/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.4856 | Final Val Loss: 10.4839\n",
      "R2 Score: -7.9098\n",
      "MSE Score: 11.7808\n",
      "MAE Score: 3.2902\n",
      "\n",
      "Trial 21/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8546 | Final Val Loss: 1.6141\n",
      "R2 Score: 0.3801\n",
      "MSE Score: 0.8197\n",
      "MAE Score: 0.6319\n",
      "\n",
      "Trial 22/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9514 | Final Val Loss: 1.6729\n",
      "R2 Score: 0.1806\n",
      "MSE Score: 1.0834\n",
      "MAE Score: 0.8034\n",
      "\n",
      "Trial 23/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.0920 | Final Val Loss: 8.2762\n",
      "R2 Score: -6.0365\n",
      "MSE Score: 9.3038\n",
      "MAE Score: 2.8791\n",
      "\n",
      "Trial 24/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.2148 | Final Val Loss: 8.7987\n",
      "R2 Score: -6.5927\n",
      "MSE Score: 10.0393\n",
      "MAE Score: 3.0163\n",
      "\n",
      "Trial 25/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6602 | Final Val Loss: 1.6075\n",
      "R2 Score: 0.1473\n",
      "MSE Score: 1.1275\n",
      "MAE Score: 0.7700\n",
      "\n",
      "Trial 26/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6234 | Final Val Loss: 1.6345\n",
      "R2 Score: 0.1547\n",
      "MSE Score: 1.1176\n",
      "MAE Score: 0.7386\n",
      "\n",
      "Trial 27/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5812 | Final Val Loss: 1.6215\n",
      "R2 Score: 0.3321\n",
      "MSE Score: 0.8831\n",
      "MAE Score: 0.6586\n",
      "\n",
      "Trial 28/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7670 | Final Val Loss: 1.7191\n",
      "R2 Score: 0.3281\n",
      "MSE Score: 0.8884\n",
      "MAE Score: 0.6717\n",
      "\n",
      "Trial 29/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6106 | Final Val Loss: 1.6240\n",
      "R2 Score: 0.2635\n",
      "MSE Score: 0.9739\n",
      "MAE Score: 0.7090\n",
      "\n",
      "Trial 30/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6067 | Final Val Loss: 1.6918\n",
      "R2 Score: 0.2757\n",
      "MSE Score: 0.9577\n",
      "MAE Score: 0.6739\n",
      "\n",
      "Trial 31/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8434 | Final Val Loss: 1.5988\n",
      "R2 Score: 0.2974\n",
      "MSE Score: 0.9290\n",
      "MAE Score: 0.6540\n",
      "\n",
      "Trial 32/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6917 | Final Val Loss: 1.5546\n",
      "R2 Score: 0.1641\n",
      "MSE Score: 1.1053\n",
      "MAE Score: 0.7227\n",
      "\n",
      "Trial 33/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3417 | Final Val Loss: 1.7452\n",
      "R2 Score: 0.1523\n",
      "MSE Score: 1.1208\n",
      "MAE Score: 0.8536\n",
      "\n",
      "Trial 34/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0979 | Final Val Loss: 1.6446\n",
      "R2 Score: -0.2867\n",
      "MSE Score: 1.7013\n",
      "MAE Score: 1.0817\n",
      "\n",
      "Trial 35/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.1538 | Final Val Loss: 10.4668\n",
      "R2 Score: -8.5311\n",
      "MSE Score: 12.6022\n",
      "MAE Score: 3.3727\n",
      "\n",
      "Trial 36/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3593 | Final Val Loss: 11.5999\n",
      "R2 Score: -9.1519\n",
      "MSE Score: 13.4231\n",
      "MAE Score: 3.5110\n",
      "\n",
      "Trial 37/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5617 | Final Val Loss: 2.3336\n",
      "R2 Score: -0.8894\n",
      "MSE Score: 2.4982\n",
      "MAE Score: 1.2832\n",
      "\n",
      "Trial 38/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.0719 | Final Val Loss: 1.9167\n",
      "R2 Score: -0.1482\n",
      "MSE Score: 1.5181\n",
      "MAE Score: 1.0574\n",
      "\n",
      "Trial 39/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.3561 | Final Val Loss: 9.2091\n",
      "R2 Score: -7.5816\n",
      "MSE Score: 11.3469\n",
      "MAE Score: 3.1944\n",
      "\n",
      "Trial 40/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.9242 | Final Val Loss: 9.2733\n",
      "R2 Score: -7.3970\n",
      "MSE Score: 11.1028\n",
      "MAE Score: 3.1199\n",
      "\n",
      "Trial 41/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1086 | Final Val Loss: 1.9429\n",
      "R2 Score: 0.0924\n",
      "MSE Score: 1.2000\n",
      "MAE Score: 0.8881\n",
      "\n",
      "Trial 42/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9061 | Final Val Loss: 1.4466\n",
      "R2 Score: 0.1359\n",
      "MSE Score: 1.1425\n",
      "MAE Score: 0.9078\n",
      "\n",
      "Trial 43/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1417 | Final Val Loss: 1.4259\n",
      "R2 Score: -0.1203\n",
      "MSE Score: 1.4812\n",
      "MAE Score: 1.0279\n",
      "\n",
      "Trial 44/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8113 | Final Val Loss: 2.4864\n",
      "R2 Score: -0.4233\n",
      "MSE Score: 1.8819\n",
      "MAE Score: 1.2147\n",
      "\n",
      "Trial 45/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3779 | Final Val Loss: 2.6578\n",
      "R2 Score: -0.2764\n",
      "MSE Score: 1.6877\n",
      "MAE Score: 1.1825\n",
      "\n",
      "Trial 46/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0897 | Final Val Loss: 1.5114\n",
      "R2 Score: 0.0763\n",
      "MSE Score: 1.2213\n",
      "MAE Score: 0.9233\n",
      "\n",
      "Trial 47/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5623 | Final Val Loss: 2.1173\n",
      "R2 Score: -1.2229\n",
      "MSE Score: 2.9391\n",
      "MAE Score: 1.4739\n",
      "\n",
      "Trial 48/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2941 | Final Val Loss: 2.7076\n",
      "R2 Score: -0.5806\n",
      "MSE Score: 2.0899\n",
      "MAE Score: 1.1819\n",
      "\n",
      "Trial 49/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.6153 | Final Val Loss: 1.6232\n",
      "R2 Score: 0.4915\n",
      "MSE Score: 0.6723\n",
      "MAE Score: 0.6351\n",
      "New best R2 score!\n",
      "\n",
      "Trial 50/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8277 | Final Val Loss: 1.7602\n",
      "R2 Score: 0.2552\n",
      "MSE Score: 0.9848\n",
      "MAE Score: 0.7729\n",
      "\n",
      "Trial 51/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2267 | Final Val Loss: 7.9147\n",
      "R2 Score: -5.5736\n",
      "MSE Score: 8.6917\n",
      "MAE Score: 2.8111\n",
      "\n",
      "Trial 52/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.0353 | Final Val Loss: 9.1475\n",
      "R2 Score: -6.7503\n",
      "MSE Score: 10.2476\n",
      "MAE Score: 3.0631\n",
      "\n",
      "Trial 53/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0418 | Final Val Loss: 1.8880\n",
      "R2 Score: 0.2914\n",
      "MSE Score: 0.9369\n",
      "MAE Score: 0.6999\n",
      "\n",
      "Trial 54/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9412 | Final Val Loss: 1.6843\n",
      "R2 Score: 0.4288\n",
      "MSE Score: 0.7552\n",
      "MAE Score: 0.6884\n",
      "\n",
      "Trial 55/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.9363 | Final Val Loss: 7.8945\n",
      "R2 Score: -5.8853\n",
      "MSE Score: 9.1039\n",
      "MAE Score: 2.8464\n",
      "\n",
      "Trial 56/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.6710 | Final Val Loss: 9.3135\n",
      "R2 Score: -6.7940\n",
      "MSE Score: 10.3054\n",
      "MAE Score: 3.0565\n",
      "\n",
      "Trial 57/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5626 | Final Val Loss: 1.6775\n",
      "R2 Score: 0.2056\n",
      "MSE Score: 1.0504\n",
      "MAE Score: 0.6709\n",
      "\n",
      "Trial 58/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7150 | Final Val Loss: 1.6358\n",
      "R2 Score: 0.2614\n",
      "MSE Score: 0.9766\n",
      "MAE Score: 0.7238\n",
      "\n",
      "Trial 59/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3058 | Final Val Loss: 1.6981\n",
      "R2 Score: -0.0281\n",
      "MSE Score: 1.3594\n",
      "MAE Score: 0.8110\n",
      "\n",
      "Trial 60/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6020 | Final Val Loss: 1.5925\n",
      "R2 Score: 0.3779\n",
      "MSE Score: 0.8226\n",
      "MAE Score: 0.6219\n",
      "\n",
      "Trial 61/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5686 | Final Val Loss: 1.5960\n",
      "R2 Score: 0.3628\n",
      "MSE Score: 0.8426\n",
      "MAE Score: 0.7171\n",
      "\n",
      "Trial 62/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6595 | Final Val Loss: 1.5860\n",
      "R2 Score: 0.3873\n",
      "MSE Score: 0.8101\n",
      "MAE Score: 0.6992\n",
      "\n",
      "Trial 63/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9566 | Final Val Loss: 1.7975\n",
      "R2 Score: 0.2350\n",
      "MSE Score: 1.0115\n",
      "MAE Score: 0.7212\n",
      "\n",
      "Trial 64/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6861 | Final Val Loss: 1.6886\n",
      "R2 Score: 0.1242\n",
      "MSE Score: 1.1580\n",
      "MAE Score: 0.7867\n",
      "\n",
      "Trial 65/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1566 | Final Val Loss: 1.9242\n",
      "R2 Score: 0.2327\n",
      "MSE Score: 1.0146\n",
      "MAE Score: 0.8274\n",
      "\n",
      "Trial 66/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9758 | Final Val Loss: 1.6008\n",
      "R2 Score: -0.2351\n",
      "MSE Score: 1.6331\n",
      "MAE Score: 1.0587\n",
      "\n",
      "Trial 67/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8757 | Final Val Loss: 10.9454\n",
      "R2 Score: -8.6801\n",
      "MSE Score: 12.7993\n",
      "MAE Score: 3.3995\n",
      "\n",
      "Trial 68/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.1650 | Final Val Loss: 11.0425\n",
      "R2 Score: -8.8978\n",
      "MSE Score: 13.0872\n",
      "MAE Score: 3.4613\n",
      "\n",
      "Trial 69/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4250 | Final Val Loss: 1.7708\n",
      "R2 Score: -0.2364\n",
      "MSE Score: 1.6348\n",
      "MAE Score: 1.0630\n",
      "\n",
      "Trial 70/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1250 | Final Val Loss: 1.5366\n",
      "R2 Score: -0.2849\n",
      "MSE Score: 1.6989\n",
      "MAE Score: 1.0679\n",
      "\n",
      "Trial 71/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.7397 | Final Val Loss: 9.8621\n",
      "R2 Score: -7.9872\n",
      "MSE Score: 11.8831\n",
      "MAE Score: 3.2694\n",
      "\n",
      "Trial 72/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.7292 | Final Val Loss: 11.8553\n",
      "R2 Score: -9.3837\n",
      "MSE Score: 13.7296\n",
      "MAE Score: 3.5345\n",
      "\n",
      "Trial 73/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8613 | Final Val Loss: 1.4236\n",
      "R2 Score: -0.1085\n",
      "MSE Score: 1.4656\n",
      "MAE Score: 1.0381\n",
      "\n",
      "Trial 74/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3589 | Final Val Loss: 1.6705\n",
      "R2 Score: 0.0015\n",
      "MSE Score: 1.3203\n",
      "MAE Score: 0.9904\n",
      "\n",
      "Trial 75/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7292 | Final Val Loss: 1.5954\n",
      "R2 Score: -0.0321\n",
      "MSE Score: 1.3647\n",
      "MAE Score: 1.0111\n",
      "\n",
      "Trial 76/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3701 | Final Val Loss: 2.7987\n",
      "R2 Score: -1.2184\n",
      "MSE Score: 2.9332\n",
      "MAE Score: 1.4555\n",
      "\n",
      "Trial 77/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9273 | Final Val Loss: 1.8148\n",
      "R2 Score: -0.0608\n",
      "MSE Score: 1.4027\n",
      "MAE Score: 0.9993\n",
      "\n",
      "Trial 78/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5733 | Final Val Loss: 2.1792\n",
      "R2 Score: -0.0428\n",
      "MSE Score: 1.3788\n",
      "MAE Score: 1.0023\n",
      "\n",
      "Trial 79/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6197 | Final Val Loss: 2.1738\n",
      "R2 Score: -0.4690\n",
      "MSE Score: 1.9423\n",
      "MAE Score: 1.2137\n",
      "\n",
      "Trial 80/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3719 | Final Val Loss: 2.7113\n",
      "R2 Score: -0.7322\n",
      "MSE Score: 2.2904\n",
      "MAE Score: 1.3497\n",
      "\n",
      "Trial 81/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8328 | Final Val Loss: 1.5566\n",
      "R2 Score: 0.3390\n",
      "MSE Score: 0.8740\n",
      "MAE Score: 0.6996\n",
      "\n",
      "Trial 82/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7241 | Final Val Loss: 1.6498\n",
      "R2 Score: 0.4585\n",
      "MSE Score: 0.7160\n",
      "MAE Score: 0.6548\n",
      "\n",
      "Trial 83/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.7150 | Final Val Loss: 10.5840\n",
      "R2 Score: -8.0516\n",
      "MSE Score: 11.9683\n",
      "MAE Score: 3.3229\n",
      "\n",
      "Trial 84/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.4931 | Final Val Loss: 8.1249\n",
      "R2 Score: -5.6303\n",
      "MSE Score: 8.7668\n",
      "MAE Score: 2.7969\n",
      "\n",
      "Trial 85/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8253 | Final Val Loss: 1.6778\n",
      "R2 Score: 0.2977\n",
      "MSE Score: 0.9286\n",
      "MAE Score: 0.7113\n",
      "\n",
      "Trial 86/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0181 | Final Val Loss: 1.5474\n",
      "R2 Score: 0.1613\n",
      "MSE Score: 1.1089\n",
      "MAE Score: 0.7556\n",
      "\n",
      "Trial 87/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.6631 | Final Val Loss: 10.6503\n",
      "R2 Score: -8.2003\n",
      "MSE Score: 12.1648\n",
      "MAE Score: 3.3507\n",
      "\n",
      "Trial 88/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.1635 | Final Val Loss: 10.3259\n",
      "R2 Score: -7.2889\n",
      "MSE Score: 10.9598\n",
      "MAE Score: 3.1832\n",
      "\n",
      "Trial 89/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.4925 | Final Val Loss: 1.4810\n",
      "R2 Score: 0.2396\n",
      "MSE Score: 1.0054\n",
      "MAE Score: 0.6373\n",
      "\n",
      "Trial 90/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6718 | Final Val Loss: 1.6625\n",
      "R2 Score: 0.2490\n",
      "MSE Score: 0.9930\n",
      "MAE Score: 0.7305\n",
      "\n",
      "Trial 91/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7901 | Final Val Loss: 1.6127\n",
      "R2 Score: 0.1748\n",
      "MSE Score: 1.0910\n",
      "MAE Score: 0.7166\n",
      "\n",
      "Trial 92/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5793 | Final Val Loss: 1.7754\n",
      "R2 Score: 0.1876\n",
      "MSE Score: 1.0742\n",
      "MAE Score: 0.7254\n",
      "\n",
      "Trial 93/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9277 | Final Val Loss: 1.6973\n",
      "R2 Score: 0.3094\n",
      "MSE Score: 0.9132\n",
      "MAE Score: 0.6613\n",
      "\n",
      "Trial 94/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6434 | Final Val Loss: 1.7263\n",
      "R2 Score: 0.4056\n",
      "MSE Score: 0.7859\n",
      "MAE Score: 0.6837\n",
      "\n",
      "Trial 95/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.7594 | Final Val Loss: 1.9888\n",
      "R2 Score: -0.0006\n",
      "MSE Score: 1.3231\n",
      "MAE Score: 0.8922\n",
      "\n",
      "Trial 96/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0720 | Final Val Loss: 1.8281\n",
      "R2 Score: 0.2590\n",
      "MSE Score: 0.9798\n",
      "MAE Score: 0.7598\n",
      "\n",
      "Trial 97/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5338 | Final Val Loss: 1.6369\n",
      "R2 Score: -0.2323\n",
      "MSE Score: 1.6294\n",
      "MAE Score: 0.9913\n",
      "\n",
      "Trial 98/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3996 | Final Val Loss: 2.1825\n",
      "R2 Score: -0.4381\n",
      "MSE Score: 1.9015\n",
      "MAE Score: 1.1793\n",
      "\n",
      "Trial 99/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.9386 | Final Val Loss: 11.3277\n",
      "R2 Score: -8.4359\n",
      "MSE Score: 12.4764\n",
      "MAE Score: 3.3909\n",
      "\n",
      "Trial 100/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.7259 | Final Val Loss: 10.7478\n",
      "R2 Score: -8.8069\n",
      "MSE Score: 12.9669\n",
      "MAE Score: 3.4242\n",
      "\n",
      "Trial 101/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0094 | Final Val Loss: 2.0342\n",
      "R2 Score: -0.3190\n",
      "MSE Score: 1.7440\n",
      "MAE Score: 1.1361\n",
      "\n",
      "Trial 102/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7053 | Final Val Loss: 2.0098\n",
      "R2 Score: -0.3480\n",
      "MSE Score: 1.7823\n",
      "MAE Score: 1.1587\n",
      "\n",
      "Trial 103/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8200 | Final Val Loss: 10.3077\n",
      "R2 Score: -8.0813\n",
      "MSE Score: 12.0076\n",
      "MAE Score: 3.2721\n",
      "\n",
      "Trial 104/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.8126 | Final Val Loss: 8.8449\n",
      "R2 Score: -7.2902\n",
      "MSE Score: 10.9615\n",
      "MAE Score: 3.0908\n",
      "\n",
      "Trial 105/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7125 | Final Val Loss: 1.5822\n",
      "R2 Score: -0.0887\n",
      "MSE Score: 1.4395\n",
      "MAE Score: 1.0165\n",
      "\n",
      "Trial 106/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8494 | Final Val Loss: 1.8012\n",
      "R2 Score: -0.0545\n",
      "MSE Score: 1.3942\n",
      "MAE Score: 0.9894\n",
      "\n",
      "Trial 107/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5330 | Final Val Loss: 1.7673\n",
      "R2 Score: -1.0044\n",
      "MSE Score: 2.6502\n",
      "MAE Score: 1.3027\n",
      "\n",
      "Trial 108/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1664 | Final Val Loss: 1.5783\n",
      "R2 Score: -0.3381\n",
      "MSE Score: 1.7693\n",
      "MAE Score: 1.1084\n",
      "\n",
      "Trial 109/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6278 | Final Val Loss: 2.4127\n",
      "R2 Score: -0.3300\n",
      "MSE Score: 1.7585\n",
      "MAE Score: 1.2021\n",
      "\n",
      "Trial 110/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1437 | Final Val Loss: 1.8200\n",
      "R2 Score: -0.1397\n",
      "MSE Score: 1.5069\n",
      "MAE Score: 1.0555\n",
      "\n",
      "Trial 111/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4998 | Final Val Loss: 2.0373\n",
      "R2 Score: -0.6475\n",
      "MSE Score: 2.1784\n",
      "MAE Score: 1.2527\n",
      "\n",
      "Trial 112/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5220 | Final Val Loss: 2.1149\n",
      "R2 Score: -0.9555\n",
      "MSE Score: 2.5856\n",
      "MAE Score: 1.3430\n",
      "\n",
      "Trial 113/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0064 | Final Val Loss: 1.6309\n",
      "R2 Score: 0.3416\n",
      "MSE Score: 0.8706\n",
      "MAE Score: 0.6963\n",
      "\n",
      "Trial 114/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8575 | Final Val Loss: 1.6918\n",
      "R2 Score: 0.3309\n",
      "MSE Score: 0.8847\n",
      "MAE Score: 0.7233\n",
      "\n",
      "Trial 115/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7404 | Final Val Loss: 9.6751\n",
      "R2 Score: -7.6796\n",
      "MSE Score: 11.4764\n",
      "MAE Score: 3.2474\n",
      "\n",
      "Trial 116/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.2400 | Final Val Loss: 9.8665\n",
      "R2 Score: -7.1700\n",
      "MSE Score: 10.8026\n",
      "MAE Score: 3.1609\n",
      "\n",
      "Trial 117/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1255 | Final Val Loss: 1.7368\n",
      "R2 Score: 0.3369\n",
      "MSE Score: 0.8767\n",
      "MAE Score: 0.7250\n",
      "\n",
      "Trial 118/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9671 | Final Val Loss: 1.7305\n",
      "R2 Score: 0.2960\n",
      "MSE Score: 0.9309\n",
      "MAE Score: 0.7602\n",
      "\n",
      "Trial 119/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.8462 | Final Val Loss: 7.7184\n",
      "R2 Score: -5.5961\n",
      "MSE Score: 8.7215\n",
      "MAE Score: 2.7872\n",
      "\n",
      "Trial 120/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.0224 | Final Val Loss: 8.0852\n",
      "R2 Score: -5.8774\n",
      "MSE Score: 9.0935\n",
      "MAE Score: 2.8571\n",
      "\n",
      "Trial 121/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9280 | Final Val Loss: 1.7012\n",
      "R2 Score: 0.1298\n",
      "MSE Score: 1.1506\n",
      "MAE Score: 0.8591\n",
      "\n",
      "Trial 122/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6387 | Final Val Loss: 1.8048\n",
      "R2 Score: 0.3810\n",
      "MSE Score: 0.8185\n",
      "MAE Score: 0.6922\n",
      "\n",
      "Trial 123/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7018 | Final Val Loss: 1.5109\n",
      "R2 Score: 0.4513\n",
      "MSE Score: 0.7255\n",
      "MAE Score: 0.6375\n",
      "\n",
      "Trial 124/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7790 | Final Val Loss: 1.7365\n",
      "R2 Score: 0.2958\n",
      "MSE Score: 0.9311\n",
      "MAE Score: 0.7049\n",
      "\n",
      "Trial 125/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8285 | Final Val Loss: 1.6931\n",
      "R2 Score: 0.2696\n",
      "MSE Score: 0.9658\n",
      "MAE Score: 0.7198\n",
      "\n",
      "Trial 126/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6975 | Final Val Loss: 1.6535\n",
      "R2 Score: 0.4098\n",
      "MSE Score: 0.7803\n",
      "MAE Score: 0.7070\n",
      "\n",
      "Trial 127/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8665 | Final Val Loss: 1.5900\n",
      "R2 Score: 0.2329\n",
      "MSE Score: 1.0142\n",
      "MAE Score: 0.7234\n",
      "\n",
      "Trial 128/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0657 | Final Val Loss: 1.6045\n",
      "R2 Score: 0.2705\n",
      "MSE Score: 0.9645\n",
      "MAE Score: 0.6917\n",
      "\n",
      "Trial 129/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5186 | Final Val Loss: 2.2122\n",
      "R2 Score: -0.5826\n",
      "MSE Score: 2.0925\n",
      "MAE Score: 1.2010\n",
      "\n",
      "Trial 130/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3989 | Final Val Loss: 1.9939\n",
      "R2 Score: -0.1470\n",
      "MSE Score: 1.5166\n",
      "MAE Score: 0.9981\n",
      "\n",
      "Trial 131/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8487 | Final Val Loss: 10.6168\n",
      "R2 Score: -9.6462\n",
      "MSE Score: 14.0767\n",
      "MAE Score: 3.5712\n",
      "\n",
      "Trial 132/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.7056 | Final Val Loss: 12.2286\n",
      "R2 Score: -9.2660\n",
      "MSE Score: 13.5740\n",
      "MAE Score: 3.4956\n",
      "\n",
      "Trial 133/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5130 | Final Val Loss: 1.8778\n",
      "R2 Score: -0.1751\n",
      "MSE Score: 1.5538\n",
      "MAE Score: 1.0152\n",
      "\n",
      "Trial 134/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.5096 | Final Val Loss: 3.3587\n",
      "R2 Score: -0.7502\n",
      "MSE Score: 2.3142\n",
      "MAE Score: 1.3986\n",
      "\n",
      "Trial 135/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8624 | Final Val Loss: 10.2358\n",
      "R2 Score: -8.7045\n",
      "MSE Score: 12.8315\n",
      "MAE Score: 3.4058\n",
      "\n",
      "Trial 136/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9168 | Final Val Loss: 9.9439\n",
      "R2 Score: -7.6253\n",
      "MSE Score: 11.4046\n",
      "MAE Score: 3.1971\n",
      "\n",
      "Trial 137/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0068 | Final Val Loss: 1.4068\n",
      "R2 Score: -0.2185\n",
      "MSE Score: 1.6111\n",
      "MAE Score: 0.9472\n",
      "\n",
      "Trial 138/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0962 | Final Val Loss: 1.9762\n",
      "R2 Score: 0.0426\n",
      "MSE Score: 1.2659\n",
      "MAE Score: 0.8955\n",
      "\n",
      "Trial 139/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3179 | Final Val Loss: 1.5413\n",
      "R2 Score: -1.6611\n",
      "MSE Score: 3.5186\n",
      "MAE Score: 1.6154\n",
      "\n",
      "Trial 140/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5049 | Final Val Loss: 2.4598\n",
      "R2 Score: -1.8672\n",
      "MSE Score: 3.7910\n",
      "MAE Score: 1.6890\n",
      "\n",
      "Trial 141/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1559 | Final Val Loss: 2.2544\n",
      "R2 Score: -0.1149\n",
      "MSE Score: 1.4742\n",
      "MAE Score: 1.0279\n",
      "\n",
      "Trial 142/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4936 | Final Val Loss: 2.1001\n",
      "R2 Score: -0.7424\n",
      "MSE Score: 2.3039\n",
      "MAE Score: 1.3061\n",
      "\n",
      "Trial 143/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5437 | Final Val Loss: 2.0203\n",
      "R2 Score: -0.9037\n",
      "MSE Score: 2.5171\n",
      "MAE Score: 1.3411\n",
      "\n",
      "Trial 144/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6229 | Final Val Loss: 3.4755\n",
      "R2 Score: -2.3751\n",
      "MSE Score: 4.4627\n",
      "MAE Score: 1.8378\n",
      "\n",
      "Trial 145/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7323 | Final Val Loss: 1.6669\n",
      "R2 Score: 0.4005\n",
      "MSE Score: 0.7927\n",
      "MAE Score: 0.6687\n",
      "\n",
      "Trial 146/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7452 | Final Val Loss: 1.6167\n",
      "R2 Score: 0.1294\n",
      "MSE Score: 1.1511\n",
      "MAE Score: 0.7945\n",
      "\n",
      "Trial 147/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.1023 | Final Val Loss: 8.9645\n",
      "R2 Score: -6.6140\n",
      "MSE Score: 10.0674\n",
      "MAE Score: 3.0231\n",
      "\n",
      "Trial 148/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.4437 | Final Val Loss: 9.5282\n",
      "R2 Score: -7.0163\n",
      "MSE Score: 10.5993\n",
      "MAE Score: 3.1005\n",
      "\n",
      "Trial 149/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0015 | Final Val Loss: 1.7988\n",
      "R2 Score: 0.2324\n",
      "MSE Score: 1.0149\n",
      "MAE Score: 0.7491\n",
      "\n",
      "Trial 150/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2494 | Final Val Loss: 1.6263\n",
      "R2 Score: 0.2277\n",
      "MSE Score: 1.0211\n",
      "MAE Score: 0.7461\n",
      "\n",
      "Trial 151/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.1501 | Final Val Loss: 7.3950\n",
      "R2 Score: -4.7496\n",
      "MSE Score: 7.6022\n",
      "MAE Score: 2.6074\n",
      "\n",
      "Trial 152/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.5507 | Final Val Loss: 8.4318\n",
      "R2 Score: -6.1460\n",
      "MSE Score: 9.4486\n",
      "MAE Score: 2.9373\n",
      "\n",
      "Trial 153/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6492 | Final Val Loss: 1.6926\n",
      "R2 Score: 0.2891\n",
      "MSE Score: 0.9400\n",
      "MAE Score: 0.7034\n",
      "\n",
      "Trial 154/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6329 | Final Val Loss: 1.5211\n",
      "R2 Score: 0.4466\n",
      "MSE Score: 0.7317\n",
      "MAE Score: 0.6667\n",
      "\n",
      "Trial 155/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6673 | Final Val Loss: 1.4996\n",
      "R2 Score: 0.3855\n",
      "MSE Score: 0.8125\n",
      "MAE Score: 0.6977\n",
      "\n",
      "Trial 156/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5775 | Final Val Loss: 1.4858\n",
      "R2 Score: 0.2959\n",
      "MSE Score: 0.9310\n",
      "MAE Score: 0.6535\n",
      "\n",
      "Trial 157/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8223 | Final Val Loss: 1.6484\n",
      "R2 Score: 0.3204\n",
      "MSE Score: 0.8985\n",
      "MAE Score: 0.7582\n",
      "\n",
      "Trial 158/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8360 | Final Val Loss: 1.7618\n",
      "R2 Score: 0.1826\n",
      "MSE Score: 1.0807\n",
      "MAE Score: 0.7872\n",
      "\n",
      "Trial 159/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9064 | Final Val Loss: 1.6631\n",
      "R2 Score: 0.0972\n",
      "MSE Score: 1.1937\n",
      "MAE Score: 0.7448\n",
      "\n",
      "Trial 160/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8498 | Final Val Loss: 1.6946\n",
      "R2 Score: 0.2206\n",
      "MSE Score: 1.0305\n",
      "MAE Score: 0.7605\n",
      "\n",
      "Trial 161/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0597 | Final Val Loss: 1.6953\n",
      "R2 Score: -0.1324\n",
      "MSE Score: 1.4972\n",
      "MAE Score: 0.9388\n",
      "\n",
      "Trial 162/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5141 | Final Val Loss: 1.8787\n",
      "R2 Score: -0.1053\n",
      "MSE Score: 1.4614\n",
      "MAE Score: 1.0199\n",
      "\n",
      "Trial 163/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.1791 | Final Val Loss: 11.9087\n",
      "R2 Score: -10.5824\n",
      "MSE Score: 15.3146\n",
      "MAE Score: 3.7142\n",
      "\n",
      "Trial 164/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.6289 | Final Val Loss: 12.9148\n",
      "R2 Score: -11.5843\n",
      "MSE Score: 16.6393\n",
      "MAE Score: 3.9276\n",
      "\n",
      "Trial 165/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7300 | Final Val Loss: 2.2441\n",
      "R2 Score: -0.2267\n",
      "MSE Score: 1.6220\n",
      "MAE Score: 1.0500\n",
      "\n",
      "Trial 166/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4641 | Final Val Loss: 2.7386\n",
      "R2 Score: -0.9904\n",
      "MSE Score: 2.6317\n",
      "MAE Score: 1.4469\n",
      "\n",
      "Trial 167/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.5138 | Final Val Loss: 9.7539\n",
      "R2 Score: -7.4470\n",
      "MSE Score: 11.1688\n",
      "MAE Score: 3.1432\n",
      "\n",
      "Trial 168/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 5.8246 | Final Val Loss: 8.4133\n",
      "R2 Score: -6.3575\n",
      "MSE Score: 9.7283\n",
      "MAE Score: 2.9110\n",
      "\n",
      "Trial 169/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8656 | Final Val Loss: 1.8983\n",
      "R2 Score: -0.7361\n",
      "MSE Score: 2.2956\n",
      "MAE Score: 1.2972\n",
      "\n",
      "Trial 170/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0699 | Final Val Loss: 1.9096\n",
      "R2 Score: -0.3435\n",
      "MSE Score: 1.7765\n",
      "MAE Score: 1.1708\n",
      "\n",
      "Trial 171/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2435 | Final Val Loss: 1.7364\n",
      "R2 Score: -1.0382\n",
      "MSE Score: 2.6949\n",
      "MAE Score: 1.3553\n",
      "\n",
      "Trial 172/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5391 | Final Val Loss: 1.7432\n",
      "R2 Score: -0.5312\n",
      "MSE Score: 2.0247\n",
      "MAE Score: 1.2380\n",
      "\n",
      "Trial 173/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1959 | Final Val Loss: 2.0363\n",
      "R2 Score: -0.5503\n",
      "MSE Score: 2.0499\n",
      "MAE Score: 1.2419\n",
      "\n",
      "Trial 174/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2376 | Final Val Loss: 1.9597\n",
      "R2 Score: -0.3462\n",
      "MSE Score: 1.7800\n",
      "MAE Score: 1.1622\n",
      "\n",
      "Trial 175/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6816 | Final Val Loss: 3.4865\n",
      "R2 Score: -1.1938\n",
      "MSE Score: 2.9006\n",
      "MAE Score: 1.5246\n",
      "\n",
      "Trial 176/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3113 | Final Val Loss: 2.1123\n",
      "R2 Score: -0.3855\n",
      "MSE Score: 1.8319\n",
      "MAE Score: 1.1727\n",
      "\n",
      "Trial 177/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7338 | Final Val Loss: 1.6496\n",
      "R2 Score: 0.3818\n",
      "MSE Score: 0.8174\n",
      "MAE Score: 0.7132\n",
      "\n",
      "Trial 178/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8981 | Final Val Loss: 1.6660\n",
      "R2 Score: 0.3609\n",
      "MSE Score: 0.8450\n",
      "MAE Score: 0.7052\n",
      "\n",
      "Trial 179/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.4631 | Final Val Loss: 7.6728\n",
      "R2 Score: -5.2529\n",
      "MSE Score: 8.2677\n",
      "MAE Score: 2.7219\n",
      "\n",
      "Trial 180/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.1315 | Final Val Loss: 8.1171\n",
      "R2 Score: -6.1575\n",
      "MSE Score: 9.4638\n",
      "MAE Score: 2.8915\n",
      "\n",
      "Trial 181/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2057 | Final Val Loss: 1.7056\n",
      "R2 Score: 0.3606\n",
      "MSE Score: 0.8455\n",
      "MAE Score: 0.6760\n",
      "\n",
      "Trial 182/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0623 | Final Val Loss: 1.7861\n",
      "R2 Score: 0.2443\n",
      "MSE Score: 0.9992\n",
      "MAE Score: 0.7298\n",
      "\n",
      "Trial 183/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.5794 | Final Val Loss: 10.6573\n",
      "R2 Score: -8.0679\n",
      "MSE Score: 11.9898\n",
      "MAE Score: 3.3350\n",
      "\n",
      "Trial 184/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.3783 | Final Val Loss: 10.4044\n",
      "R2 Score: -7.7486\n",
      "MSE Score: 11.5676\n",
      "MAE Score: 3.2498\n",
      "\n",
      "Trial 185/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7178 | Final Val Loss: 1.4768\n",
      "R2 Score: 0.3399\n",
      "MSE Score: 0.8728\n",
      "MAE Score: 0.7245\n",
      "\n",
      "Trial 186/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6814 | Final Val Loss: 1.6619\n",
      "R2 Score: 0.3311\n",
      "MSE Score: 0.8845\n",
      "MAE Score: 0.6697\n",
      "\n",
      "Trial 187/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8372 | Final Val Loss: 1.5735\n",
      "R2 Score: 0.4049\n",
      "MSE Score: 0.7868\n",
      "MAE Score: 0.6628\n",
      "\n",
      "Trial 188/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7367 | Final Val Loss: 1.5756\n",
      "R2 Score: 0.1450\n",
      "MSE Score: 1.1305\n",
      "MAE Score: 0.7559\n",
      "\n",
      "Trial 189/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6941 | Final Val Loss: 1.6201\n",
      "R2 Score: 0.1207\n",
      "MSE Score: 1.1626\n",
      "MAE Score: 0.7980\n",
      "\n",
      "Trial 190/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8958 | Final Val Loss: 1.6344\n",
      "R2 Score: 0.3879\n",
      "MSE Score: 0.8093\n",
      "MAE Score: 0.6801\n",
      "\n",
      "Trial 191/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8177 | Final Val Loss: 1.6484\n",
      "R2 Score: 0.3083\n",
      "MSE Score: 0.9146\n",
      "MAE Score: 0.6731\n",
      "\n",
      "Trial 192/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9947 | Final Val Loss: 1.7385\n",
      "R2 Score: 0.3565\n",
      "MSE Score: 0.8509\n",
      "MAE Score: 0.6776\n",
      "\n",
      "Trial 193/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2805 | Final Val Loss: 1.5584\n",
      "R2 Score: 0.0365\n",
      "MSE Score: 1.2740\n",
      "MAE Score: 0.8577\n",
      "\n",
      "Trial 194/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1596 | Final Val Loss: 1.7917\n",
      "R2 Score: -0.1395\n",
      "MSE Score: 1.5066\n",
      "MAE Score: 0.9878\n",
      "\n",
      "Trial 195/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.2809 | Final Val Loss: 9.8588\n",
      "R2 Score: -8.4717\n",
      "MSE Score: 12.5238\n",
      "MAE Score: 3.3343\n",
      "\n",
      "Trial 196/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.1995 | Final Val Loss: 8.2969\n",
      "R2 Score: -5.9348\n",
      "MSE Score: 9.1694\n",
      "MAE Score: 2.8138\n",
      "\n",
      "Trial 197/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6435 | Final Val Loss: 2.5203\n",
      "R2 Score: -0.4319\n",
      "MSE Score: 1.8933\n",
      "MAE Score: 1.2060\n",
      "\n",
      "Trial 198/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.3677 | Final Val Loss: 2.3545\n",
      "R2 Score: -0.7795\n",
      "MSE Score: 2.3529\n",
      "MAE Score: 1.3082\n",
      "\n",
      "Trial 199/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.2624 | Final Val Loss: 11.6610\n",
      "R2 Score: -9.8546\n",
      "MSE Score: 14.3523\n",
      "MAE Score: 3.6136\n",
      "\n",
      "Trial 200/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9784 | Final Val Loss: 10.3015\n",
      "R2 Score: -8.3770\n",
      "MSE Score: 12.3985\n",
      "MAE Score: 3.3663\n",
      "\n",
      "Trial 201/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0054 | Final Val Loss: 2.0251\n",
      "R2 Score: -0.8160\n",
      "MSE Score: 2.4012\n",
      "MAE Score: 1.3910\n",
      "\n",
      "Trial 202/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8105 | Final Val Loss: 1.4768\n",
      "R2 Score: -0.1133\n",
      "MSE Score: 1.4720\n",
      "MAE Score: 1.0077\n",
      "\n",
      "Trial 203/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5744 | Final Val Loss: 2.7821\n",
      "R2 Score: -0.5375\n",
      "MSE Score: 2.0329\n",
      "MAE Score: 1.3045\n",
      "\n",
      "Trial 204/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9821 | Final Val Loss: 1.9821\n",
      "R2 Score: -0.8598\n",
      "MSE Score: 2.4591\n",
      "MAE Score: 1.3794\n",
      "\n",
      "Trial 205/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1616 | Final Val Loss: 1.6982\n",
      "R2 Score: -0.2302\n",
      "MSE Score: 1.6266\n",
      "MAE Score: 1.1074\n",
      "\n",
      "Trial 206/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1719 | Final Val Loss: 2.2469\n",
      "R2 Score: -0.0726\n",
      "MSE Score: 1.4182\n",
      "MAE Score: 1.0185\n",
      "\n",
      "Trial 207/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.0350 | Final Val Loss: 2.5105\n",
      "R2 Score: -1.1693\n",
      "MSE Score: 2.8683\n",
      "MAE Score: 1.5381\n",
      "\n",
      "Trial 208/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4193 | Final Val Loss: 2.8335\n",
      "R2 Score: -1.4427\n",
      "MSE Score: 3.2298\n",
      "MAE Score: 1.5918\n",
      "\n",
      "Trial 209/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9211 | Final Val Loss: 1.6637\n",
      "R2 Score: 0.4279\n",
      "MSE Score: 0.7564\n",
      "MAE Score: 0.7056\n",
      "\n",
      "Trial 210/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7481 | Final Val Loss: 1.6844\n",
      "R2 Score: 0.3397\n",
      "MSE Score: 0.8731\n",
      "MAE Score: 0.7136\n",
      "\n",
      "Trial 211/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2826 | Final Val Loss: 8.5161\n",
      "R2 Score: -5.8954\n",
      "MSE Score: 9.1173\n",
      "MAE Score: 2.8844\n",
      "\n",
      "Trial 212/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.2624 | Final Val Loss: 11.1215\n",
      "R2 Score: -8.2472\n",
      "MSE Score: 12.2269\n",
      "MAE Score: 3.3625\n",
      "\n",
      "Trial 213/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8730 | Final Val Loss: 1.7372\n",
      "R2 Score: 0.3781\n",
      "MSE Score: 0.8223\n",
      "MAE Score: 0.7265\n",
      "\n",
      "Trial 214/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7452 | Final Val Loss: 1.6615\n",
      "R2 Score: 0.2650\n",
      "MSE Score: 0.9718\n",
      "MAE Score: 0.7312\n",
      "\n",
      "Trial 215/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7256 | Final Val Loss: 9.5633\n",
      "R2 Score: -6.4934\n",
      "MSE Score: 9.9080\n",
      "MAE Score: 3.0171\n",
      "\n",
      "Trial 216/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.2599 | Final Val Loss: 9.7679\n",
      "R2 Score: -7.1831\n",
      "MSE Score: 10.8200\n",
      "MAE Score: 3.1334\n",
      "\n",
      "Trial 217/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7699 | Final Val Loss: 1.6234\n",
      "R2 Score: 0.3960\n",
      "MSE Score: 0.7986\n",
      "MAE Score: 0.7075\n",
      "\n",
      "Trial 218/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5083 | Final Val Loss: 1.5706\n",
      "R2 Score: 0.0520\n",
      "MSE Score: 1.2534\n",
      "MAE Score: 0.7985\n",
      "\n",
      "Trial 219/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8446 | Final Val Loss: 1.5686\n",
      "R2 Score: 0.1545\n",
      "MSE Score: 1.1179\n",
      "MAE Score: 0.7448\n",
      "\n",
      "Trial 220/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8683 | Final Val Loss: 1.3866\n",
      "R2 Score: 0.2993\n",
      "MSE Score: 0.9264\n",
      "MAE Score: 0.7023\n",
      "\n",
      "Trial 221/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9022 | Final Val Loss: 1.7116\n",
      "R2 Score: 0.1371\n",
      "MSE Score: 1.1409\n",
      "MAE Score: 0.8213\n",
      "\n",
      "Trial 222/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8080 | Final Val Loss: 1.6563\n",
      "R2 Score: 0.2317\n",
      "MSE Score: 1.0159\n",
      "MAE Score: 0.7267\n",
      "\n",
      "Trial 223/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9336 | Final Val Loss: 1.5110\n",
      "R2 Score: 0.1409\n",
      "MSE Score: 1.1359\n",
      "MAE Score: 0.7487\n",
      "\n",
      "Trial 224/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0620 | Final Val Loss: 1.6632\n",
      "R2 Score: 0.1822\n",
      "MSE Score: 1.0814\n",
      "MAE Score: 0.6662\n",
      "\n",
      "Trial 225/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6454 | Final Val Loss: 2.1882\n",
      "R2 Score: -0.4182\n",
      "MSE Score: 1.8752\n",
      "MAE Score: 1.1063\n",
      "\n",
      "Trial 226/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5265 | Final Val Loss: 1.8215\n",
      "R2 Score: -0.6188\n",
      "MSE Score: 2.1404\n",
      "MAE Score: 1.1954\n",
      "\n",
      "Trial 227/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.7798 | Final Val Loss: 9.1746\n",
      "R2 Score: -7.5752\n",
      "MSE Score: 11.3383\n",
      "MAE Score: 3.1924\n",
      "\n",
      "Trial 228/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.9942 | Final Val Loss: 10.8791\n",
      "R2 Score: -8.3348\n",
      "MSE Score: 12.3427\n",
      "MAE Score: 3.3467\n",
      "\n",
      "Trial 229/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6681 | Final Val Loss: 2.4173\n",
      "R2 Score: -0.5625\n",
      "MSE Score: 2.0660\n",
      "MAE Score: 1.1840\n",
      "\n",
      "Trial 230/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1523 | Final Val Loss: 2.4228\n",
      "R2 Score: -0.5114\n",
      "MSE Score: 1.9984\n",
      "MAE Score: 1.2039\n",
      "\n",
      "Trial 231/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.4685 | Final Val Loss: 8.9248\n",
      "R2 Score: -7.9223\n",
      "MSE Score: 11.7973\n",
      "MAE Score: 3.2361\n",
      "\n",
      "Trial 232/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.8433 | Final Val Loss: 9.5552\n",
      "R2 Score: -7.9747\n",
      "MSE Score: 11.8665\n",
      "MAE Score: 3.2549\n",
      "\n",
      "Trial 233/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6907 | Final Val Loss: 1.4016\n",
      "R2 Score: 0.2037\n",
      "MSE Score: 1.0529\n",
      "MAE Score: 0.8516\n",
      "\n",
      "Trial 234/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0238 | Final Val Loss: 1.9337\n",
      "R2 Score: -0.3875\n",
      "MSE Score: 1.8345\n",
      "MAE Score: 1.1876\n",
      "\n",
      "Trial 235/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4892 | Final Val Loss: 2.9347\n",
      "R2 Score: -1.1840\n",
      "MSE Score: 2.8878\n",
      "MAE Score: 1.4484\n",
      "\n",
      "Trial 236/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4812 | Final Val Loss: 1.9970\n",
      "R2 Score: -0.3182\n",
      "MSE Score: 1.7430\n",
      "MAE Score: 1.1936\n",
      "\n",
      "Trial 237/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0678 | Final Val Loss: 1.6081\n",
      "R2 Score: 0.0629\n",
      "MSE Score: 1.2391\n",
      "MAE Score: 0.9507\n",
      "\n",
      "Trial 238/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2176 | Final Val Loss: 2.2608\n",
      "R2 Score: -0.1568\n",
      "MSE Score: 1.5295\n",
      "MAE Score: 1.0744\n",
      "\n",
      "Trial 239/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4754 | Final Val Loss: 1.9992\n",
      "R2 Score: -0.0360\n",
      "MSE Score: 1.3699\n",
      "MAE Score: 0.9461\n",
      "\n",
      "Trial 240/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6140 | Final Val Loss: 1.8661\n",
      "R2 Score: -0.3131\n",
      "MSE Score: 1.7362\n",
      "MAE Score: 1.1246\n",
      "\n",
      "Trial 241/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.6888 | Final Val Loss: 1.7429\n",
      "R2 Score: 0.4199\n",
      "MSE Score: 0.7670\n",
      "MAE Score: 0.6598\n",
      "\n",
      "Trial 242/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9220 | Final Val Loss: 1.6976\n",
      "R2 Score: 0.2281\n",
      "MSE Score: 1.0206\n",
      "MAE Score: 0.7734\n",
      "\n",
      "Trial 243/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.7747 | Final Val Loss: 7.7778\n",
      "R2 Score: -5.4867\n",
      "MSE Score: 8.5769\n",
      "MAE Score: 2.7695\n",
      "\n",
      "Trial 244/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.5880 | Final Val Loss: 12.0262\n",
      "R2 Score: -8.9075\n",
      "MSE Score: 13.1000\n",
      "MAE Score: 3.4970\n",
      "\n",
      "Trial 245/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9650 | Final Val Loss: 1.6668\n",
      "R2 Score: 0.2628\n",
      "MSE Score: 0.9747\n",
      "MAE Score: 0.6762\n",
      "\n",
      "Trial 246/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1794 | Final Val Loss: 1.6704\n",
      "R2 Score: 0.3643\n",
      "MSE Score: 0.8405\n",
      "MAE Score: 0.6996\n",
      "\n",
      "Trial 247/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.5613 | Final Val Loss: 7.7181\n",
      "R2 Score: -5.1367\n",
      "MSE Score: 8.1141\n",
      "MAE Score: 2.6869\n",
      "\n",
      "Trial 248/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5003 | Final Val Loss: 9.6433\n",
      "R2 Score: -7.1756\n",
      "MSE Score: 10.8100\n",
      "MAE Score: 3.1505\n",
      "\n",
      "Trial 249/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6237 | Final Val Loss: 1.6049\n",
      "R2 Score: 0.3101\n",
      "MSE Score: 0.9123\n",
      "MAE Score: 0.7107\n",
      "\n",
      "Trial 250/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6595 | Final Val Loss: 1.5880\n",
      "R2 Score: 0.3676\n",
      "MSE Score: 0.8361\n",
      "MAE Score: 0.6805\n",
      "\n",
      "Trial 251/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7654 | Final Val Loss: 1.5632\n",
      "R2 Score: 0.2521\n",
      "MSE Score: 0.9889\n",
      "MAE Score: 0.7159\n",
      "\n",
      "Trial 252/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0675 | Final Val Loss: 1.6972\n",
      "R2 Score: 0.1576\n",
      "MSE Score: 1.1139\n",
      "MAE Score: 0.8451\n",
      "\n",
      "Trial 253/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6794 | Final Val Loss: 1.6720\n",
      "R2 Score: 0.1983\n",
      "MSE Score: 1.0601\n",
      "MAE Score: 0.7462\n",
      "\n",
      "Trial 254/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9405 | Final Val Loss: 1.8565\n",
      "R2 Score: 0.3370\n",
      "MSE Score: 0.8767\n",
      "MAE Score: 0.7499\n",
      "\n",
      "Trial 255/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7573 | Final Val Loss: 1.6541\n",
      "R2 Score: 0.2995\n",
      "MSE Score: 0.9262\n",
      "MAE Score: 0.6438\n",
      "\n",
      "Trial 256/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6762 | Final Val Loss: 1.5950\n",
      "R2 Score: 0.2453\n",
      "MSE Score: 0.9979\n",
      "MAE Score: 0.7416\n",
      "\n",
      "Trial 257/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5573 | Final Val Loss: 1.8643\n",
      "R2 Score: -0.3468\n",
      "MSE Score: 1.7808\n",
      "MAE Score: 1.1202\n",
      "\n",
      "Trial 258/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1351 | Final Val Loss: 1.6712\n",
      "R2 Score: -0.2122\n",
      "MSE Score: 1.6027\n",
      "MAE Score: 0.9958\n",
      "\n",
      "Trial 259/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 5.3401 | Final Val Loss: 7.1899\n",
      "R2 Score: -6.8919\n",
      "MSE Score: 10.4349\n",
      "MAE Score: 3.0214\n",
      "\n",
      "Trial 260/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9791 | Final Val Loss: 9.8237\n",
      "R2 Score: -8.0417\n",
      "MSE Score: 11.9552\n",
      "MAE Score: 3.2820\n",
      "\n",
      "Trial 261/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6635 | Final Val Loss: 1.9874\n",
      "R2 Score: -0.5070\n",
      "MSE Score: 1.9926\n",
      "MAE Score: 1.2439\n",
      "\n",
      "Trial 262/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5025 | Final Val Loss: 2.3577\n",
      "R2 Score: -0.4004\n",
      "MSE Score: 1.8517\n",
      "MAE Score: 1.1719\n",
      "\n",
      "Trial 263/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.8688 | Final Val Loss: 9.7097\n",
      "R2 Score: -7.3857\n",
      "MSE Score: 11.0879\n",
      "MAE Score: 3.1401\n",
      "\n",
      "Trial 264/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.0111 | Final Val Loss: 9.6543\n",
      "R2 Score: -8.1991\n",
      "MSE Score: 12.1633\n",
      "MAE Score: 3.3116\n",
      "\n",
      "Trial 265/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3998 | Final Val Loss: 1.9003\n",
      "R2 Score: -0.0303\n",
      "MSE Score: 1.3622\n",
      "MAE Score: 0.9762\n",
      "\n",
      "Trial 266/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1259 | Final Val Loss: 1.6949\n",
      "R2 Score: -0.1339\n",
      "MSE Score: 1.4993\n",
      "MAE Score: 1.0497\n",
      "\n",
      "Trial 267/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8961 | Final Val Loss: 2.0320\n",
      "R2 Score: -0.5372\n",
      "MSE Score: 2.0325\n",
      "MAE Score: 1.1668\n",
      "\n",
      "Trial 268/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3826 | Final Val Loss: 2.1507\n",
      "R2 Score: -0.2988\n",
      "MSE Score: 1.7173\n",
      "MAE Score: 1.0684\n",
      "\n",
      "Trial 269/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0427 | Final Val Loss: 1.7580\n",
      "R2 Score: -0.7605\n",
      "MSE Score: 2.3278\n",
      "MAE Score: 1.3338\n",
      "\n",
      "Trial 270/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1739 | Final Val Loss: 1.8493\n",
      "R2 Score: -0.2796\n",
      "MSE Score: 1.6919\n",
      "MAE Score: 1.1307\n",
      "\n",
      "Trial 271/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6506 | Final Val Loss: 2.4086\n",
      "R2 Score: -0.6677\n",
      "MSE Score: 2.2051\n",
      "MAE Score: 1.3232\n",
      "\n",
      "Trial 272/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4900 | Final Val Loss: 1.7653\n",
      "R2 Score: -0.9620\n",
      "MSE Score: 2.5942\n",
      "MAE Score: 1.3288\n",
      "\n",
      "Trial 273/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8671 | Final Val Loss: 1.6436\n",
      "R2 Score: 0.3662\n",
      "MSE Score: 0.8381\n",
      "MAE Score: 0.7011\n",
      "\n",
      "Trial 274/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9592 | Final Val Loss: 1.7014\n",
      "R2 Score: 0.3664\n",
      "MSE Score: 0.8377\n",
      "MAE Score: 0.6716\n",
      "\n",
      "Trial 275/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.5625 | Final Val Loss: 8.4011\n",
      "R2 Score: -5.6751\n",
      "MSE Score: 8.8260\n",
      "MAE Score: 2.8330\n",
      "\n",
      "Trial 276/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.8544 | Final Val Loss: 11.1259\n",
      "R2 Score: -8.5585\n",
      "MSE Score: 12.6386\n",
      "MAE Score: 3.4206\n",
      "\n",
      "Trial 277/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8040 | Final Val Loss: 1.6382\n",
      "R2 Score: 0.2898\n",
      "MSE Score: 0.9391\n",
      "MAE Score: 0.7191\n",
      "\n",
      "Trial 278/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8896 | Final Val Loss: 1.7566\n",
      "R2 Score: 0.3306\n",
      "MSE Score: 0.8851\n",
      "MAE Score: 0.6946\n",
      "\n",
      "Trial 279/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9899 | Final Val Loss: 8.9801\n",
      "R2 Score: -6.5591\n",
      "MSE Score: 9.9948\n",
      "MAE Score: 3.0151\n",
      "\n",
      "Trial 280/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.9559 | Final Val Loss: 9.5436\n",
      "R2 Score: -7.1120\n",
      "MSE Score: 10.7259\n",
      "MAE Score: 3.1354\n",
      "\n",
      "Trial 281/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6166 | Final Val Loss: 1.3897\n",
      "R2 Score: 0.4140\n",
      "MSE Score: 0.7748\n",
      "MAE Score: 0.6579\n",
      "\n",
      "Trial 282/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8835 | Final Val Loss: 1.6814\n",
      "R2 Score: 0.3008\n",
      "MSE Score: 0.9245\n",
      "MAE Score: 0.7218\n",
      "\n",
      "Trial 283/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7821 | Final Val Loss: 1.4080\n",
      "R2 Score: 0.2055\n",
      "MSE Score: 1.0506\n",
      "MAE Score: 0.7048\n",
      "\n",
      "Trial 284/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7880 | Final Val Loss: 1.5500\n",
      "R2 Score: 0.2611\n",
      "MSE Score: 0.9771\n",
      "MAE Score: 0.7234\n",
      "\n",
      "Trial 285/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6839 | Final Val Loss: 1.6061\n",
      "R2 Score: 0.4462\n",
      "MSE Score: 0.7322\n",
      "MAE Score: 0.7113\n",
      "\n",
      "Trial 286/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9072 | Final Val Loss: 1.5292\n",
      "R2 Score: 0.1342\n",
      "MSE Score: 1.1448\n",
      "MAE Score: 0.7875\n",
      "\n",
      "Trial 287/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8931 | Final Val Loss: 1.6382\n",
      "R2 Score: 0.2646\n",
      "MSE Score: 0.9724\n",
      "MAE Score: 0.7000\n",
      "\n",
      "Trial 288/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7168 | Final Val Loss: 1.5561\n",
      "R2 Score: 0.3699\n",
      "MSE Score: 0.8332\n",
      "MAE Score: 0.6563\n",
      "\n",
      "Grid search completed for this dataset!\n",
      "\n",
      "Best parameters found:\n",
      "num_epochs: 350\n",
      "num_units: [24, 16, 16, 8]\n",
      "drop: 0.2\n",
      "lr: 0.001\n",
      "decay: 0.0001\n",
      "acts: tanh\n",
      "opts: adam\n",
      "patience: 15\n",
      "\n",
      "Best metrics:\n",
      "R2: 0.4915\n",
      "MSE: 0.6723\n",
      "MAE: 0.6351\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing dataset: filtered_005.csv\n",
      "==================================================\n",
      "Total parameter combinations to try: 288\n",
      "\n",
      "Trial 1/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9880 | Final Val Loss: 1.4125\n",
      "R2 Score: 0.6619\n",
      "MSE Score: 0.4290\n",
      "MAE Score: 0.5103\n",
      "New best R2 score!\n",
      "\n",
      "Trial 2/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_20332\\425057010.py:142: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_trials_df = pd.concat([all_trials_df, pd.DataFrame([trial_results])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train loss: 1.0209 | Final Val Loss: 1.6629\n",
      "R2 Score: 0.7978\n",
      "MSE Score: 0.2566\n",
      "MAE Score: 0.3833\n",
      "New best R2 score!\n",
      "\n",
      "Trial 3/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.7426 | Final Val Loss: 14.0809\n",
      "R2 Score: -5.4144\n",
      "MSE Score: 8.1386\n",
      "MAE Score: 2.6793\n",
      "\n",
      "Trial 4/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5873 | Final Val Loss: 10.5965\n",
      "R2 Score: -3.7082\n",
      "MSE Score: 5.9738\n",
      "MAE Score: 2.2432\n",
      "\n",
      "Trial 5/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6725 | Final Val Loss: 1.3836\n",
      "R2 Score: 0.8029\n",
      "MSE Score: 0.2501\n",
      "MAE Score: 0.3878\n",
      "New best R2 score!\n",
      "\n",
      "Trial 6/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8860 | Final Val Loss: 1.3382\n",
      "R2 Score: 0.6583\n",
      "MSE Score: 0.4335\n",
      "MAE Score: 0.5702\n",
      "\n",
      "Trial 7/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.0930 | Final Val Loss: 12.4419\n",
      "R2 Score: -4.5846\n",
      "MSE Score: 7.0858\n",
      "MAE Score: 2.4565\n",
      "\n",
      "Trial 8/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.6362 | Final Val Loss: 11.2623\n",
      "R2 Score: -3.6777\n",
      "MSE Score: 5.9351\n",
      "MAE Score: 2.2424\n",
      "\n",
      "Trial 9/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3572 | Final Val Loss: 1.4201\n",
      "R2 Score: 0.5806\n",
      "MSE Score: 0.5321\n",
      "MAE Score: 0.5842\n",
      "\n",
      "Trial 10/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0465 | Final Val Loss: 1.1480\n",
      "R2 Score: 0.5015\n",
      "MSE Score: 0.6325\n",
      "MAE Score: 0.6876\n",
      "\n",
      "Trial 11/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4761 | Final Val Loss: 1.8964\n",
      "R2 Score: 0.8054\n",
      "MSE Score: 0.2469\n",
      "MAE Score: 0.4149\n",
      "New best R2 score!\n",
      "\n",
      "Trial 12/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0541 | Final Val Loss: 0.6667\n",
      "R2 Score: 0.5364\n",
      "MSE Score: 0.5882\n",
      "MAE Score: 0.6462\n",
      "\n",
      "Trial 13/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0580 | Final Val Loss: 1.4278\n",
      "R2 Score: 0.4888\n",
      "MSE Score: 0.6486\n",
      "MAE Score: 0.7213\n",
      "\n",
      "Trial 14/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2514 | Final Val Loss: 1.5580\n",
      "R2 Score: 0.3666\n",
      "MSE Score: 0.8037\n",
      "MAE Score: 0.7808\n",
      "\n",
      "Trial 15/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1609 | Final Val Loss: 2.1072\n",
      "R2 Score: 0.5309\n",
      "MSE Score: 0.5952\n",
      "MAE Score: 0.6365\n",
      "\n",
      "Trial 16/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5504 | Final Val Loss: 1.7153\n",
      "R2 Score: 0.5839\n",
      "MSE Score: 0.5280\n",
      "MAE Score: 0.5835\n",
      "\n",
      "Trial 17/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.6452 | Final Val Loss: 0.9234\n",
      "R2 Score: 0.3891\n",
      "MSE Score: 0.7751\n",
      "MAE Score: 0.7742\n",
      "\n",
      "Trial 18/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8889 | Final Val Loss: 1.3139\n",
      "R2 Score: 0.7678\n",
      "MSE Score: 0.2946\n",
      "MAE Score: 0.4503\n",
      "\n",
      "Trial 19/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7658 | Final Val Loss: 10.3257\n",
      "R2 Score: -3.4517\n",
      "MSE Score: 5.6484\n",
      "MAE Score: 2.3034\n",
      "\n",
      "Trial 20/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.2708 | Final Val Loss: 8.4679\n",
      "R2 Score: -2.2457\n",
      "MSE Score: 4.1182\n",
      "MAE Score: 1.9133\n",
      "\n",
      "Trial 21/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9875 | Final Val Loss: 1.0659\n",
      "R2 Score: 0.5691\n",
      "MSE Score: 0.5467\n",
      "MAE Score: 0.6374\n",
      "\n",
      "Trial 22/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3485 | Final Val Loss: 1.2123\n",
      "R2 Score: 0.5981\n",
      "MSE Score: 0.5100\n",
      "MAE Score: 0.6121\n",
      "\n",
      "Trial 23/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.6634 | Final Val Loss: 10.0833\n",
      "R2 Score: -3.3369\n",
      "MSE Score: 5.5027\n",
      "MAE Score: 2.2470\n",
      "\n",
      "Trial 24/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8603 | Final Val Loss: 9.3105\n",
      "R2 Score: -2.9929\n",
      "MSE Score: 5.0663\n",
      "MAE Score: 2.1735\n",
      "\n",
      "Trial 25/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8038 | Final Val Loss: 0.8987\n",
      "R2 Score: 0.3531\n",
      "MSE Score: 0.8208\n",
      "MAE Score: 0.7274\n",
      "\n",
      "Trial 26/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8288 | Final Val Loss: 0.9436\n",
      "R2 Score: 0.5123\n",
      "MSE Score: 0.6188\n",
      "MAE Score: 0.6347\n",
      "\n",
      "Trial 27/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9973 | Final Val Loss: 1.4600\n",
      "R2 Score: 0.6345\n",
      "MSE Score: 0.4638\n",
      "MAE Score: 0.5654\n",
      "\n",
      "Trial 28/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8400 | Final Val Loss: 1.2163\n",
      "R2 Score: 0.5857\n",
      "MSE Score: 0.5257\n",
      "MAE Score: 0.6390\n",
      "\n",
      "Trial 29/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8885 | Final Val Loss: 0.9829\n",
      "R2 Score: 0.2483\n",
      "MSE Score: 0.9538\n",
      "MAE Score: 0.8462\n",
      "\n",
      "Trial 30/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6852 | Final Val Loss: 1.0308\n",
      "R2 Score: 0.2991\n",
      "MSE Score: 0.8894\n",
      "MAE Score: 0.8097\n",
      "\n",
      "Trial 31/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8627 | Final Val Loss: 1.6333\n",
      "R2 Score: 0.7217\n",
      "MSE Score: 0.3531\n",
      "MAE Score: 0.5003\n",
      "\n",
      "Trial 32/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0208 | Final Val Loss: 1.4118\n",
      "R2 Score: 0.7636\n",
      "MSE Score: 0.2999\n",
      "MAE Score: 0.4551\n",
      "\n",
      "Trial 33/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5696 | Final Val Loss: 1.3710\n",
      "R2 Score: 0.7259\n",
      "MSE Score: 0.3478\n",
      "MAE Score: 0.4378\n",
      "\n",
      "Trial 34/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3673 | Final Val Loss: 1.4337\n",
      "R2 Score: 0.8070\n",
      "MSE Score: 0.2448\n",
      "MAE Score: 0.3785\n",
      "New best R2 score!\n",
      "\n",
      "Trial 35/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8554 | Final Val Loss: 10.8068\n",
      "R2 Score: -4.0511\n",
      "MSE Score: 6.4089\n",
      "MAE Score: 2.3338\n",
      "\n",
      "Trial 36/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 5.9883 | Final Val Loss: 9.4871\n",
      "R2 Score: -3.4105\n",
      "MSE Score: 5.5961\n",
      "MAE Score: 2.1751\n",
      "\n",
      "Trial 37/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5455 | Final Val Loss: 1.4298\n",
      "R2 Score: 0.7793\n",
      "MSE Score: 0.2800\n",
      "MAE Score: 0.4691\n",
      "\n",
      "Trial 38/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.3801 | Final Val Loss: 1.3132\n",
      "R2 Score: 0.6919\n",
      "MSE Score: 0.3909\n",
      "MAE Score: 0.5170\n",
      "\n",
      "Trial 39/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7012 | Final Val Loss: 11.9041\n",
      "R2 Score: -3.9014\n",
      "MSE Score: 6.2189\n",
      "MAE Score: 2.3228\n",
      "\n",
      "Trial 40/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5543 | Final Val Loss: 11.8974\n",
      "R2 Score: -3.8820\n",
      "MSE Score: 6.1943\n",
      "MAE Score: 2.3043\n",
      "\n",
      "Trial 41/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0396 | Final Val Loss: 1.6770\n",
      "R2 Score: 0.5632\n",
      "MSE Score: 0.5542\n",
      "MAE Score: 0.6233\n",
      "\n",
      "Trial 42/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7607 | Final Val Loss: 1.2890\n",
      "R2 Score: 0.6078\n",
      "MSE Score: 0.4977\n",
      "MAE Score: 0.6085\n",
      "\n",
      "Trial 43/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4620 | Final Val Loss: 1.8503\n",
      "R2 Score: 0.6705\n",
      "MSE Score: 0.4180\n",
      "MAE Score: 0.4725\n",
      "\n",
      "Trial 44/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6113 | Final Val Loss: 3.5436\n",
      "R2 Score: 0.3308\n",
      "MSE Score: 0.8490\n",
      "MAE Score: 0.6894\n",
      "\n",
      "Trial 45/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2890 | Final Val Loss: 1.7022\n",
      "R2 Score: 0.3975\n",
      "MSE Score: 0.7644\n",
      "MAE Score: 0.7333\n",
      "\n",
      "Trial 46/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4701 | Final Val Loss: 1.6862\n",
      "R2 Score: 0.3936\n",
      "MSE Score: 0.7694\n",
      "MAE Score: 0.8071\n",
      "\n",
      "Trial 47/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.9249 | Final Val Loss: 1.5804\n",
      "R2 Score: 0.5268\n",
      "MSE Score: 0.6004\n",
      "MAE Score: 0.5771\n",
      "\n",
      "Trial 48/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3602 | Final Val Loss: 2.1727\n",
      "R2 Score: 0.6392\n",
      "MSE Score: 0.4578\n",
      "MAE Score: 0.5308\n",
      "\n",
      "Trial 49/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8926 | Final Val Loss: 0.8807\n",
      "R2 Score: 0.4880\n",
      "MSE Score: 0.6496\n",
      "MAE Score: 0.6552\n",
      "\n",
      "Trial 50/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9534 | Final Val Loss: 1.0291\n",
      "R2 Score: 0.4445\n",
      "MSE Score: 0.7049\n",
      "MAE Score: 0.6875\n",
      "\n",
      "Trial 51/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.5339 | Final Val Loss: 12.3347\n",
      "R2 Score: -4.3083\n",
      "MSE Score: 6.7352\n",
      "MAE Score: 2.4990\n",
      "\n",
      "Trial 52/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.6190 | Final Val Loss: 8.4380\n",
      "R2 Score: -2.3777\n",
      "MSE Score: 4.2857\n",
      "MAE Score: 1.9899\n",
      "\n",
      "Trial 53/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1118 | Final Val Loss: 1.1743\n",
      "R2 Score: 0.5820\n",
      "MSE Score: 0.5303\n",
      "MAE Score: 0.6235\n",
      "\n",
      "Trial 54/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1983 | Final Val Loss: 0.9659\n",
      "R2 Score: 0.6424\n",
      "MSE Score: 0.4537\n",
      "MAE Score: 0.5911\n",
      "\n",
      "Trial 55/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.4904 | Final Val Loss: 12.6584\n",
      "R2 Score: -4.4060\n",
      "MSE Score: 6.8591\n",
      "MAE Score: 2.5452\n",
      "\n",
      "Trial 56/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.9740 | Final Val Loss: 8.7488\n",
      "R2 Score: -2.3550\n",
      "MSE Score: 4.2569\n",
      "MAE Score: 1.9586\n",
      "\n",
      "Trial 57/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8043 | Final Val Loss: 1.2013\n",
      "R2 Score: 0.4687\n",
      "MSE Score: 0.6741\n",
      "MAE Score: 0.6986\n",
      "\n",
      "Trial 58/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6921 | Final Val Loss: 1.0204\n",
      "R2 Score: 0.4415\n",
      "MSE Score: 0.7087\n",
      "MAE Score: 0.6880\n",
      "\n",
      "Trial 59/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9486 | Final Val Loss: 1.6499\n",
      "R2 Score: 0.6470\n",
      "MSE Score: 0.4479\n",
      "MAE Score: 0.5322\n",
      "\n",
      "Trial 60/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9484 | Final Val Loss: 1.4759\n",
      "R2 Score: 0.7582\n",
      "MSE Score: 0.3068\n",
      "MAE Score: 0.4310\n",
      "\n",
      "Trial 61/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8035 | Final Val Loss: 1.1238\n",
      "R2 Score: 0.4350\n",
      "MSE Score: 0.7169\n",
      "MAE Score: 0.7290\n",
      "\n",
      "Trial 62/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7634 | Final Val Loss: 1.0546\n",
      "R2 Score: 0.4975\n",
      "MSE Score: 0.6375\n",
      "MAE Score: 0.6700\n",
      "\n",
      "Trial 63/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9459 | Final Val Loss: 1.4454\n",
      "R2 Score: 0.5512\n",
      "MSE Score: 0.5694\n",
      "MAE Score: 0.6520\n",
      "\n",
      "Trial 64/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1989 | Final Val Loss: 1.6232\n",
      "R2 Score: 0.7315\n",
      "MSE Score: 0.3407\n",
      "MAE Score: 0.4886\n",
      "\n",
      "Trial 65/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5698 | Final Val Loss: 1.2532\n",
      "R2 Score: 0.7441\n",
      "MSE Score: 0.3247\n",
      "MAE Score: 0.4556\n",
      "\n",
      "Trial 66/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2183 | Final Val Loss: 1.2323\n",
      "R2 Score: 0.6796\n",
      "MSE Score: 0.4065\n",
      "MAE Score: 0.5398\n",
      "\n",
      "Trial 67/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.9092 | Final Val Loss: 9.9527\n",
      "R2 Score: -3.2645\n",
      "MSE Score: 5.4108\n",
      "MAE Score: 2.0809\n",
      "\n",
      "Trial 68/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.3498 | Final Val Loss: 14.0201\n",
      "R2 Score: -5.4432\n",
      "MSE Score: 8.1752\n",
      "MAE Score: 2.6550\n",
      "\n",
      "Trial 69/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8427 | Final Val Loss: 1.8243\n",
      "R2 Score: 0.5457\n",
      "MSE Score: 0.5764\n",
      "MAE Score: 0.6128\n",
      "\n",
      "Trial 70/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.9527 | Final Val Loss: 1.3840\n",
      "R2 Score: 0.7235\n",
      "MSE Score: 0.3508\n",
      "MAE Score: 0.4427\n",
      "\n",
      "Trial 71/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 12.6313 | Final Val Loss: 14.5843\n",
      "R2 Score: -5.4863\n",
      "MSE Score: 8.2299\n",
      "MAE Score: 2.6867\n",
      "\n",
      "Trial 72/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.4860 | Final Val Loss: 13.8213\n",
      "R2 Score: -5.2283\n",
      "MSE Score: 7.9026\n",
      "MAE Score: 2.6360\n",
      "\n",
      "Trial 73/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9115 | Final Val Loss: 1.2932\n",
      "R2 Score: 0.4651\n",
      "MSE Score: 0.6787\n",
      "MAE Score: 0.7052\n",
      "\n",
      "Trial 74/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4194 | Final Val Loss: 1.4214\n",
      "R2 Score: 0.5458\n",
      "MSE Score: 0.5762\n",
      "MAE Score: 0.6704\n",
      "\n",
      "Trial 75/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0168 | Final Val Loss: 1.3930\n",
      "R2 Score: 0.4873\n",
      "MSE Score: 0.6505\n",
      "MAE Score: 0.6227\n",
      "\n",
      "Trial 76/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1470 | Final Val Loss: 1.5159\n",
      "R2 Score: 0.5384\n",
      "MSE Score: 0.5857\n",
      "MAE Score: 0.5601\n",
      "\n",
      "Trial 77/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3953 | Final Val Loss: 1.5081\n",
      "R2 Score: 0.3946\n",
      "MSE Score: 0.7681\n",
      "MAE Score: 0.7809\n",
      "\n",
      "Trial 78/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5870 | Final Val Loss: 1.2260\n",
      "R2 Score: 0.6320\n",
      "MSE Score: 0.4669\n",
      "MAE Score: 0.6048\n",
      "\n",
      "Trial 79/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5834 | Final Val Loss: 2.4915\n",
      "R2 Score: 0.5255\n",
      "MSE Score: 0.6021\n",
      "MAE Score: 0.6358\n",
      "\n",
      "Trial 80/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2816 | Final Val Loss: 1.2156\n",
      "R2 Score: 0.6786\n",
      "MSE Score: 0.4078\n",
      "MAE Score: 0.5337\n",
      "\n",
      "Trial 81/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8192 | Final Val Loss: 0.9012\n",
      "R2 Score: 0.3729\n",
      "MSE Score: 0.7957\n",
      "MAE Score: 0.7593\n",
      "\n",
      "Trial 82/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.6980 | Final Val Loss: 1.1686\n",
      "R2 Score: 0.5333\n",
      "MSE Score: 0.5921\n",
      "MAE Score: 0.6376\n",
      "\n",
      "Trial 83/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8308 | Final Val Loss: 10.1346\n",
      "R2 Score: -3.2793\n",
      "MSE Score: 5.4296\n",
      "MAE Score: 2.2365\n",
      "\n",
      "Trial 84/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.7008 | Final Val Loss: 9.7010\n",
      "R2 Score: -2.8505\n",
      "MSE Score: 4.8855\n",
      "MAE Score: 2.1092\n",
      "\n",
      "Trial 85/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0526 | Final Val Loss: 1.1059\n",
      "R2 Score: 0.5878\n",
      "MSE Score: 0.5231\n",
      "MAE Score: 0.6182\n",
      "\n",
      "Trial 86/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0289 | Final Val Loss: 1.1065\n",
      "R2 Score: 0.5658\n",
      "MSE Score: 0.5509\n",
      "MAE Score: 0.6173\n",
      "\n",
      "Trial 87/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.8053 | Final Val Loss: 9.4947\n",
      "R2 Score: -2.8679\n",
      "MSE Score: 4.9077\n",
      "MAE Score: 2.0931\n",
      "\n",
      "Trial 88/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.2391 | Final Val Loss: 12.3678\n",
      "R2 Score: -4.5313\n",
      "MSE Score: 7.0182\n",
      "MAE Score: 2.5432\n",
      "\n",
      "Trial 89/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7584 | Final Val Loss: 1.0596\n",
      "R2 Score: 0.5621\n",
      "MSE Score: 0.5557\n",
      "MAE Score: 0.6512\n",
      "\n",
      "Trial 90/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6907 | Final Val Loss: 0.9299\n",
      "R2 Score: 0.2745\n",
      "MSE Score: 0.9205\n",
      "MAE Score: 0.8248\n",
      "\n",
      "Trial 91/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9241 | Final Val Loss: 1.4059\n",
      "R2 Score: 0.7211\n",
      "MSE Score: 0.3539\n",
      "MAE Score: 0.4765\n",
      "\n",
      "Trial 92/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8677 | Final Val Loss: 1.2234\n",
      "R2 Score: 0.6577\n",
      "MSE Score: 0.4343\n",
      "MAE Score: 0.5341\n",
      "\n",
      "Trial 93/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8602 | Final Val Loss: 0.7265\n",
      "R2 Score: 0.3953\n",
      "MSE Score: 0.7673\n",
      "MAE Score: 0.7462\n",
      "\n",
      "Trial 94/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0130 | Final Val Loss: 0.9791\n",
      "R2 Score: 0.4573\n",
      "MSE Score: 0.6885\n",
      "MAE Score: 0.6643\n",
      "\n",
      "Trial 95/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0273 | Final Val Loss: 1.5264\n",
      "R2 Score: 0.6647\n",
      "MSE Score: 0.4255\n",
      "MAE Score: 0.5149\n",
      "\n",
      "Trial 96/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [24, 16, 16, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8730 | Final Val Loss: 1.2624\n",
      "R2 Score: 0.5948\n",
      "MSE Score: 0.5142\n",
      "MAE Score: 0.5856\n",
      "\n",
      "Trial 97/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6234 | Final Val Loss: 1.5081\n",
      "R2 Score: 0.5130\n",
      "MSE Score: 0.6179\n",
      "MAE Score: 0.5648\n",
      "\n",
      "Trial 98/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4213 | Final Val Loss: 1.4081\n",
      "R2 Score: 0.7398\n",
      "MSE Score: 0.3301\n",
      "MAE Score: 0.4642\n",
      "\n",
      "Trial 99/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.1545 | Final Val Loss: 11.6028\n",
      "R2 Score: -4.0480\n",
      "MSE Score: 6.4049\n",
      "MAE Score: 2.3855\n",
      "\n",
      "Trial 100/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.0167 | Final Val Loss: 11.2896\n",
      "R2 Score: -3.8308\n",
      "MSE Score: 6.1293\n",
      "MAE Score: 2.2688\n",
      "\n",
      "Trial 101/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4558 | Final Val Loss: 1.9541\n",
      "R2 Score: 0.5665\n",
      "MSE Score: 0.5500\n",
      "MAE Score: 0.5117\n",
      "\n",
      "Trial 102/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7173 | Final Val Loss: 2.3282\n",
      "R2 Score: 0.6153\n",
      "MSE Score: 0.4881\n",
      "MAE Score: 0.4923\n",
      "\n",
      "Trial 103/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.9714 | Final Val Loss: 12.5432\n",
      "R2 Score: -4.5791\n",
      "MSE Score: 7.0788\n",
      "MAE Score: 2.4910\n",
      "\n",
      "Trial 104/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.9711 | Final Val Loss: 11.0404\n",
      "R2 Score: -3.6350\n",
      "MSE Score: 5.8809\n",
      "MAE Score: 2.2198\n",
      "\n",
      "Trial 105/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1396 | Final Val Loss: 0.8700\n",
      "R2 Score: 0.5739\n",
      "MSE Score: 0.5406\n",
      "MAE Score: 0.6367\n",
      "\n",
      "Trial 106/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0789 | Final Val Loss: 1.1588\n",
      "R2 Score: 0.5221\n",
      "MSE Score: 0.6064\n",
      "MAE Score: 0.7262\n",
      "\n",
      "Trial 107/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5242 | Final Val Loss: 1.7074\n",
      "R2 Score: 0.5828\n",
      "MSE Score: 0.5294\n",
      "MAE Score: 0.5590\n",
      "\n",
      "Trial 108/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9226 | Final Val Loss: 1.5799\n",
      "R2 Score: 0.6493\n",
      "MSE Score: 0.4449\n",
      "MAE Score: 0.4985\n",
      "\n",
      "Trial 109/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0444 | Final Val Loss: 1.8364\n",
      "R2 Score: 0.3600\n",
      "MSE Score: 0.8120\n",
      "MAE Score: 0.7296\n",
      "\n",
      "Trial 110/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6699 | Final Val Loss: 1.4058\n",
      "R2 Score: 0.4767\n",
      "MSE Score: 0.6640\n",
      "MAE Score: 0.7721\n",
      "\n",
      "Trial 111/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6946 | Final Val Loss: 1.3027\n",
      "R2 Score: 0.2574\n",
      "MSE Score: 0.9422\n",
      "MAE Score: 0.8547\n",
      "\n",
      "Trial 112/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.9669 | Final Val Loss: 3.0784\n",
      "R2 Score: 0.3276\n",
      "MSE Score: 0.8531\n",
      "MAE Score: 0.7671\n",
      "\n",
      "Trial 113/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9386 | Final Val Loss: 0.9800\n",
      "R2 Score: 0.5194\n",
      "MSE Score: 0.6098\n",
      "MAE Score: 0.6641\n",
      "\n",
      "Trial 114/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9247 | Final Val Loss: 0.9970\n",
      "R2 Score: 0.2314\n",
      "MSE Score: 0.9752\n",
      "MAE Score: 0.8607\n",
      "\n",
      "Trial 115/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.4542 | Final Val Loss: 9.0023\n",
      "R2 Score: -2.6231\n",
      "MSE Score: 4.5971\n",
      "MAE Score: 2.0445\n",
      "\n",
      "Trial 116/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.1934 | Final Val Loss: 10.1977\n",
      "R2 Score: -2.9694\n",
      "MSE Score: 5.0365\n",
      "MAE Score: 2.0907\n",
      "\n",
      "Trial 117/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9476 | Final Val Loss: 0.8373\n",
      "R2 Score: 0.4506\n",
      "MSE Score: 0.6971\n",
      "MAE Score: 0.7164\n",
      "\n",
      "Trial 118/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1476 | Final Val Loss: 1.0542\n",
      "R2 Score: 0.4675\n",
      "MSE Score: 0.6756\n",
      "MAE Score: 0.7035\n",
      "\n",
      "Trial 119/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.7912 | Final Val Loss: 11.2783\n",
      "R2 Score: -3.8733\n",
      "MSE Score: 6.1832\n",
      "MAE Score: 2.3947\n",
      "\n",
      "Trial 120/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.8697 | Final Val Loss: 9.6819\n",
      "R2 Score: -3.1914\n",
      "MSE Score: 5.3181\n",
      "MAE Score: 2.2383\n",
      "\n",
      "Trial 121/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7187 | Final Val Loss: 1.1805\n",
      "R2 Score: 0.3966\n",
      "MSE Score: 0.7656\n",
      "MAE Score: 0.7592\n",
      "\n",
      "Trial 122/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7452 | Final Val Loss: 0.6945\n",
      "R2 Score: 0.4307\n",
      "MSE Score: 0.7224\n",
      "MAE Score: 0.7296\n",
      "\n",
      "Trial 123/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3893 | Final Val Loss: 2.1236\n",
      "R2 Score: 0.7250\n",
      "MSE Score: 0.3489\n",
      "MAE Score: 0.4765\n",
      "\n",
      "Trial 124/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9043 | Final Val Loss: 1.2528\n",
      "R2 Score: 0.6808\n",
      "MSE Score: 0.4050\n",
      "MAE Score: 0.4831\n",
      "\n",
      "Trial 125/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0593 | Final Val Loss: 0.8752\n",
      "R2 Score: 0.3721\n",
      "MSE Score: 0.7967\n",
      "MAE Score: 0.8011\n",
      "\n",
      "Trial 126/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6590 | Final Val Loss: 0.7913\n",
      "R2 Score: 0.3936\n",
      "MSE Score: 0.7694\n",
      "MAE Score: 0.7402\n",
      "\n",
      "Trial 127/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8544 | Final Val Loss: 1.2810\n",
      "R2 Score: 0.6264\n",
      "MSE Score: 0.4741\n",
      "MAE Score: 0.5815\n",
      "\n",
      "Trial 128/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9102 | Final Val Loss: 1.1770\n",
      "R2 Score: 0.7167\n",
      "MSE Score: 0.3594\n",
      "MAE Score: 0.4844\n",
      "\n",
      "Trial 129/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1341 | Final Val Loss: 1.4431\n",
      "R2 Score: 0.5914\n",
      "MSE Score: 0.5185\n",
      "MAE Score: 0.6434\n",
      "\n",
      "Trial 130/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5987 | Final Val Loss: 2.1740\n",
      "R2 Score: 0.5693\n",
      "MSE Score: 0.5465\n",
      "MAE Score: 0.5281\n",
      "\n",
      "Trial 131/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5434 | Final Val Loss: 10.9494\n",
      "R2 Score: -3.5398\n",
      "MSE Score: 5.7601\n",
      "MAE Score: 2.2083\n",
      "\n",
      "Trial 132/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.2660 | Final Val Loss: 11.5234\n",
      "R2 Score: -3.9204\n",
      "MSE Score: 6.2431\n",
      "MAE Score: 2.3042\n",
      "\n",
      "Trial 133/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4273 | Final Val Loss: 1.1717\n",
      "R2 Score: 0.5864\n",
      "MSE Score: 0.5248\n",
      "MAE Score: 0.5978\n",
      "\n",
      "Trial 134/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.4117 | Final Val Loss: 1.4353\n",
      "R2 Score: 0.7343\n",
      "MSE Score: 0.3371\n",
      "MAE Score: 0.4816\n",
      "\n",
      "Trial 135/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.3709 | Final Val Loss: 12.1995\n",
      "R2 Score: -4.3575\n",
      "MSE Score: 6.7976\n",
      "MAE Score: 2.3946\n",
      "\n",
      "Trial 136/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.9249 | Final Val Loss: 12.9442\n",
      "R2 Score: -4.9975\n",
      "MSE Score: 7.6098\n",
      "MAE Score: 2.5196\n",
      "\n",
      "Trial 137/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9876 | Final Val Loss: 1.9750\n",
      "R2 Score: 0.3648\n",
      "MSE Score: 0.8060\n",
      "MAE Score: 0.7482\n",
      "\n",
      "Trial 138/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2299 | Final Val Loss: 1.6217\n",
      "R2 Score: 0.7083\n",
      "MSE Score: 0.3701\n",
      "MAE Score: 0.5023\n",
      "\n",
      "Trial 139/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4509 | Final Val Loss: 2.1226\n",
      "R2 Score: 0.2902\n",
      "MSE Score: 0.9006\n",
      "MAE Score: 0.7541\n",
      "\n",
      "Trial 140/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2806 | Final Val Loss: 2.0231\n",
      "R2 Score: 0.4472\n",
      "MSE Score: 0.7014\n",
      "MAE Score: 0.6215\n",
      "\n",
      "Trial 141/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1610 | Final Val Loss: 1.5521\n",
      "R2 Score: 0.5337\n",
      "MSE Score: 0.5916\n",
      "MAE Score: 0.6342\n",
      "\n",
      "Trial 142/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1912 | Final Val Loss: 1.8377\n",
      "R2 Score: 0.4919\n",
      "MSE Score: 0.6447\n",
      "MAE Score: 0.6800\n",
      "\n",
      "Trial 143/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8856 | Final Val Loss: 2.4560\n",
      "R2 Score: 0.2568\n",
      "MSE Score: 0.9430\n",
      "MAE Score: 0.7544\n",
      "\n",
      "Trial 144/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5842 | Final Val Loss: 1.5527\n",
      "R2 Score: 0.5627\n",
      "MSE Score: 0.5549\n",
      "MAE Score: 0.5981\n",
      "\n",
      "Trial 145/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7018 | Final Val Loss: 0.8395\n",
      "R2 Score: 0.4645\n",
      "MSE Score: 0.6794\n",
      "MAE Score: 0.6881\n",
      "\n",
      "Trial 146/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8928 | Final Val Loss: 1.0634\n",
      "R2 Score: 0.4789\n",
      "MSE Score: 0.6612\n",
      "MAE Score: 0.6904\n",
      "\n",
      "Trial 147/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.8378 | Final Val Loss: 8.9539\n",
      "R2 Score: -2.5326\n",
      "MSE Score: 4.4822\n",
      "MAE Score: 1.9902\n",
      "\n",
      "Trial 148/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.6148 | Final Val Loss: 10.1886\n",
      "R2 Score: -3.1538\n",
      "MSE Score: 5.2703\n",
      "MAE Score: 2.1981\n",
      "\n",
      "Trial 149/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0559 | Final Val Loss: 1.0141\n",
      "R2 Score: 0.5163\n",
      "MSE Score: 0.6137\n",
      "MAE Score: 0.7009\n",
      "\n",
      "Trial 150/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8992 | Final Val Loss: 1.1576\n",
      "R2 Score: 0.5872\n",
      "MSE Score: 0.5237\n",
      "MAE Score: 0.6113\n",
      "\n",
      "Trial 151/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.6733 | Final Val Loss: 9.6334\n",
      "R2 Score: -2.9699\n",
      "MSE Score: 5.0371\n",
      "MAE Score: 2.1408\n",
      "\n",
      "Trial 152/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.1448 | Final Val Loss: 11.0945\n",
      "R2 Score: -3.7339\n",
      "MSE Score: 6.0064\n",
      "MAE Score: 2.3224\n",
      "\n",
      "Trial 153/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5277 | Final Val Loss: 1.1252\n",
      "R2 Score: 0.4478\n",
      "MSE Score: 0.7007\n",
      "MAE Score: 0.7279\n",
      "\n",
      "Trial 154/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7807 | Final Val Loss: 0.9496\n",
      "R2 Score: 0.3705\n",
      "MSE Score: 0.7988\n",
      "MAE Score: 0.7422\n",
      "\n",
      "Trial 155/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1873 | Final Val Loss: 1.1737\n",
      "R2 Score: 0.5787\n",
      "MSE Score: 0.5345\n",
      "MAE Score: 0.6147\n",
      "\n",
      "Trial 156/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7212 | Final Val Loss: 1.5465\n",
      "R2 Score: 0.6277\n",
      "MSE Score: 0.4723\n",
      "MAE Score: 0.5648\n",
      "\n",
      "Trial 157/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9404 | Final Val Loss: 0.8757\n",
      "R2 Score: 0.4791\n",
      "MSE Score: 0.6610\n",
      "MAE Score: 0.6769\n",
      "\n",
      "Trial 158/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2237 | Final Val Loss: 0.7648\n",
      "R2 Score: 0.3348\n",
      "MSE Score: 0.8440\n",
      "MAE Score: 0.8016\n",
      "\n",
      "Trial 159/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1244 | Final Val Loss: 1.4365\n",
      "R2 Score: 0.7103\n",
      "MSE Score: 0.3676\n",
      "MAE Score: 0.5503\n",
      "\n",
      "Trial 160/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0680 | Final Val Loss: 1.3795\n",
      "R2 Score: 0.6893\n",
      "MSE Score: 0.3942\n",
      "MAE Score: 0.4831\n",
      "\n",
      "Trial 161/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8295 | Final Val Loss: 1.9933\n",
      "R2 Score: 0.5893\n",
      "MSE Score: 0.5211\n",
      "MAE Score: 0.5001\n",
      "\n",
      "Trial 162/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3711 | Final Val Loss: 1.7837\n",
      "R2 Score: 0.5742\n",
      "MSE Score: 0.5403\n",
      "MAE Score: 0.5877\n",
      "\n",
      "Trial 163/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.5892 | Final Val Loss: 9.6840\n",
      "R2 Score: -3.3968\n",
      "MSE Score: 5.5787\n",
      "MAE Score: 2.1788\n",
      "\n",
      "Trial 164/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.8436 | Final Val Loss: 11.3852\n",
      "R2 Score: -4.1276\n",
      "MSE Score: 6.5060\n",
      "MAE Score: 2.3338\n",
      "\n",
      "Trial 165/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1244 | Final Val Loss: 1.2166\n",
      "R2 Score: 0.6279\n",
      "MSE Score: 0.4721\n",
      "MAE Score: 0.6010\n",
      "\n",
      "Trial 166/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.1503 | Final Val Loss: 2.4273\n",
      "R2 Score: 0.3072\n",
      "MSE Score: 0.8791\n",
      "MAE Score: 0.6654\n",
      "\n",
      "Trial 167/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.2506 | Final Val Loss: 10.2199\n",
      "R2 Score: -3.4746\n",
      "MSE Score: 5.6774\n",
      "MAE Score: 2.1395\n",
      "\n",
      "Trial 168/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7631 | Final Val Loss: 10.4746\n",
      "R2 Score: -3.5654\n",
      "MSE Score: 5.7926\n",
      "MAE Score: 2.1585\n",
      "\n",
      "Trial 169/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7723 | Final Val Loss: 0.9538\n",
      "R2 Score: 0.6246\n",
      "MSE Score: 0.4763\n",
      "MAE Score: 0.6108\n",
      "\n",
      "Trial 170/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2294 | Final Val Loss: 1.2630\n",
      "R2 Score: 0.5505\n",
      "MSE Score: 0.5703\n",
      "MAE Score: 0.6765\n",
      "\n",
      "Trial 171/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2872 | Final Val Loss: 1.6244\n",
      "R2 Score: 0.7612\n",
      "MSE Score: 0.3030\n",
      "MAE Score: 0.4796\n",
      "\n",
      "Trial 172/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1072 | Final Val Loss: 2.3241\n",
      "R2 Score: 0.4554\n",
      "MSE Score: 0.6910\n",
      "MAE Score: 0.5999\n",
      "\n",
      "Trial 173/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3807 | Final Val Loss: 1.2484\n",
      "R2 Score: 0.4544\n",
      "MSE Score: 0.6923\n",
      "MAE Score: 0.7832\n",
      "\n",
      "Trial 174/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4615 | Final Val Loss: 1.3623\n",
      "R2 Score: 0.4755\n",
      "MSE Score: 0.6654\n",
      "MAE Score: 0.7427\n",
      "\n",
      "Trial 175/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4205 | Final Val Loss: 1.1829\n",
      "R2 Score: 0.3738\n",
      "MSE Score: 0.7946\n",
      "MAE Score: 0.8260\n",
      "\n",
      "Trial 176/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4154 | Final Val Loss: 1.8774\n",
      "R2 Score: 0.3028\n",
      "MSE Score: 0.8846\n",
      "MAE Score: 0.7355\n",
      "\n",
      "Trial 177/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7876 | Final Val Loss: 0.9930\n",
      "R2 Score: 0.3943\n",
      "MSE Score: 0.7685\n",
      "MAE Score: 0.7779\n",
      "\n",
      "Trial 178/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.7508 | Final Val Loss: 1.0511\n",
      "R2 Score: 0.6141\n",
      "MSE Score: 0.4896\n",
      "MAE Score: 0.6101\n",
      "\n",
      "Trial 179/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.6352 | Final Val Loss: 8.3525\n",
      "R2 Score: -2.6217\n",
      "MSE Score: 4.5952\n",
      "MAE Score: 2.0388\n",
      "\n",
      "Trial 180/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.2776 | Final Val Loss: 10.5039\n",
      "R2 Score: -2.8440\n",
      "MSE Score: 4.8774\n",
      "MAE Score: 2.1299\n",
      "\n",
      "Trial 181/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0546 | Final Val Loss: 1.1440\n",
      "R2 Score: 0.5628\n",
      "MSE Score: 0.5548\n",
      "MAE Score: 0.6541\n",
      "\n",
      "Trial 182/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9039 | Final Val Loss: 1.0148\n",
      "R2 Score: 0.4968\n",
      "MSE Score: 0.6385\n",
      "MAE Score: 0.7079\n",
      "\n",
      "Trial 183/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.7662 | Final Val Loss: 11.5319\n",
      "R2 Score: -4.1672\n",
      "MSE Score: 6.5562\n",
      "MAE Score: 2.4424\n",
      "\n",
      "Trial 184/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.9968 | Final Val Loss: 12.6861\n",
      "R2 Score: -4.5109\n",
      "MSE Score: 6.9924\n",
      "MAE Score: 2.5539\n",
      "\n",
      "Trial 185/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7338 | Final Val Loss: 1.1384\n",
      "R2 Score: 0.3946\n",
      "MSE Score: 0.7681\n",
      "MAE Score: 0.7434\n",
      "\n",
      "Trial 186/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8166 | Final Val Loss: 1.0307\n",
      "R2 Score: 0.2443\n",
      "MSE Score: 0.9588\n",
      "MAE Score: 0.7819\n",
      "\n",
      "Trial 187/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9584 | Final Val Loss: 1.3061\n",
      "R2 Score: 0.5672\n",
      "MSE Score: 0.5492\n",
      "MAE Score: 0.6348\n",
      "\n",
      "Trial 188/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8298 | Final Val Loss: 1.2305\n",
      "R2 Score: 0.6659\n",
      "MSE Score: 0.4239\n",
      "MAE Score: 0.5569\n",
      "\n",
      "Trial 189/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8894 | Final Val Loss: 0.8331\n",
      "R2 Score: 0.4513\n",
      "MSE Score: 0.6963\n",
      "MAE Score: 0.7212\n",
      "\n",
      "Trial 190/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9164 | Final Val Loss: 0.8427\n",
      "R2 Score: 0.4333\n",
      "MSE Score: 0.7190\n",
      "MAE Score: 0.7079\n",
      "\n",
      "Trial 191/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3661 | Final Val Loss: 1.1870\n",
      "R2 Score: 0.5811\n",
      "MSE Score: 0.5315\n",
      "MAE Score: 0.6074\n",
      "\n",
      "Trial 192/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [32, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4691 | Final Val Loss: 1.8509\n",
      "R2 Score: 0.6342\n",
      "MSE Score: 0.4641\n",
      "MAE Score: 0.6003\n",
      "\n",
      "Trial 193/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3420 | Final Val Loss: 2.3606\n",
      "R2 Score: 0.4629\n",
      "MSE Score: 0.6815\n",
      "MAE Score: 0.6550\n",
      "\n",
      "Trial 194/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.6672 | Final Val Loss: 1.1516\n",
      "R2 Score: 0.6123\n",
      "MSE Score: 0.4919\n",
      "MAE Score: 0.4981\n",
      "\n",
      "Trial 195/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.5637 | Final Val Loss: 9.3654\n",
      "R2 Score: -3.0819\n",
      "MSE Score: 5.1792\n",
      "MAE Score: 2.0172\n",
      "\n",
      "Trial 196/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 11.0171 | Final Val Loss: 12.6320\n",
      "R2 Score: -4.5509\n",
      "MSE Score: 7.0431\n",
      "MAE Score: 2.4743\n",
      "\n",
      "Trial 197/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5709 | Final Val Loss: 1.2519\n",
      "R2 Score: 0.6127\n",
      "MSE Score: 0.4914\n",
      "MAE Score: 0.5688\n",
      "\n",
      "Trial 198/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.0247 | Final Val Loss: 1.3840\n",
      "R2 Score: 0.5560\n",
      "MSE Score: 0.5634\n",
      "MAE Score: 0.6053\n",
      "\n",
      "Trial 199/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.4752 | Final Val Loss: 12.4682\n",
      "R2 Score: -4.4506\n",
      "MSE Score: 6.9158\n",
      "MAE Score: 2.4002\n",
      "\n",
      "Trial 200/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 13.0513 | Final Val Loss: 15.6854\n",
      "R2 Score: -6.3569\n",
      "MSE Score: 9.3345\n",
      "MAE Score: 2.8865\n",
      "\n",
      "Trial 201/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9283 | Final Val Loss: 1.4751\n",
      "R2 Score: 0.5629\n",
      "MSE Score: 0.5546\n",
      "MAE Score: 0.6645\n",
      "\n",
      "Trial 202/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3274 | Final Val Loss: 1.4175\n",
      "R2 Score: 0.5385\n",
      "MSE Score: 0.5855\n",
      "MAE Score: 0.6585\n",
      "\n",
      "Trial 203/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3550 | Final Val Loss: 2.9335\n",
      "R2 Score: 0.3560\n",
      "MSE Score: 0.8171\n",
      "MAE Score: 0.6995\n",
      "\n",
      "Trial 204/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3345 | Final Val Loss: 1.3472\n",
      "R2 Score: 0.4242\n",
      "MSE Score: 0.7305\n",
      "MAE Score: 0.6715\n",
      "\n",
      "Trial 205/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1127 | Final Val Loss: 1.4925\n",
      "R2 Score: 0.5231\n",
      "MSE Score: 0.6051\n",
      "MAE Score: 0.7257\n",
      "\n",
      "Trial 206/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1095 | Final Val Loss: 1.1035\n",
      "R2 Score: 0.3582\n",
      "MSE Score: 0.8143\n",
      "MAE Score: 0.7709\n",
      "\n",
      "Trial 207/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3913 | Final Val Loss: 2.8904\n",
      "R2 Score: 0.2371\n",
      "MSE Score: 0.9679\n",
      "MAE Score: 0.7871\n",
      "\n",
      "Trial 208/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 2.1248 | Final Val Loss: 1.8572\n",
      "R2 Score: 0.3603\n",
      "MSE Score: 0.8117\n",
      "MAE Score: 0.7677\n",
      "\n",
      "Trial 209/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8712 | Final Val Loss: 0.8255\n",
      "R2 Score: 0.3565\n",
      "MSE Score: 0.8165\n",
      "MAE Score: 0.7801\n",
      "\n",
      "Trial 210/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0329 | Final Val Loss: 1.0937\n",
      "R2 Score: 0.4531\n",
      "MSE Score: 0.6939\n",
      "MAE Score: 0.6883\n",
      "\n",
      "Trial 211/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.7130 | Final Val Loss: 10.8410\n",
      "R2 Score: -3.3511\n",
      "MSE Score: 5.5207\n",
      "MAE Score: 2.2361\n",
      "\n",
      "Trial 212/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.7716 | Final Val Loss: 12.7390\n",
      "R2 Score: -4.6345\n",
      "MSE Score: 7.1492\n",
      "MAE Score: 2.6010\n",
      "\n",
      "Trial 213/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9663 | Final Val Loss: 0.8832\n",
      "R2 Score: 0.6115\n",
      "MSE Score: 0.4929\n",
      "MAE Score: 0.6144\n",
      "\n",
      "Trial 214/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9610 | Final Val Loss: 1.1020\n",
      "R2 Score: 0.5390\n",
      "MSE Score: 0.5849\n",
      "MAE Score: 0.6615\n",
      "\n",
      "Trial 215/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.3245 | Final Val Loss: 9.6958\n",
      "R2 Score: -2.9178\n",
      "MSE Score: 4.9710\n",
      "MAE Score: 2.1131\n",
      "\n",
      "Trial 216/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.8530 | Final Val Loss: 10.0361\n",
      "R2 Score: -2.8703\n",
      "MSE Score: 4.9107\n",
      "MAE Score: 2.0992\n",
      "\n",
      "Trial 217/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.6136 | Final Val Loss: 1.0019\n",
      "R2 Score: 0.3649\n",
      "MSE Score: 0.8059\n",
      "MAE Score: 0.7448\n",
      "\n",
      "Trial 218/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.5806 | Final Val Loss: 1.1278\n",
      "R2 Score: 0.5238\n",
      "MSE Score: 0.6042\n",
      "MAE Score: 0.6367\n",
      "\n",
      "Trial 219/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8718 | Final Val Loss: 1.3418\n",
      "R2 Score: 0.6919\n",
      "MSE Score: 0.3909\n",
      "MAE Score: 0.5212\n",
      "\n",
      "Trial 220/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7036 | Final Val Loss: 1.4586\n",
      "R2 Score: 0.6713\n",
      "MSE Score: 0.4171\n",
      "MAE Score: 0.5551\n",
      "\n",
      "Trial 221/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7130 | Final Val Loss: 1.0815\n",
      "R2 Score: 0.6090\n",
      "MSE Score: 0.4961\n",
      "MAE Score: 0.5760\n",
      "\n",
      "Trial 222/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7595 | Final Val Loss: 1.1842\n",
      "R2 Score: 0.4103\n",
      "MSE Score: 0.7482\n",
      "MAE Score: 0.6846\n",
      "\n",
      "Trial 223/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8602 | Final Val Loss: 1.3551\n",
      "R2 Score: 0.6592\n",
      "MSE Score: 0.4324\n",
      "MAE Score: 0.5182\n",
      "\n",
      "Trial 224/288\n",
      "Current parameters: {'num_epochs': 250, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1002 | Final Val Loss: 1.3839\n",
      "R2 Score: 0.6579\n",
      "MSE Score: 0.4341\n",
      "MAE Score: 0.5206\n",
      "\n",
      "Trial 225/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3772 | Final Val Loss: 2.4485\n",
      "R2 Score: 0.3699\n",
      "MSE Score: 0.7995\n",
      "MAE Score: 0.6872\n",
      "\n",
      "Trial 226/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.3494 | Final Val Loss: 1.9451\n",
      "R2 Score: 0.5386\n",
      "MSE Score: 0.5855\n",
      "MAE Score: 0.5175\n",
      "\n",
      "Trial 227/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.3574 | Final Val Loss: 12.8254\n",
      "R2 Score: -4.7263\n",
      "MSE Score: 7.2655\n",
      "MAE Score: 2.5302\n",
      "\n",
      "Trial 228/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.0648 | Final Val Loss: 11.3941\n",
      "R2 Score: -3.8667\n",
      "MSE Score: 6.1750\n",
      "MAE Score: 2.3138\n",
      "\n",
      "Trial 229/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.7424 | Final Val Loss: 2.0113\n",
      "R2 Score: 0.4662\n",
      "MSE Score: 0.6773\n",
      "MAE Score: 0.6037\n",
      "\n",
      "Trial 230/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.2523 | Final Val Loss: 2.2468\n",
      "R2 Score: 0.5724\n",
      "MSE Score: 0.5426\n",
      "MAE Score: 0.6072\n",
      "\n",
      "Trial 231/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5212 | Final Val Loss: 12.1620\n",
      "R2 Score: -4.5449\n",
      "MSE Score: 7.0354\n",
      "MAE Score: 2.4404\n",
      "\n",
      "Trial 232/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.7223 | Final Val Loss: 10.6287\n",
      "R2 Score: -3.6224\n",
      "MSE Score: 5.8650\n",
      "MAE Score: 2.1923\n",
      "\n",
      "Trial 233/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4298 | Final Val Loss: 2.2742\n",
      "R2 Score: 0.4651\n",
      "MSE Score: 0.6787\n",
      "MAE Score: 0.6716\n",
      "\n",
      "Trial 234/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4284 | Final Val Loss: 1.3444\n",
      "R2 Score: 0.6272\n",
      "MSE Score: 0.4730\n",
      "MAE Score: 0.6566\n",
      "\n",
      "Trial 235/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2594 | Final Val Loss: 1.2202\n",
      "R2 Score: 0.7217\n",
      "MSE Score: 0.3531\n",
      "MAE Score: 0.5035\n",
      "\n",
      "Trial 236/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.5475 | Final Val Loss: 1.6191\n",
      "R2 Score: 0.6713\n",
      "MSE Score: 0.4171\n",
      "MAE Score: 0.5133\n",
      "\n",
      "Trial 237/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4037 | Final Val Loss: 1.5120\n",
      "R2 Score: 0.3940\n",
      "MSE Score: 0.7689\n",
      "MAE Score: 0.7886\n",
      "\n",
      "Trial 238/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1247 | Final Val Loss: 1.1926\n",
      "R2 Score: 0.3813\n",
      "MSE Score: 0.7850\n",
      "MAE Score: 0.8089\n",
      "\n",
      "Trial 239/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6293 | Final Val Loss: 2.2194\n",
      "R2 Score: 0.3595\n",
      "MSE Score: 0.8127\n",
      "MAE Score: 0.7658\n",
      "\n",
      "Trial 240/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.6834 | Final Val Loss: 1.7277\n",
      "R2 Score: 0.4794\n",
      "MSE Score: 0.6605\n",
      "MAE Score: 0.6251\n",
      "\n",
      "Trial 241/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8256 | Final Val Loss: 1.0538\n",
      "R2 Score: 0.4706\n",
      "MSE Score: 0.6717\n",
      "MAE Score: 0.7146\n",
      "\n",
      "Trial 242/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.8590 | Final Val Loss: 1.2674\n",
      "R2 Score: 0.5886\n",
      "MSE Score: 0.5219\n",
      "MAE Score: 0.6332\n",
      "\n",
      "Trial 243/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.5279 | Final Val Loss: 9.8862\n",
      "R2 Score: -3.2159\n",
      "MSE Score: 5.3492\n",
      "MAE Score: 2.1961\n",
      "\n",
      "Trial 244/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.4366 | Final Val Loss: 10.9008\n",
      "R2 Score: -3.6538\n",
      "MSE Score: 5.9048\n",
      "MAE Score: 2.2619\n",
      "\n",
      "Trial 245/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0754 | Final Val Loss: 1.2010\n",
      "R2 Score: 0.4868\n",
      "MSE Score: 0.6511\n",
      "MAE Score: 0.7039\n",
      "\n",
      "Trial 246/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1111 | Final Val Loss: 1.1574\n",
      "R2 Score: 0.5227\n",
      "MSE Score: 0.6056\n",
      "MAE Score: 0.6483\n",
      "\n",
      "Trial 247/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.3450 | Final Val Loss: 9.9081\n",
      "R2 Score: -3.1074\n",
      "MSE Score: 5.2115\n",
      "MAE Score: 2.1295\n",
      "\n",
      "Trial 248/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.0631 | Final Val Loss: 9.6159\n",
      "R2 Score: -2.8981\n",
      "MSE Score: 4.9459\n",
      "MAE Score: 2.0865\n",
      "\n",
      "Trial 249/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8241 | Final Val Loss: 1.0259\n",
      "R2 Score: 0.3811\n",
      "MSE Score: 0.7852\n",
      "MAE Score: 0.6990\n",
      "\n",
      "Trial 250/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9317 | Final Val Loss: 1.2326\n",
      "R2 Score: 0.2803\n",
      "MSE Score: 0.9131\n",
      "MAE Score: 0.8216\n",
      "\n",
      "Trial 251/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.7566 | Final Val Loss: 1.4559\n",
      "R2 Score: 0.5774\n",
      "MSE Score: 0.5362\n",
      "MAE Score: 0.5850\n",
      "\n",
      "Trial 252/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9894 | Final Val Loss: 1.4810\n",
      "R2 Score: 0.6851\n",
      "MSE Score: 0.3995\n",
      "MAE Score: 0.5132\n",
      "\n",
      "Trial 253/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9438 | Final Val Loss: 1.2088\n",
      "R2 Score: 0.3927\n",
      "MSE Score: 0.7705\n",
      "MAE Score: 0.7063\n",
      "\n",
      "Trial 254/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2503 | Final Val Loss: 0.9988\n",
      "R2 Score: 0.2907\n",
      "MSE Score: 0.9000\n",
      "MAE Score: 0.7848\n",
      "\n",
      "Trial 255/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0192 | Final Val Loss: 1.6874\n",
      "R2 Score: 0.7538\n",
      "MSE Score: 0.3124\n",
      "MAE Score: 0.4578\n",
      "\n",
      "Trial 256/288\n",
      "Current parameters: {'num_epochs': 350, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.2383 | Final Val Loss: 0.9256\n",
      "R2 Score: 0.5664\n",
      "MSE Score: 0.5502\n",
      "MAE Score: 0.6563\n",
      "\n",
      "Trial 257/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.5664 | Final Val Loss: 1.3581\n",
      "R2 Score: 0.5854\n",
      "MSE Score: 0.5261\n",
      "MAE Score: 0.6162\n",
      "\n",
      "Trial 258/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0608 | Final Val Loss: 1.0255\n",
      "R2 Score: 0.5911\n",
      "MSE Score: 0.5188\n",
      "MAE Score: 0.5891\n",
      "\n",
      "Trial 259/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.8893 | Final Val Loss: 12.2007\n",
      "R2 Score: -4.2393\n",
      "MSE Score: 6.6476\n",
      "MAE Score: 2.4037\n",
      "\n",
      "Trial 260/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 6.4984 | Final Val Loss: 10.6209\n",
      "R2 Score: -2.9973\n",
      "MSE Score: 5.0718\n",
      "MAE Score: 2.0338\n",
      "\n",
      "Trial 261/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.8475 | Final Val Loss: 2.3692\n",
      "R2 Score: 0.5431\n",
      "MSE Score: 0.5797\n",
      "MAE Score: 0.4971\n",
      "\n",
      "Trial 262/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 2.3035 | Final Val Loss: 1.5110\n",
      "R2 Score: 0.8053\n",
      "MSE Score: 0.2470\n",
      "MAE Score: 0.4098\n",
      "\n",
      "Trial 263/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 7.3385 | Final Val Loss: 10.3444\n",
      "R2 Score: -3.0978\n",
      "MSE Score: 5.1993\n",
      "MAE Score: 1.9890\n",
      "\n",
      "Trial 264/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 10.3590 | Final Val Loss: 11.9566\n",
      "R2 Score: -4.0624\n",
      "MSE Score: 6.4233\n",
      "MAE Score: 2.3409\n",
      "\n",
      "Trial 265/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1752 | Final Val Loss: 1.1794\n",
      "R2 Score: 0.5571\n",
      "MSE Score: 0.5620\n",
      "MAE Score: 0.6864\n",
      "\n",
      "Trial 266/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9605 | Final Val Loss: 1.2293\n",
      "R2 Score: 0.5391\n",
      "MSE Score: 0.5848\n",
      "MAE Score: 0.6832\n",
      "\n",
      "Trial 267/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3210 | Final Val Loss: 1.2177\n",
      "R2 Score: 0.6202\n",
      "MSE Score: 0.4819\n",
      "MAE Score: 0.5828\n",
      "\n",
      "Trial 268/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4159 | Final Val Loss: 1.3080\n",
      "R2 Score: 0.5125\n",
      "MSE Score: 0.6186\n",
      "MAE Score: 0.6937\n",
      "\n",
      "Trial 269/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.3725 | Final Val Loss: 1.0447\n",
      "R2 Score: 0.3995\n",
      "MSE Score: 0.7619\n",
      "MAE Score: 0.8244\n",
      "\n",
      "Trial 270/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.4071 | Final Val Loss: 1.3006\n",
      "R2 Score: 0.4931\n",
      "MSE Score: 0.6431\n",
      "MAE Score: 0.7609\n",
      "\n",
      "Trial 271/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0920 | Final Val Loss: 3.7559\n",
      "R2 Score: 0.0125\n",
      "MSE Score: 1.2529\n",
      "MAE Score: 0.9143\n",
      "\n",
      "Trial 272/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'relu', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.8363 | Final Val Loss: 1.7205\n",
      "R2 Score: 0.7236\n",
      "MSE Score: 0.3507\n",
      "MAE Score: 0.4696\n",
      "\n",
      "Trial 273/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9250 | Final Val Loss: 0.8367\n",
      "R2 Score: 0.3267\n",
      "MSE Score: 0.8543\n",
      "MAE Score: 0.8312\n",
      "\n",
      "Trial 274/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 0.9230 | Final Val Loss: 1.1947\n",
      "R2 Score: 0.3623\n",
      "MSE Score: 0.8091\n",
      "MAE Score: 0.8006\n",
      "\n",
      "Trial 275/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.3879 | Final Val Loss: 9.2364\n",
      "R2 Score: -2.7292\n",
      "MSE Score: 4.7316\n",
      "MAE Score: 2.0869\n",
      "\n",
      "Trial 276/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.0713 | Final Val Loss: 10.7259\n",
      "R2 Score: -3.6201\n",
      "MSE Score: 5.8621\n",
      "MAE Score: 2.2943\n",
      "\n",
      "Trial 277/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.0336 | Final Val Loss: 0.8419\n",
      "R2 Score: 0.4925\n",
      "MSE Score: 0.6439\n",
      "MAE Score: 0.7046\n",
      "\n",
      "Trial 278/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 1.1155 | Final Val Loss: 1.0250\n",
      "R2 Score: 0.4368\n",
      "MSE Score: 0.7146\n",
      "MAE Score: 0.7521\n",
      "\n",
      "Trial 279/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 9.7449 | Final Val Loss: 11.0427\n",
      "R2 Score: -3.8808\n",
      "MSE Score: 6.1928\n",
      "MAE Score: 2.4020\n",
      "\n",
      "Trial 280/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'adam', 'patience': 15}\n",
      "Final Train loss: 8.1670 | Final Val Loss: 9.2427\n",
      "R2 Score: -2.9070\n",
      "MSE Score: 4.9573\n",
      "MAE Score: 2.1057\n",
      "\n",
      "Trial 281/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9454 | Final Val Loss: 1.0127\n",
      "R2 Score: 0.4821\n",
      "MSE Score: 0.6571\n",
      "MAE Score: 0.6758\n",
      "\n",
      "Trial 282/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1528 | Final Val Loss: 0.9686\n",
      "R2 Score: 0.2317\n",
      "MSE Score: 0.9749\n",
      "MAE Score: 0.8480\n",
      "\n",
      "Trial 283/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0080 | Final Val Loss: 1.4667\n",
      "R2 Score: 0.7325\n",
      "MSE Score: 0.3394\n",
      "MAE Score: 0.4857\n",
      "\n",
      "Trial 284/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.2, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0296 | Final Val Loss: 1.2755\n",
      "R2 Score: 0.6068\n",
      "MSE Score: 0.4989\n",
      "MAE Score: 0.5642\n",
      "\n",
      "Trial 285/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.1918 | Final Val Loss: 1.0273\n",
      "R2 Score: 0.4950\n",
      "MSE Score: 0.6407\n",
      "MAE Score: 0.6903\n",
      "\n",
      "Trial 286/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.8754 | Final Val Loss: 1.2904\n",
      "R2 Score: 0.5447\n",
      "MSE Score: 0.5777\n",
      "MAE Score: 0.6173\n",
      "\n",
      "Trial 287/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 0.0001, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 0.9356 | Final Val Loss: 1.6868\n",
      "R2 Score: 0.6568\n",
      "MSE Score: 0.4355\n",
      "MAE Score: 0.5745\n",
      "\n",
      "Trial 288/288\n",
      "Current parameters: {'num_epochs': 450, 'num_units': [16, 16, 8, 8], 'drop': 0.3, 'lr': 0.0001, 'decay': 1e-05, 'acts': 'tanh', 'opts': 'sgd', 'patience': 15}\n",
      "Final Train loss: 1.0716 | Final Val Loss: 1.4139\n",
      "R2 Score: 0.6489\n",
      "MSE Score: 0.4455\n",
      "MAE Score: 0.5506\n",
      "\n",
      "Grid search completed for this dataset!\n",
      "\n",
      "Best parameters found:\n",
      "num_epochs: 350\n",
      "num_units: [24, 16, 16, 8]\n",
      "drop: 0.2\n",
      "lr: 0.001\n",
      "decay: 1e-05\n",
      "acts: relu\n",
      "opts: adam\n",
      "patience: 15\n",
      "\n",
      "Best metrics:\n",
      "R2: 0.8070\n",
      "MSE: 0.2448\n",
      "MAE: 0.3785\n",
      "\n",
      "All datasets processed. Best results saved to 'results/best_models_summary.csv'\n",
      "\n",
      "Best overall model found for dataset: filtered_005.csv\n",
      "R2 Score: 0.8070\n"
     ]
    }
   ],
   "source": [
    "best_params, best_model, best_metrics = grid_search_MLP(target_r2=0.9,data_folder=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      2\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_targets.append(batch_y.numpy().reshape(-1, 1))  # Reshape to match predictions\n",
    "\n",
    "y_pred = np.concatenate(all_preds).reshape(-1)\n",
    "y_true = np.concatenate(all_targets).reshape(-1)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\n=== Final Evaluation on Test Set ===\")\n",
    "print(f\"MSE:  {mse:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"R^2:  {r2:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Learning Curve (1D CNN)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_true, y_pred, alpha=0.5)\n",
    "min_val = min(min(y_true), min(y_pred))\n",
    "max_val = max(max(y_true), max(y_pred))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "plt.title(\"Predicted vs True Phenotype\")\n",
    "plt.xlabel(\"True Phenotype\")\n",
    "plt.ylabel(\"Predicted Phenotype\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_00001.csv = \"[16, 16, 8, 8],0.2,0.0001,0.0001,350,tanh,sgd,15\"\n",
    "filtered_0001.csv = \"[16, 16, 8, 8],0.3,0.0001,1e-05,450,tanh,sgd,15\"\n",
    "filtered_001.csv = \"[24, 16, 16, 8],0.2,0.001,0.0001,350,tanh,adam,15\"\n",
    "filtered_005.csv = \"[24, 16, 16, 8],0.2,0.001,1e-05,350,relu,adam,15\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_7332\\634679112.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model00001.load_state_dict(torch.load(PATH, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ANN(\n",
       "  (layers): ModuleDict(\n",
       "    (input): Linear(in_features=15391, out_features=16, bias=True)\n",
       "    (hidden0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (hidden1): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (hidden2): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (output): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       "  (batch_norms): ModuleDict(\n",
       "    (input): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"MLP_models/best_model_filtered_00001.pth\"\n",
    "input_length = get_SNP(\"filtered_00001.csv\")[-1]\n",
    "model00001 = createANNModel([16, 16, 8, 8], drop=0.2,lr=0.0001,decay=0.0001,input_length=input_length,activation_type=\"tanh\",optimizer_type=\"sgd\")[0]\n",
    "model00001.load_state_dict(torch.load(PATH, map_location=device))  \n",
    "model00001 = model00001.to(device) \n",
    "model00001.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_7332\\1305006459.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model005.load_state_dict(torch.load(PATH, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ANN(\n",
       "  (layers): ModuleDict(\n",
       "    (input): Linear(in_features=96306, out_features=24, bias=True)\n",
       "    (hidden0): Linear(in_features=24, out_features=16, bias=True)\n",
       "    (hidden1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (hidden2): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (output): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       "  (batch_norms): ModuleDict(\n",
       "    (input): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"MLP_models/best_model_filtered_005.pth\"\n",
    "input_length = get_SNP(\"filtered_005.csv\")[-1]\n",
    "model005 = createANNModel([24, 16, 16, 8], drop=0.2,lr=0.001,decay=1e-5,input_length=input_length,activation_type=\"relu\",optimizer_type=\"adam\")[0]\n",
    "model005.load_state_dict(torch.load(PATH, map_location=device))  \n",
    "model005 = model005.to(device) \n",
    "model005.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\AppData\\Local\\Temp\\ipykernel_7332\\626024841.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model001.load_state_dict(torch.load(PATH, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ANN(\n",
       "  (layers): ModuleDict(\n",
       "    (input): Linear(in_features=52848, out_features=24, bias=True)\n",
       "    (hidden0): Linear(in_features=24, out_features=16, bias=True)\n",
       "    (hidden1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (hidden2): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (output): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       "  (batch_norms): ModuleDict(\n",
       "    (input): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"MLP_models/best_model_filtered_001.pth\"\n",
    "input_length = get_SNP(\"filtered_001.csv\")[-1]\n",
    "model001 = createANNModel([24, 16, 16, 8], drop=0.2,lr=0.001,decay=0.0001,input_length=input_length,activation_type=\"tanh\",optimizer_type=\"adam\")[0]\n",
    "model001.load_state_dict(torch.load(PATH, map_location=device))  \n",
    "model001 = model001.to(device) \n",
    "model001.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_graph(model,data,snp_number=20):\n",
    "    N = snp_number\n",
    "    \n",
    "    df = pd.read_csv(f\"data/{data}.csv\")\n",
    "    df = df.drop([\"Genotype\"],axis=1)\n",
    "    X = df.drop([\"Phenotype\"],axis=1)\n",
    "    \n",
    "    input_weights = model.state_dict()[list(model.state_dict().keys())[0]]\n",
    "    \n",
    "    snp_weights = input_weights.mean(dim=0).cpu().numpy()\n",
    "    \n",
    "    fig_height = max(5, N * 0.4)\n",
    "    plt.figure(figsize=(12, fig_height))\n",
    "\n",
    "    snp_names = np.array(X.columns)\n",
    "    sorted_indices = np.argsort(snp_weights)\n",
    "\n",
    "    plt.barh(snp_names[sorted_indices][-N:], snp_weights[sorted_indices][-N:], color=\"forestgreen\", label=\"Positive Effect\")\n",
    "    plt.barh(snp_names[sorted_indices][:N], snp_weights[sorted_indices][:N], color=\"firebrick\", label=\"Negative Effect\")\n",
    "\n",
    "    plt.xlabel(\"Feature Importance (Weight Value)\")\n",
    "    plt.ylabel(\"SNPs\")\n",
    "    plt.title(f\"Top SNPs Affecting Phenotype for {data}\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"important_{snp_number}_snps for {data}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = \"MLP_models/best_model_filtered_0001.pth\"\n",
    "input_length = get_SNP(\"filtered_0001.csv\")[-1]\n",
    "model0001 = createANNModel([16, 16, 8, 8], drop=0.3,lr=0.0001,decay=1e-5,input_length=input_length,activation_type=\"tanh\",optimizer_type=\"sgd\")[0]\n",
    "model0001.load_state_dict(torch.load(PATH, map_location=device))  \n",
    "model0001 = model0001.to(device) \n",
    "model0001.eval()\n",
    "importance_graph(model00001, snp_number=20,data=\"filtered_00001\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
